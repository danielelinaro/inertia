{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import strftime, localtime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.fft import fft\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(F0, F1, time, random_phase=False, mu=0.0, sigma=0.0):\n",
    "    N_samples = time.shape[0]\n",
    "    if F1 is None:\n",
    "        N_entries = len(F0)\n",
    "    else:\n",
    "        N_entries = len(F0) * len(F1)\n",
    "\n",
    "    if random_phase:\n",
    "        phi = tf.random.uniform(shape=[N_entries], minval=0, maxval=np.pi)\n",
    "    else:\n",
    "        phi = tf.zeros(N_entries)\n",
    "        \n",
    "    if F1 is None:\n",
    "        x = tf.constant([np.sin(2 * np.pi * f * time + phi) for f,phi in zip(F0, phi)])\n",
    "        y = tf.constant(list(map(float, F0)), shape=(len(F0),1))\n",
    "    else:\n",
    "        x = np.zeros((N_entries, N_samples), dtype=np.float32)\n",
    "        y = np.zeros((N_entries, 2), dtype=np.float32)\n",
    "        k = 0\n",
    "        for f0 in F0:\n",
    "            for f1 in F1:\n",
    "                c = (f1 - f0) / time[-1]\n",
    "                F = c * time + f0\n",
    "                x[k] = np.sin(2 * np.pi * F * time + phi[k])\n",
    "                y[k,0] = f0\n",
    "                y[k,1] = f1\n",
    "                k += 1\n",
    "        x = tf.constant(x)\n",
    "        y = tf.constant(y)\n",
    "    if mu != 0.0 or sigma > 0.0:\n",
    "        x = tf.math.add(x, tf.random.normal(shape=x.shape, mean=mu, stddev=sigma))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fix the seed of the RNG, for reproducibility purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_good_sinusoidal = False\n",
    "use_good_chirp = False\n",
    "\n",
    "with open('/dev/random', 'rb') as fid:\n",
    "    seed = int.from_bytes(fid.read(4), 'little')\n",
    "\n",
    "if use_good_sinusoidal:\n",
    "    seed = 1870310641\n",
    "elif use_good_chirp:\n",
    "    seed = 1794354334\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print('Seed: {}'.format(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'chirp'\n",
    "\n",
    "tend = 1\n",
    "\n",
    "random_phase = False\n",
    "mu = 0.0\n",
    "sigma = 0.1\n",
    "\n",
    "if data_type == 'sinusoidal':\n",
    "    N = 1024 * 8\n",
    "    N_reps = 10\n",
    "\n",
    "    time = np.linspace(0, tend, N)\n",
    "\n",
    "    df = 1.5\n",
    "    F_train = np.r_[10 : 70 + df/2 : df]\n",
    "    F_val = F_train[:-1] + 2. / 3. * df\n",
    "    F_test = F_train[:-1] + df / 3.\n",
    "    F_train = np.tile(F_train, [N_reps,1]).flatten('F')\n",
    "\n",
    "    x_train, y_train = make_dataset(F_train, None, time, random_phase, mu, sigma)\n",
    "    x_test, y_test = make_dataset(F_test, None, time, random_phase, mu, sigma)\n",
    "    x_val, y_val = make_dataset(F_val, None, time, random_phase, mu, sigma)\n",
    "\n",
    "elif data_type == 'chirp':\n",
    "    N = 10000\n",
    "\n",
    "    time = np.linspace(0, tend, N)\n",
    "\n",
    "    df0 = 3\n",
    "    df1 = 6\n",
    "    F0_train = np.r_[10 : 70 + df0/2 : df0]\n",
    "    F1_train = np.r_[100 : 220 + df1/2 : df1]\n",
    "    F0_val = F0_train[:-1] + 2. / 3. * df0\n",
    "    F1_val = F1_train[:-1] + 2. / 3. * df1\n",
    "    F0_test = F0_train[:-1] + 1. / 3. * df0\n",
    "    F1_test = F1_train[:-1] + 1. / 3. * df1\n",
    "\n",
    "    x_train, y_train = make_dataset(F0_train, F1_train, time, random_phase, mu, sigma)\n",
    "    x_test, y_test = make_dataset(F0_test, F1_test, time, random_phase, mu, sigma)\n",
    "    x_val, y_val = make_dataset(F0_val, F1_val, time, random_phase, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std\n",
    "x_val = (x_val - x_train_mean) / x_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "fig,(ax1,ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "ax1.plot(time, x_train[idx], 'm')\n",
    "ax1.plot(time, x_val[idx], 'g')\n",
    "ax1.plot(time, x_test[idx], 'b')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax2.plot(time, x_train[idx], 'm', label='Train')\n",
    "ax2.plot(time, x_val[idx], 'g', label='Test')\n",
    "ax2.plot(time, x_test[idx], 'b', label='Validation')\n",
    "if data_type == 'sinusoidal':\n",
    "    ax1.set_xlim([0, 3/F_train[idx]])\n",
    "    ax2.set_xlim([time[-1] - 3/F_train[idx], time[-1]])\n",
    "elif data_type == 'chirp':\n",
    "    ax1.set_xlim([0, 3/F0_train[idx]])\n",
    "    ax2.set_xlim([time[-1] - 3/F0_train[idx], time[-1]])\n",
    "ax2.legend(loc='best')\n",
    "ax2.set_xlabel('Time (s)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use FFT to extract the frequency of the sinusoids in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'sinusoidal':\n",
    "    x_test_fft = fft(x_test.numpy(), axis=1)\n",
    "    x_test_fft_mag = 2.0 / N * np.abs(x_test_fft[:, 0:N//2])\n",
    "    idx = np.argmax(x_test_fft_mag, axis=1)\n",
    "    freq = np.linspace(0.0, 1.0 / (2.0 * np.diff(time[:2])), N//2)\n",
    "    y_fft = freq[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "The network topology used here is taken from the following paper:\n",
    "\n",
    "George, D., & Huerta, E. A. (2018). Deep neural networks to enable real-time multimessenger astrophysics. Physical Review D, 97(4), 044039. http://doi.org/10.1103/PhysRevD.97.044039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_dropout = False\n",
    "dropout_coeff = 0.2\n",
    "depth_level = 2\n",
    "learning_rate = 1e-4\n",
    "\n",
    "N_units = {}\n",
    "\n",
    "if depth_level == 1:\n",
    "    N_units['conv'] = [16, 32, 64]\n",
    "elif depth_level == 2:\n",
    "    N_units['conv'] = [64, 128, 256, 512]\n",
    "\n",
    "N_units['pooling'] = [4 for _ in range(len(N_units['conv']))]\n",
    "kernel_size = [5 for _ in range(len(N_units['conv']))]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((N,1), input_shape=(N,)),\n",
    "])\n",
    "\n",
    "for N_conv,N_pooling,sz in zip(N_units['conv'], N_units['pooling'], kernel_size):\n",
    "    model.add(tf.keras.layers.Conv1D(N_conv, sz, activation=None))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(N_pooling))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "if depth_level == 2:\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    \n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "if with_dropout:\n",
    "    model.add(tf.keras.layers.Dropout(dropout_coeff))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(y_train.shape[1]))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = strftime('%Y%m%d-%H%M%S', localtime())\n",
    "path = 'parameter_extraction_models/' + data_type + '/' + ts\n",
    "checkpoint_path = path + '/checkpoints'\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0)\n",
    "\n",
    "EPOCHS = 10\n",
    "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data=(x_val, y_val), \\\n",
    "                    callbacks=[cp_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the loss as a function of the epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.r_[0 : len(history.history['loss'])] + 1\n",
    "plt.plot(epochs, history.history['loss'], 'k', label='Training')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the network prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the Mean Absolute Percentage Error on the CNN and FFT predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_cnn = tf.keras.losses.mean_absolute_percentage_error(tf.transpose(y_test), tf.transpose(y_cnn)).numpy()[0]\n",
    "if data_type == 'sinusoidal':\n",
    "    mape_fft = tf.keras.losses.mean_absolute_percentage_error(tf.transpose(y_test), tf.transpose(y_fft)).numpy()[0]\n",
    "    print('MAPE on FFT prediction ... {:.2f}%'.format(mape_fft))\n",
    "print('MAPE on CNN prediction ... {:.2f}%'.format(mape_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results obtained with the CNN\n",
    "\n",
    "(and compare them with those obtained with the FFT if using just sinusoidal data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'sinusoidal':\n",
    "    fig,ax = plt.subplots(1, 2, sharex=True, figsize=(10,5))\n",
    "    limits = y_test.numpy()[[0,-1]]\n",
    "    \n",
    "    ax[0].plot(limits, limits, 'r--')\n",
    "    ax[0].plot(y_test, y_cnn, 'ko', markersize=5, markerfacecolor='w', markeredgewidth=1)\n",
    "    ax[0].axis('square')\n",
    "    ax[0].set_title('CNN')\n",
    "    ax[0].set_xlabel('Expected value')\n",
    "    ax[0].set_ylabel('Predicted value')\n",
    "\n",
    "    ax[1].plot(limits, limits, 'r--')\n",
    "    ax[1].plot(y_test, y_fft, 'ko', markersize=5, markerfacecolor='w', markeredgewidth=1)\n",
    "    ax[1].axis('square')\n",
    "    ax[1].set_title('FFT')\n",
    "    ax[1].set_xlabel('Expected value');\n",
    "\n",
    "elif data_type == 'chirp':\n",
    "    fig,ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "    for i in range(2):\n",
    "        limits = y_test.numpy()[[0,-1],i]\n",
    "        ax[i].plot(limits, limits, 'r--')\n",
    "        ax[i].plot(y_test[:,i], y_cnn[:,i], 'ko', markersize=5, markerfacecolor='w', markeredgewidth=1)\n",
    "        ax[i].set_xlabel('Expected value')\n",
    "        ax[i].set_title('F{}'.format(i))\n",
    "    ax[0].set_ylabel('Predicted value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'tend': tend, 'random_phase': random_phase, 'mu': mu, 'sigma': sigma,\n",
    "              'N_samples': N, 'data_type': data_type, 'seed': seed, 'with_dropout': with_dropout,\n",
    "              'depth_level': depth_level, 'N_units': N_units, 'kernel_size': kernel_size,\n",
    "              'N_epochs': EPOCHS, 'mape_cnn': mape_cnn, 'learning_rate': learning_rate,\n",
    "              'x_train': x_train, 'y_train': y_train, \n",
    "              'x_test': x_test, 'y_test': y_test, \n",
    "              'x_val': x_val, 'y_val': y_val, 'y_cnn': y_cnn}\n",
    "if data_type == 'sinusoidal':\n",
    "    parameters['df'] = df\n",
    "    parameters['F_train'] = F_train\n",
    "    parameters['F_val'] = F_val\n",
    "    parameters['F_test'] = F_test\n",
    "    parameters['mape_fft'] = mape_fft\n",
    "    parameters['y_fft'] = y_fft\n",
    "elif data_type == 'chirp':\n",
    "    parameters['df0'] = df0\n",
    "    parameters['df1'] = df1\n",
    "    parameters['F0_train'] = F0_train\n",
    "    parameters['F1_train'] = F1_train\n",
    "    parameters['F0_val'] = F0_val\n",
    "    parameters['F1_val'] = F1_val\n",
    "    parameters['F0_test'] = F0_test\n",
    "    parameters['F1_test'] = F1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path)\n",
    "pickle.dump(parameters, open(path + '/parameters.pkl', 'wb'))\n",
    "pickle.dump(history.history, open(path + '/history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'parameter_extraction_models/chirp/20200915-172605'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(path)\n",
    "parameters = pickle.load(open(path + '/parameters.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(parameters['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace(0, parameters['tend'], parameters['N_samples'])\n",
    "\n",
    "if parameters['data_type'] == 'sinusoidal':\n",
    "    x_train, _ = make_dataset(parameters['F_train'], None, time, \\\n",
    "                              parameters['random_phase'], parameters['mu'], parameters['sigma'])\n",
    "    x_test, y_test = make_dataset(parameters['F_test'], None, time, \\\n",
    "                              parameters['random_phase'], parameters['mu'], parameters['sigma'])\n",
    "elif parameters['data_type'] == 'chirp':\n",
    "    x_train, _ = make_dataset(parameters['F0_train'], parameters['F1_train'], time, \\\n",
    "                              parameters['random_phase'], parameters['mu'], parameters['sigma'])\n",
    "    x_test, y_test = make_dataset(parameters['F0_test'], parameters['F1_test'], time, \\\n",
    "                              parameters['random_phase'], parameters['mu'], parameters['sigma'])\n",
    "\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn = model.predict(parameters['x_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_cnn = tf.keras.losses.mean_absolute_percentage_error(tf.transpose(y_test), tf.transpose(y_cnn)).numpy()[0]\n",
    "print('MAPE on CNN prediction ... {:.2f}%'.format(mape_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.transpose(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['y_cnn'].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
