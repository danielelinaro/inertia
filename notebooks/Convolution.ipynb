{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.signal import convolve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5900aae",
   "metadata": {},
   "source": [
    "### Prepare the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd42677",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "input_shape = (1, n_samples, 1)\n",
    "tf.random.set_seed(5061983)\n",
    "x = tf.random.uniform(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e77a4",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab14de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kernels = [4, 8]\n",
    "kernel_size = [5, 5]\n",
    "input_layer = keras.Input(shape=(n_samples,1), name='input')\n",
    "layers = [input_layer]\n",
    "kernel_init = 'glorot_uniform'\n",
    "# kernel_init = 'ones'\n",
    "for i,(n,sz) in enumerate(zip(n_kernels, kernel_size)):\n",
    "    L = keras.layers.Conv1D(filters=n, kernel_size=sz, strides=1,\n",
    "                            name=f'conv_{i+1}', padding='valid',\n",
    "                            dilation_rate=1, groups=1, kernel_initializer=kernel_init,\n",
    "                            use_bias=False)(layers[-1])\n",
    "    layers.append(L)\n",
    "model = keras.Model(inputs=layers[:1], outputs=layers[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe588985",
   "metadata": {},
   "source": [
    "### Compute the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff323db",
   "metadata": {},
   "source": [
    "#### Get the weights, i.e., the kernels used in the convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79fcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = model.layers[1:]\n",
    "weights = [layer.weights[0] for layer in conv_layers]\n",
    "weights_shapes = [w.shape for w in weights]\n",
    "for shp,lyr in zip(weights_shapes, conv_layers):\n",
    "    print(f'The weights of layer `{lyr.name}` have shape', shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7c645",
   "metadata": {},
   "source": [
    "### Figure out how Conv1D performs the computation\n",
    "\n",
    "The first layer has `n_kernels[0]` 1D kernels of length `kernel_size[0]`. The input is a 1D time series of `n_samples` samples. The output will be a matrix with `n_samples - kernel_size[0] + 1` rows and `n_kernels[0]` columns. The i-th column is the convolution of the i-th kernel with the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([convolve(np.squeeze(x.numpy()),\n",
    "                        np.squeeze(weights[0][-1::-1, 0, i].numpy()),\n",
    "                        mode='valid', method='direct') for i in range(n_kernels[0])]).T[np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(y1 == y[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7aaf69",
   "metadata": {},
   "source": [
    "The second layer has `n_kernels[1]` 2D kernels of size (`kernel_size[1]`,`n_kernels[0]`). The input is a 2D matrix with `n_samples - kernel_size[0] + 1` rows and `n_kernels[0]` columns. The output will be a matrix with `n_samples - kernel_size[0] - kernel_size[1] + 2` rows and `n_kernels[1]` columns. The i-th column is the __sum__ of the convolutions of __each column__ of the i-th 2D kernel with __each column__ of the 2D input matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db98cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array([np.array([convolve(np.squeeze(y[0][0, :, j].numpy()),\n",
    "                         np.squeeze(weights[1][-1::-1, j, i].numpy()),\n",
    "                         mode='valid', method='direct') for j in range(weights[1].shape[1])]).sum(axis=0) \\\n",
    "               for i in range(n_kernels[i])]).T[np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75158794",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(np.abs(y2 - y[1].numpy())) < 1e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
