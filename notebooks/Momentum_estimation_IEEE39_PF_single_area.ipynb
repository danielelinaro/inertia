{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import shelve\n",
    "from collections import OrderedDict\n",
    "\n",
    "from comet_ml.api import API, APIExperiment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import read_area_values, load_data_slide\n",
    "from dlml.nn import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = lambda H, S, fn=60.: 2 * H@S / fn * 1e-3\n",
    "\n",
    "inertia = lambda H, S: H@S / S.sum()\n",
    "\n",
    "\n",
    "def make_filename(H_values, data_dir, data_file_suffix='ieee39_PF_stoch_loads_compensators'):\n",
    "    data_file = data_file_suffix\n",
    "    variable_generators = []\n",
    "    for gen in H_values[0].keys():\n",
    "        h_val = np.array([v[gen] for v in H_values])\n",
    "        if np.all(h_val == h_val[0]):\n",
    "            data_file += f'_{h_val[0]:.3f}'\n",
    "        else:\n",
    "            variable_generators.append(gen)\n",
    "            data_file += '_' + '-'.join(list(map(lambda s: f'{s:.3f}', h_val)))\n",
    "    data_file += '.h5'\n",
    "    return os.path.join(data_dir, data_file), variable_generators\n",
    "\n",
    "\n",
    "def analyze_single_file_experiment(H_values, data_dir, var_names, data_mean, data_std,\n",
    "                                   window_dur, window_step, area_id,\n",
    "                                   data_file_suffix='ieee39_PF_stoch_loads_compensators'):\n",
    "    data_file,var_gens = make_filename(H_values, data_dir, data_file_suffix)\n",
    "    if not os.path.isfile(data_file):\n",
    "        raise Exception(data_file + ': no such file')\n",
    "    data_time, data, data_normalized, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                                        var_names,\n",
    "                                                                        data_mean,\n",
    "                                                                        data_std,\n",
    "                                                                        window_dur,\n",
    "                                                                        window_step,\n",
    "                                                                        add_omega_ref = False,\n",
    "                                                                        verbose = True)\n",
    "    prediction_time, prediction, _ = predict(model, data_sliding, window_step)\n",
    "        \n",
    "    sim_dur = np.ceil(data_time[-1])\n",
    "    N_H = len(H_values)\n",
    "    block_dur = sim_dur / N_H\n",
    "    S = np.array([P_nom_with_comp[gen]*1e-6 for gen in generators_areas_map_with_comp['default'][area_id-1]])\n",
    "    area_inertia = np.zeros(N_H)\n",
    "    exact = np.zeros(N_H)\n",
    "    mean_prediction = np.zeros(N_H)\n",
    "    for i in range(N_H):\n",
    "        try:\n",
    "            H = np.array([H_values[i]['G02'],\n",
    "                          H_values[i]['G03'],\n",
    "                          H_values[i]['Comp11']])\n",
    "        except:\n",
    "            H = np.array([H_values[i]['G02'],\n",
    "                          H_values[i]['VSG03'],\n",
    "                          H_values[i]['Comp11']])\n",
    "        area_inertia[i] = inertia(H, S)\n",
    "        exact[i] = momentum(H, S)\n",
    "        idx = (prediction_time >= i*block_dur) & (prediction_time < (i+1)*block_dur)\n",
    "        mean_prediction[i] = np.nanmean(prediction[idx])\n",
    "        print('H = {} -> H = {:.4f} s, M = {:.4f}, M_pred = {:.4f} GW.s2'.format(\n",
    "            H, area_inertia[i], exact[i], mean_prediction[i]))\n",
    "\n",
    "    return data_time, data, data_normalized, prediction_time, prediction, area_inertia, exact, mean_prediction\n",
    "\n",
    "\n",
    "def plot_single_file_experiment(time, prediction, exact, mean_prediction, N_blocks,\n",
    "                                block_dur, area_measure, measure_units):\n",
    "    fig,ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "    for i in range(N_blocks):\n",
    "        t0,t1 = block_dur*i/60, block_dur*(i+1)/60\n",
    "        ax.plot([t0, t1], mean_prediction[i] + np.zeros(2), 'k--', lw=1)\n",
    "        ax.plot([t0, t1], exact[i] + np.zeros(2), 'r--', lw=1)\n",
    "    ax.plot(time/60, prediction, 'k', lw=2)\n",
    "    for side in 'right','top':\n",
    "        ax.spines[side].set_visible(False)\n",
    "    ax.set_xlabel('Time [min]')\n",
    "    ax.set_ylabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "    ax.grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "    fig.tight_layout()\n",
    "    \n",
    "\n",
    "make_experiment_dict = lambda H_values, data_time, data, data_normalized, \\\n",
    "                            prediction_time, prediction, area_inertia, exact, \\\n",
    "                            mean_prediction, description='': \\\n",
    "    {\n",
    "        'H_values': H_values,\n",
    "        'data_time': data_time, 'data': data, 'data_normalized': data_normalized,\n",
    "        'prediction_time': prediction_time, 'prediction': prediction,\n",
    "        'area_inertia': area_inertia,\n",
    "        'exact': exact,\n",
    "        'mean_prediction': mean_prediction,\n",
    "        'description': description\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "area_ID = 1\n",
    "area_measure = 'momentum'\n",
    "stoch_load_bus_IDs = []\n",
    "rec_bus_IDs = [3, 14, 17, 39]\n",
    "H_G1, D, DZA = None, None, None # 500, 2, 0\n",
    "additional_tags = ['ReLU_none', 'converted_from_PowerFactory', 'all_stoch_loads']\n",
    "\n",
    "experiments = collect_experiments(area_ID, area_measure=area_measure, D=D, DZA=DZA, \\\n",
    "                                  stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=H_G1, \\\n",
    "                                  rec_bus_IDs=rec_bus_IDs, additional_tags=additional_tags, \\\n",
    "                                  verbose=True)\n",
    "experiment_IDs = list(experiments.keys())\n",
    "experiment_ID = experiment_IDs[np.argmin([expt['val_loss'].min() for expt in experiments.values()])]\n",
    "experiment_ID = '7d55f784f6b64f2caeb866804bda1a8b'\n",
    "experiment_ID = '8b8ba7ec5b854b5fa2deffdfd774ba41'\n",
    "experiment_ID = '57dfd307a5a945d8b28e5cf501b41f13'\n",
    "MAPE = experiments[experiment_ID]['MAPE']\n",
    "loss = experiments[experiment_ID]['loss']\n",
    "val_loss = experiments[experiment_ID]['val_loss']\n",
    "batch_loss = experiments[experiment_ID]['batch_loss']\n",
    "tags = experiments[experiment_ID]['tags']\n",
    "print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE:.4f}%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full grid without varying compensator's inertia\n",
    "# experiment_ID = '7d55f784f6b64f2caeb866804bda1a8b' # WRONG\n",
    "experiment_ID = 'f64bde90cab54d1ea770bb21f33c3ed1'\n",
    "# full grid with variable compensator's inertia\n",
    "# experiment_ID = '57dfd307a5a945d8b28e5cf501b41f13' # WRONG\n",
    "# experiment_ID = '13ea047db0cb40efa3e2743de9b9726e'\n",
    "# experiment_ID = '98d1862b1cc1465884cf9e5ab59fc4da'\n",
    "experiment_ID = 'a40658acee3c4e419c0ee34d0c59f4df'\n",
    "\n",
    "workspace = 'danielelinaro'\n",
    "project_name = 'inertia'\n",
    "\n",
    "api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "experiment = api.get_experiment(workspace, project_name, experiment_ID)\n",
    "sys.stdout.write(f'Getting metrics and tags for experiment {experiment_ID[:6]}... ')\n",
    "sys.stdout.flush()\n",
    "metrics = experiment.get_metrics()\n",
    "tags = experiment.get_tags()\n",
    "sys.stdout.write('done.\\n')\n",
    "\n",
    "print(f'Experiment {experiment_ID[:6]} has the following tags:')\n",
    "nchar = 0\n",
    "for tag in tags:\n",
    "    if 'buses_' in tag:\n",
    "        rec_bus_IDs = sorted(list(map(int, re.findall('\\d+', tag))))\n",
    "    elif 'area_measure_' in tag:\n",
    "        area_measure = tag.split('_')[-1]\n",
    "    elif 'area' in tag:\n",
    "        area_ID = int(tag[4:])\n",
    "    elif tag == 'all_stoch_loads':\n",
    "        stoch_load_bus_IDs = []\n",
    "    sys.stdout.write('\"' + tag + '\"   ')\n",
    "    nchar += len(tag) + 5\n",
    "    if nchar >= 70:\n",
    "        nchar = 0\n",
    "        sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = {}\n",
    "metric_names = 'loss', 'val_loss', 'lr', 'epoch_duration'\n",
    "for m in metrics:\n",
    "    name = m['metricName']\n",
    "    if name in metric_names:\n",
    "        step = int(m['step'])\n",
    "        if step not in blob:\n",
    "            blob[step] = {}\n",
    "        blob[step][name] = float(m['metricValue'])\n",
    "        blob[step]['epoch'] = int(m['epoch'])\n",
    "    elif name == 'mape_prediction':\n",
    "        MAPE = float(m['metricValue'])\n",
    "epochs = np.array([v['epoch'] for v in blob.values()]) + 1\n",
    "data = {\n",
    "    'step': np.array(list(blob.keys()))\n",
    "}\n",
    "for k in metric_names:\n",
    "    data[k] = np.array([v[k] for v in blob.values()])\n",
    "df = pd.DataFrame(data, epochs)\n",
    "df.index.rename('epoch', inplace=True)\n",
    "columns = df.columns.to_list()\n",
    "columns[columns.index('lr')] = 'learning_rate'\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Experiment {} has minimum validation loss = {:.4f} and MAPE = {:.2f}%.'.format(\n",
    "    experiment_ID[:6], df['val_loss'].min(), MAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfrac = 0.1\n",
    "VSG_pars = {'KAD': 2.0, 'KW': 10.0}\n",
    "shelf_name = experiment_ID[:6] + f'_Pfrac={Pfrac:.1f}'\n",
    "for k,v in VSG_pars.items():\n",
    "    shelf_name += f'_{k}={v:.1f}'\n",
    "print(f'Saving data to {experiment_ID}/{shelf_name}.out')\n",
    "db = shelve.open(os.path.join('..','experiments','neural_network', experiment_ID, shelf_name + '.out'),\n",
    "                 flag='n')\n",
    "db['metrics'] = df\n",
    "db['MAPE'] = MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "\n",
    "ax.plot(df.index, df['loss'], 'k', lw=1, label='Batch')\n",
    "ax.plot(df.index, df['val_loss'], 'r', lw=1, label='Validation')\n",
    "ax.grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "\n",
    "twin = ax.twinx()\n",
    "twin.plot(df.index, df['learning_rate'], color=[0,.2,.8], lw=1)\n",
    "twin.set_ylabel('Learning rate')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "if len(checkpoint_files) == 1:\n",
    "    best_checkpoint = checkpoint_files[0]\n",
    "else:\n",
    "    epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "model = keras.models.load_model(best_checkpoint, compile=False)\n",
    "model.compile()\n",
    "network_parameters = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'parameters.pkl'), 'rb'))\n",
    "data_dirs = [os.path.join('..', d.format(a)) if '{}' in d else os.path.join('..', d) \\\n",
    "             for d,a in zip(network_parameters['data_dirs'], network_parameters['area_IDs'])]\n",
    "# we need mean and standard deviation of the training set to normalize the data\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "data_dir = data_dirs[0]\n",
    "tmp = [re.findall('.*_bus', var_name)[0] for var_name in network_parameters['var_names'] if 'bus' in var_name]\n",
    "var_names_fmt = OrderedDict({k + '{}': [] for k in tmp})\n",
    "tmp = [re.findall('.*_line', var_name)[0] for var_name in network_parameters['var_names'] if 'line' in var_name]\n",
    "for k in tmp:\n",
    "    var_names_fmt[k + '_{}_{}'] = []\n",
    "var_names_fmt = list(var_names_fmt.keys())\n",
    "if len(rec_bus_IDs) == 0:\n",
    "    rec_bus_IDs = list(np.unique([int(re.findall('\\d+', var_name)[0]) \\\n",
    "                                  for var_name in network_parameters['var_names']]))\n",
    "    rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "var_names = [fmt.format(bus) for fmt in var_names_fmt for bus in rec_bus_IDs]\n",
    "if not os.path.isdir(data_dir):\n",
    "    raise Exception(f'{data_dir}: no such directory')\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Data directory is {data_dir}.')\n",
    "print(f'Variable names: {var_names_fmt}')\n",
    "db['x_train_mean'] = x_train_mean\n",
    "db['x_train_std'] = x_train_std\n",
    "db['data_dir'] = data_dir\n",
    "db['weights_file'] = best_checkpoint\n",
    "db['var_names_fmt'] = var_names_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_H = OrderedDict([\n",
    "    ('G01', 5.00), ('G02', 4.33), ('G03', 4.47), ('G04', 3.57), ('G05', 4.33),\n",
    "    ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.20)\n",
    "])\n",
    "default_H_with_comp = OrderedDict([\n",
    "    ('G01', 5.00), ('G02', 4.33), ('G03', 4.47), ('G04', 3.57), ('G05', 4.33),\n",
    "    ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.20),\n",
    "    ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "])\n",
    "default_H_with_comp_and_vsg = OrderedDict([\n",
    "    ('G01', 5.00), ('G02', 4.33), ('G04', 3.57), ('G05', 4.33),\n",
    "    ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.20),\n",
    "    ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1), ('VSG03', 4.47)\n",
    "])\n",
    "\n",
    "\n",
    "generators_areas_map = {\n",
    "    'default': [\n",
    "        ['G02', 'G03'],\n",
    "        ['G04', 'G05', 'G06', 'G07'],\n",
    "        ['G08', 'G09', 'G10'],\n",
    "        ['G01']\n",
    "    ]\n",
    "}\n",
    "generators_areas_map_with_comp = {\n",
    "    'default': [\n",
    "        ['G02', 'G03', 'Comp11'],\n",
    "        ['G04', 'G05', 'G06', 'G07', 'Comp21'],\n",
    "        ['G08', 'G09', 'G10', 'Comp31'],\n",
    "        ['G01']\n",
    "    ]\n",
    "}\n",
    "generators_areas_map_with_comp_and_vsg = {\n",
    "    'default': [\n",
    "        ['G02', 'VSG03', 'Comp11'],\n",
    "        ['G04', 'G05', 'G06', 'G07', 'Comp21'],\n",
    "        ['G08', 'G09', 'G10', 'Comp31'],\n",
    "        ['G01']\n",
    "    ]\n",
    "}\n",
    "\n",
    "P_nom = {'G01': 10000e6, 'G02': 700e6, 'G03': 800e6, 'G04':  800e6, 'G05':  300e6,\n",
    "         'G06':   800e6, 'G07': 700e6, 'G08': 700e6, 'G09': 1000e6, 'G10': 1000e6}\n",
    "P_nom_with_comp = {'G01': 10000e6, 'G02': 700e6, 'G03': 800e6, 'G04':  800e6, 'G05':  300e6,\n",
    "                   'G06':   800e6, 'G07': 700e6, 'G08': 700e6, 'G09': 1000e6, 'G10': 1000e6,\n",
    "                   'Comp11': 100e6, 'Comp21': 100e6, 'Comp31': 100e6}\n",
    "P_nom_with_comp_and_vsg = {'G01': 10000e6, 'G02': 700e6, 'G04':  800e6, 'G05':  300e6,\n",
    "                           'G06':   800e6, 'G07': 700e6, 'G08': 700e6, 'G09': 1000e6, 'G10': 1000e6,\n",
    "                           'Comp11': 100e6, 'Comp21': 100e6, 'Comp31': 100e6, 'VSG03': 800e6}\n",
    "\n",
    "\n",
    "window_dur = 60\n",
    "window_step = 1\n",
    "var_names = network_parameters['var_names']\n",
    "data_mean = {var_name: x_train_mean[k] for k,var_name in enumerate(var_names)}\n",
    "data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "\n",
    "if area_measure == 'inertia':\n",
    "    measure_units = 's'\n",
    "elif area_measure == 'energy':\n",
    "    measure_units = r'GW$\\cdot$s'\n",
    "elif area_measure == 'momentum':\n",
    "    measure_units = r'GW$\\cdot$s$^2$'\n",
    "    \n",
    "stoch_load_bus_list = 'stoch_load_bus_' + '-'.join(map(str, stoch_load_bus_IDs))\n",
    "rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "\n",
    "abbrv = {'inertia': 'H', 'energy': 'E', 'momentum': 'M'}\n",
    "\n",
    "EXPERIMENTS = []\n",
    "\n",
    "db['window_dur'] = window_dur\n",
    "db['window_step'] = window_step\n",
    "db['var_names'] = var_names\n",
    "db['data_mean'] = data_mean\n",
    "db['data_std'] = data_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of momentum varying only the inertia of the generators\n",
    "`G03` has `type = 6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 3.83), ('G03', 3.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.83), ('G03', 4.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ])\n",
    "]\n",
    "\n",
    "data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "    area_inertia, exact, mean_prediction = \\\n",
    "    analyze_single_file_experiment(H_values, data_dir, var_names, data_mean, data_std,\n",
    "                                   window_dur, window_step, area_ID)\n",
    "\n",
    "N_blocks = len(H_values)\n",
    "block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                            N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                        prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                                       'momentum steps varying only generators inertia, G3 type=6'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of momentum varying only the inertia of the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 3.83), ('G03', 3.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.83), ('G03', 4.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ])\n",
    "]\n",
    "\n",
    "data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "    area_inertia, exact, mean_prediction = \\\n",
    "    analyze_single_file_experiment(H_values, data_dir, var_names, data_mean, data_std,\n",
    "                                   window_dur, window_step, area_ID,\n",
    "                                 data_file_suffix='ieee39_PF_stoch_loads_compensators_G3_type=2')\n",
    "\n",
    "N_blocks = len(H_values)\n",
    "block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                            N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                        prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                                       'momentum steps varying only generators inertia, G3 type=2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different combinations of inertia corresponding to the same area momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([700, 800, 100])\n",
    "H = np.array([4.33, 4.47, 0.1])\n",
    "print('M =', momentum(H,S))\n",
    "H = np.array([3.83, 4.9075, 0.1])\n",
    "print('M =', momentum(H,S))\n",
    "H = np.array([4.90142857, 3.97, 0.1])\n",
    "print('M =', momentum(H,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 3.83), ('G03', 4.907), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.901), ('G03', 3.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ])\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 3.53), ('G03', 5.17), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "#         ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ]),\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 5.244), ('G03', 3.67), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "#         ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ])\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 3.93), ('G03', 4.87), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "#         ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ]),\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 4.73), ('G03', 4.07), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "#         ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ])\n",
    "]\n",
    "\n",
    "data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "    area_inertia, exact, mean_prediction = \\\n",
    "    analyze_single_file_experiment(H_values, data_dir, var_names, data_mean, data_std,\n",
    "                                   window_dur, window_step, area_ID)\n",
    "N_blocks = len(H_values)\n",
    "block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                            N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                        prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                                       'fixed area momentum while varying generators inertia'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same steps of area momentum obtained in two different ways:\n",
    "Either by changing the inertia of the generators..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([700, 800, 100])\n",
    "H = np.array([4.33, 4.47, 0.1])\n",
    "print('M =', momentum(H,S))\n",
    "H = np.array([4.24150442, 4.84743363, 0.1])\n",
    "print('M =', momentum(H,S))\n",
    "H = np.array([4.39637168, 5.02442478, 0.1])\n",
    "print('M =', momentum(H,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.242), ('G03', 4.847), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.20),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.396), ('G03', 5.024), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ])\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 4.58), ('G03', 4.72), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.20),\n",
    "#         ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ]),\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 4.83), ('G03', 4.97), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "#         ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ])\n",
    "]\n",
    "\n",
    "data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "    area_inertia, exact, mean_prediction = \\\n",
    "    analyze_single_file_experiment(H_values, data_dir, var_names, data_mean, data_std,\n",
    "                                   window_dur, window_step, area_ID)\n",
    "\n",
    "N_blocks = len(H_values)\n",
    "block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                            N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                        prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                                       'increasing momentum varying generators inertia'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or by changing the inertia of the compensator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([700, 800, 100])\n",
    "H = np.array([4.33, 4.47, 0.1])\n",
    "print('M =', momentum(H,S))\n",
    "H = np.array([4.33, 4.47, 2.5])\n",
    "print('M =', momentum(H,S))\n",
    "H = np.array([4.33, 4.47, 5.0])\n",
    "print('M =', momentum(H,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.33), ('G03', 4.47), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.20),\n",
    "        ('Comp11', 2.5), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.33), ('G03', 4.47), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 5.0), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ])\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 4.33), ('G03', 4.47), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.20),\n",
    "#         ('Comp11', 4.0), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ]),\n",
    "#     OrderedDict([\n",
    "#         ('G01', 5.00), ('G02', 4.33), ('G03', 4.47), ('G04', 3.57), ('G05', 4.33),\n",
    "#         ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "#         ('Comp11', 8.0), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "#     ])\n",
    "]\n",
    "\n",
    "data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "    area_inertia, exact, mean_prediction = \\\n",
    "    analyze_single_file_experiment(H_values, data_dir, var_names, data_mean, data_std,\n",
    "                                   window_dur, window_step, area_ID)\n",
    "\n",
    "N_blocks = len(H_values)\n",
    "block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                            N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                        prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                                       'increasing momentum varying compensator inertia'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of momentum varying only the inertia of the generators\n",
    "The generator `G03` is split in 2, the first one (the original one) having `1-Pfrac` of the power and inertia, and the second one having `Pfrac` power and inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 3.83), ('G03', 3.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.83), ('G03', 4.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ])\n",
    "]\n",
    "\n",
    "for gen_type in 2, 6:\n",
    "    data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "        area_inertia, exact, mean_prediction = \\\n",
    "        analyze_single_file_experiment(H_values, data_dir, var_names, None, data_std,\n",
    "                                       window_dur, window_step, area_ID,\n",
    "                                       data_file_suffix='ieee39_PF_stoch_loads_compensators_' + \\\n",
    "                                           f'split_G3_type={gen_type}_Pfrac={Pfrac:.1f}')\n",
    "\n",
    "    N_blocks = len(H_values)\n",
    "    block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "    plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                                N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "    EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                            prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                                f'momentum steps varying only generators inertia, split G3 type={gen_type}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of momentum varying the inertia of one generator and one virtual synchronous generator\n",
    "The generator `G03` is replaced by a VSG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp_and_vsg,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 3.83), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1), ('VSG03', 3.97)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.83), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1), ('VSG03', 4.97)\n",
    "    ])\n",
    "]\n",
    "\n",
    "suffix = 'ieee39_PF_stoch_loads_compensators_vsg'\n",
    "for k,v in VSG_pars.items():\n",
    "    suffix += f'_{k}={v:.1f}'\n",
    "print(suffix)\n",
    "data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "    area_inertia, exact, mean_prediction = \\\n",
    "    analyze_single_file_experiment(H_values, data_dir, var_names, None, data_std,\n",
    "                                   window_dur, window_step, area_ID, data_file_suffix=suffix)\n",
    "\n",
    "N_blocks = len(H_values)\n",
    "block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                            N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                        prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                            'momentum steps varying inertia of G2 and VSG3, a VSG that replaces G3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of momentum varying the inertia of two generators and one virtual synchronous generator\n",
    "The VSG accounts for `Pfrac` of the power and inertia of the generator `G03`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_momentum(H,S):\n",
    "    sys.stdout.write('H = [')\n",
    "    for h in H:\n",
    "        sys.stdout.write(f'{h:.2f} ')\n",
    "    sys.stdout.write(f'] -> M = {momentum(H,S):.4f} GW.s2\\n')\n",
    "\n",
    "S = np.array([700, 800, 800, 100])\n",
    "H = np.array([4.33, 4.47*(1-Pfrac), 4.47*Pfrac, 0.1])\n",
    "print_momentum(H,S)\n",
    "H = np.array([3.83, 3.97*(1-Pfrac), 3.97*Pfrac, 0.1])\n",
    "print_momentum(H,S)\n",
    "H = np.array([4.83, 4.97*(1-Pfrac), 4.97*Pfrac, 0.1])\n",
    "print_momentum(H,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H_with_comp,\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 3.83), ('G03', 3.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G01', 5.00), ('G02', 4.83), ('G03', 4.97), ('G04', 3.57), ('G05', 4.33),\n",
    "        ('G06', 4.35), ('G07', 3.77), ('G08', 3.47), ('G09', 3.45), ('G10', 4.2),\n",
    "        ('Comp11', 0.1), ('Comp21', 0.1), ('Comp31', 0.1)\n",
    "    ])\n",
    "]\n",
    "\n",
    "data_time, data, data_normalized, prediction_time, prediction, \\\n",
    "    area_inertia, exact, mean_prediction = \\\n",
    "    analyze_single_file_experiment(H_values, data_dir, var_names, None, data_std,\n",
    "                                   window_dur, window_step, area_ID,\n",
    "                                   data_file_suffix='ieee39_PF_stoch_loads_compensators_split_vsg' + \\\n",
    "                                   f'_Pfrac={Pfrac:.1f}')\n",
    "\n",
    "N_blocks = len(H_values)\n",
    "block_dur = np.ceil(data_time[-1]) / N_blocks\n",
    "plot_single_file_experiment(prediction_time, prediction, exact, mean_prediction,\n",
    "                            N_blocks, block_dur, area_measure, measure_units)\n",
    "\n",
    "EXPERIMENTS.append(make_experiment_dict(H_values, data_time, data, data_normalized,\n",
    "                                        prediction_time, prediction, area_inertia, exact, mean_prediction,\n",
    "                                       'momentum steps varying inertia of G2, G3 and VSG3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before but with the generator `G03` subdivided in two parts, the second one modeled with either a type 2 or type 6 machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['experiments'] = EXPERIMENTS\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
