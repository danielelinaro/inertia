{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import welch#, periodogram\n",
    "import pandas as pd\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import read_area_values, load_data_slide\n",
    "from dlml.nn import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_IDs = [1, 2, 3]\n",
    "area_measure = 'momentum'\n",
    "H_G1 = 500\n",
    "stoch_load_bus_IDs = [3]\n",
    "rec_bus_IDs = [3, 14, 17]\n",
    "rec_bus_IDs = []\n",
    "D = 2\n",
    "DZA = 0\n",
    "\n",
    "experiments = collect_experiments(area_IDs, area_measure=area_measure, D=D, DZA=DZA, \\\n",
    "                                  stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=H_G1, \\\n",
    "                                  rec_bus_IDs=rec_bus_IDs, additional_tags=['ReLU_none'], \\\n",
    "                                  verbose=True)\n",
    "if experiments is None:\n",
    "    raise Exception('No experiment matches the tags')\n",
    "experiment_IDs = list(experiments.keys())\n",
    "experiment_ID = experiment_IDs[np.argmin([expt['val_loss'].min() for expt in experiments.values()])]\n",
    "MAPE = experiments[experiment_ID]['MAPE']\n",
    "if np.isscalar(MAPE):\n",
    "    MAPE_str = f'{MAPE:.3f}%'\n",
    "else:\n",
    "    MAPE_str = '[' + '%, '.join([f'{m:.3f}' for m in MAPE]) + '%]'\n",
    "loss = experiments[experiment_ID]['loss']\n",
    "val_loss = experiments[experiment_ID]['val_loss']\n",
    "batch_loss = experiments[experiment_ID]['batch_loss']\n",
    "tags = experiments[experiment_ID]['tags']\n",
    "print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE_str}).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = {'77bf2ad6d2ff4986bbf9e9ee547bd0c1': 26}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "network_parameters = pickle.load(open(experiments_path + experiment_ID \\\n",
    "                                      + '/parameters.pkl', 'rb'))\n",
    "epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "idx = np.argmin(val_loss) + 1\n",
    "if experiment_ID in offsets:\n",
    "    idx += offsets[experiment_ID]\n",
    "best_checkpoint = checkpoint_files[epochs.index(idx)]\n",
    "model = keras.models.load_model(best_checkpoint, compile=True)\n",
    "data_dirs = ['..' + os.path.sep +\n",
    "             os.path.sep.join([d for d in data_dir.split(os.path.sep) if '{}' not in d]) +\n",
    "             f'/H_G1_{H_G1}/stoch_load_bus_' + '-'.join(map(str, stoch_load_bus_IDs))\n",
    "             for data_dir in network_parameters['data_dirs']]\n",
    "# we need mean and standard deviation of the training set to normalize the data\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "ss = data_dirs[0].split(os.path.sep)\n",
    "data_dir = os.path.join(os.path.join(*ss[:3]), 'Hiskens', os.path.join(*ss[3:]))\n",
    "tmp = [re.findall('.*_bus', var_name)[0] for var_name in network_parameters['var_names']]\n",
    "var_names_fmt = list(OrderedDict({k + '{}': [] for k in tmp}).keys())\n",
    "if len(rec_bus_IDs) == 0:\n",
    "    rec_bus_IDs = list(np.unique([int(re.findall('\\d+', var_name)[0]) \\\n",
    "                                  for var_name in network_parameters['var_names']]))\n",
    "    rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "if not os.path.isdir(data_dir):\n",
    "    raise Exception(f'{data_dir}: no such directory')\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Data directory is {data_dir}.')\n",
    "print(f'Variable names: {var_names_fmt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_H = OrderedDict([\n",
    "    ('Pg30', H_G1), ('Pg31', 30.3), ('Pg32', 35.8), ('Pg33', 28.6), ('Pg34', 26),\n",
    "    ('Pg35', 34.8), ('Pg36', 26.4), ('Pg37', 24.3), ('Pg38', 34.5), ('Pg39', 42)\n",
    "])\n",
    "\n",
    "generators_areas_map = {\n",
    "    'default': [\n",
    "        ['Pg31', 'Pg32', 'Pg39'],\n",
    "        ['Pg33', 'Pg34', 'Pg35', 'Pg36'],\n",
    "        ['Pg37', 'Pg38'],\n",
    "        ['Pg30']\n",
    "    ],\n",
    "    'compensator': [\n",
    "        ['Pg31', 'Pg32', 'Pg39', 'Pg99'],\n",
    "        ['Pg33', 'Pg34', 'Pg35', 'Pg36'],\n",
    "        ['Pg37', 'Pg38'],\n",
    "        ['Pg30']\n",
    "    ]\n",
    "}\n",
    "\n",
    "P_nom = {gen_ID: 100e6 for gen_ID in default_H}\n",
    "\n",
    "window_dur = 60\n",
    "window_step = 1\n",
    "\n",
    "var_names = [var_name.format(bus_ID) for bus_ID in np.unique(rec_bus_IDs) for var_name in var_names_fmt]\n",
    "data_mean = {var_name: x_train_mean[k] for k,var_name in enumerate(var_names)}\n",
    "data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "\n",
    "if area_measure == 'inertia':\n",
    "    measure_units = 's'\n",
    "elif area_measure == 'energy':\n",
    "    measure_units = r'GW$\\cdot$s'\n",
    "elif area_measure == 'momentum':\n",
    "    measure_units = r'GW$\\cdot$s$^2$'\n",
    "    \n",
    "stoch_load_bus_list = 'stoch_load_bus_' + '-'.join(map(str, stoch_load_bus_IDs))\n",
    "rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "\n",
    "abbrv = {'inertia': 'H', 'energy': 'E', 'momentum': 'M'}\n",
    "\n",
    "figure_width, figure_height = 8.5, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H,\n",
    "    OrderedDict([\n",
    "        ('Pg30', H_G1), ('Pg31', 35), ('Pg32', 42), ('Pg33', 28.6), ('Pg34', 26),\n",
    "        ('Pg35', 34.8), ('Pg36', 26.4), ('Pg37', 24.3), ('Pg38', 34.5), ('Pg39', 46)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('Pg30', H_G1), ('Pg31', 30.3), ('Pg32', 35.8), ('Pg33', 32), ('Pg34', 30),\n",
    "        ('Pg35', 39), ('Pg36', 30), ('Pg37', 24.3), ('Pg38', 34.5), ('Pg39', 42)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('Pg30', H_G1), ('Pg31', 30.3), ('Pg32', 35.8), ('Pg33', 28.6), ('Pg34', 26),\n",
    "        ('Pg35', 34.8), ('Pg36', 26.4), ('Pg37', 32), ('Pg38', 43), ('Pg39', 42)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('Pg30', H_G1), ('Pg31', 35), ('Pg32', 42), ('Pg33', 32), ('Pg34', 30),\n",
    "        ('Pg35', 39), ('Pg36', 30), ('Pg37', 32), ('Pg38', 43), ('Pg39', 46)\n",
    "    ])\n",
    "]\n",
    "N_H = len(H_values)\n",
    "\n",
    "measure_exact = []\n",
    "data_normalized = []\n",
    "measure = []\n",
    "\n",
    "var_names = [var_name.format(bus_ID) for bus_ID in np.unique(rec_bus_IDs) for var_name in var_names_fmt]\n",
    "data_mean = {var_name: x_train_mean[k] for k,var_name in enumerate(var_names)}\n",
    "data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "\n",
    "for H in H_values:\n",
    "    data_file = data_dir + '/ieee39_' + '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "    _,_,v,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "    measure_exact.append([v[area_ID - 1] for area_ID in area_IDs])\n",
    "\n",
    "    t, _, data_norm, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                        var_names,\n",
    "                                                        data_mean,\n",
    "                                                        data_std,\n",
    "                                                        window_dur,\n",
    "                                                        window_step,\n",
    "                                                        add_omega_ref = False,\n",
    "                                                        verbose = True)\n",
    "    data_normalized.append(data_norm)\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    time, HH, _ = predict(model, data_sliding, window_step)\n",
    "    measure.append(HH)\n",
    "measure_exact = np.array(measure_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE = np.array([[np.nanmean(np.abs((measure_exact[i,j] - measure[i][:,j]) / measure_exact[i,j])) * 100 \\\n",
    "                   for j in range(3)] for i in range(N_H)])\n",
    "for i,row in enumerate(MAPE[1:]):\n",
    "    print(f'{i+1} & ' + ' & '.join(map(lambda v: f'{v:.2f}\\\\%', row)) + ' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 2\n",
    "cols = 2\n",
    "x_offset = 0.15\n",
    "x_border = 0.02\n",
    "x_space = 0.07\n",
    "y_offset = 0.16\n",
    "y_border = 0.05\n",
    "y_space = 0.07\n",
    "w = (1 - (x_offset + x_border + x_space * (cols - 1))) / cols\n",
    "h = (1 - (y_offset + y_border + y_space * (rows - 1))) / rows\n",
    "\n",
    "labels = 'ABCD'\n",
    "fig = plt.figure(figsize=(figure_width/2.54, figure_height/2.54))\n",
    "ax = [plt.axes([x_offset + j * (w + x_space), y_offset + i * (h + y_space), w, h]) \\\n",
    "     for i in range(rows-1, -1, -1) for j in range(cols)]\n",
    "cmap = plt.get_cmap('gray', 4)\n",
    "for i,a in enumerate(ax):\n",
    "    for j in range(3):\n",
    "        a.plot(time[[0,-1]] / 60, measure_exact[i+1,j] + np.zeros(2), '--', color=cmap(j), lw=1)\n",
    "        a.plot(time / 60, measure[i+1][:,j], color=cmap(j), lw=1.5, label=f'Area {j+1}')\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.set_ylim([0.15, 0.47])\n",
    "    a.set_xticks(np.r_[0 : 80 : 20])\n",
    "    a.set_yticks(np.r_[0.2 : 0.5 : 0.1])\n",
    "    if i > 1:\n",
    "        a.set_xlabel('Time [min]', fontsize=8)\n",
    "    else:\n",
    "        a.set_xticklabels([])\n",
    "    if i % 2 == 0:\n",
    "        a.set_ylabel(f'{area_measure.capitalize()} [{measure_units}]', fontsize=8)\n",
    "    else:\n",
    "        a.set_yticklabels([])\n",
    "    #a.grid(which='major', axis='y', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "    a.tick_params(axis='x', labelsize=8)\n",
    "    a.tick_params(axis='y', labelsize=8)\n",
    "    a.text(-12, 0.47, labels[i], fontsize=10)\n",
    "output_filename = f'IEEE39_areas{\"-\".join(map(str, area_IDs))}_H_G1={H_G1}_' + \\\n",
    "    f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_const_H_{experiment_ID[:6]}.pdf'\n",
    "fig.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step of measure with transient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = data_dir + '/ieee39_4_steps.h5'\n",
    "\n",
    "_,_,measure_exact,tstop = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "t, _, data_normalized, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                         var_names,\n",
    "                                                         None,\n",
    "                                                         data_std,\n",
    "                                                         window_dur,\n",
    "                                                         window_step,\n",
    "                                                         add_omega_ref = False,\n",
    "                                                         verbose = True)\n",
    "\n",
    "dt = np.diff(t[:2])[0]\n",
    "time, measure, _ = predict(model, data_sliding, window_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_blocks = tstop.size\n",
    "fig = plt.figure(figsize=(figure_width/2.54, figure_height/2.54))\n",
    "\n",
    "rows = 3\n",
    "cols = 1\n",
    "x_offset = 0.15\n",
    "x_border = 0.02\n",
    "x_space = 0.1\n",
    "y_offset = 0.15\n",
    "y_border = 0.02\n",
    "y_space = 0.05\n",
    "w = (1 - (x_offset + x_border + x_space * (cols - 1))) / cols\n",
    "h = (1 - (y_offset + y_border + y_space)) / rows\n",
    "\n",
    "ax = [\n",
    "    plt.axes([x_offset, y_offset + (rows-1) * h + y_space, w, h]),\n",
    "    plt.axes([x_offset, y_offset, w, h * (rows - 1)])\n",
    "]\n",
    "\n",
    "var_name = 'Vd_bus3'\n",
    "ax[0].plot(t / 60, data_normalized[var_name], color='k', lw=0.5)\n",
    "cmap = plt.get_cmap('gray', 4)\n",
    "for j in range(3):\n",
    "    for i in range(N_blocks):\n",
    "        if i == 0:\n",
    "            ax[1].plot([0, tstop[i]/60], measure_exact[j,i] + np.zeros(2), '--', color=cmap(j), lw=1)\n",
    "        else:\n",
    "            ax[1].plot([tstop[i-1]/60, tstop[i]/60], measure_exact[j,i] + np.zeros(2), '--', color=cmap(j), lw=1)\n",
    "    ax[1].plot(time/60, measure[:,j], color=cmap(j), lw=1, label=f'Area {j+1}')\n",
    "for a in ax:\n",
    "    a.grid(which='major', axis='y', lw=0.5, ls=':')\n",
    "    a.set_xlim([-2, 62])\n",
    "    a.tick_params(axis='x', labelsize=8)\n",
    "    a.tick_params(axis='y', labelsize=8)\n",
    "    a.set_xticks(np.r_[0 : (N_blocks+1) * 15  : 15])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "ax[0].set_ylabel(r'V$_{d,3}$')\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_yticks(np.r_[-4 : 5 : 2])\n",
    "ax[1].set_xlabel('Time [min]', fontsize=8)\n",
    "ax[1].set_ylabel(f'{area_measure.capitalize()} [{measure_units}]', fontsize=8)\n",
    "# ax[1].legend(loc='center left', fontsize=8)\n",
    "ax[1].legend(loc='upper left', bbox_to_anchor=(0.015, 0.62), fontsize=8)\n",
    "# fig.tight_layout()\n",
    "output_filename = f'IEEE39_areas{\"-\".join(map(str, area_IDs))}_H_G1={H_G1}_' + \\\n",
    "    f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_4_steps_H_{experiment_ID[:6]}.pdf'\n",
    "fig.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = np.r_[0 : 0.1 : 0.01]\n",
    "measure_exact = []\n",
    "data = []\n",
    "data_normalized = []\n",
    "measure = []\n",
    "\n",
    "var_names = [var_name.format(bus_ID) for bus_ID in np.unique(rec_bus_IDs) for var_name in var_names_fmt]\n",
    "data_mean = {var_name: x_train_mean[k] for k,var_name in enumerate(var_names)}\n",
    "data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "\n",
    "for l in LAMBDA:\n",
    "    data_file = data_dir + '/ieee39_' + '_'.join(map(lambda h: f'{h:.3f}', default_H.values())) + \\\n",
    "        f'_lambda={l:.3f}.h5'\n",
    "    _,_,v,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "    measure_exact.append([v[area_ID - 1] for area_ID in area_IDs])\n",
    "\n",
    "    t, dat, data_norm, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                        var_names,\n",
    "                                                        None,\n",
    "                                                        data_std,\n",
    "                                                        window_dur,\n",
    "                                                        window_step,\n",
    "                                                        add_omega_ref = False,\n",
    "                                                        verbose = True)\n",
    "    data.append(dat)\n",
    "    data_normalized.append(data_norm)\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    time, HH, _ = predict(model, data_sliding, window_step)\n",
    "    measure.append(HH)\n",
    "measure_exact = np.array(measure_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figure_width/2.54, 8/2.54))\n",
    "\n",
    "rows = 3\n",
    "cols = 1\n",
    "x_offset = 0.15\n",
    "x_border = 0.02\n",
    "x_space = 0.1\n",
    "y_offset = 0.12\n",
    "y_border = 0.3\n",
    "y_space = 0.05\n",
    "w = (1 - (x_offset + x_border + x_space * (cols - 1))) / cols\n",
    "h = (1 - (y_offset + y_border + y_space * (rows - 1))) / rows\n",
    "\n",
    "ax = [plt.axes([x_offset, y_offset + i * (h + y_space), w, h]) for i in range(rows-1, -1, -1)]\n",
    "\n",
    "y_offset = y_offset + rows * (h + y_space) + 0.07\n",
    "y_border = 0.02\n",
    "x_space = 0.05\n",
    "rows = 1\n",
    "cols = 3\n",
    "w = (1 - (x_offset + x_border + x_space * (cols - 1))) / cols\n",
    "h = (1 - (y_offset + y_border + y_space * (rows - 1))) / rows\n",
    "\n",
    "for i in range(cols):\n",
    "    ax.append(plt.axes([x_offset + i * (w + x_space), y_offset, w, h]))\n",
    "\n",
    "cmap = plt.get_cmap('gray', LAMBDA.size + 2)\n",
    "lim = [\n",
    "    [0.96, 1.01],\n",
    "    [0.96, 1.02],\n",
    "    [0.9, 1.7],\n",
    "    [955, 975],\n",
    "    [-4,4],\n",
    "    [0,0.5]\n",
    "]\n",
    "ticks = [\n",
    "    np.r_[0.97 : 1.01 : 0.015],\n",
    "    np.r_[0.97 : 1.02 : 0.015],\n",
    "    np.r_[1 : 1.7 : 0.2],\n",
    "    np.r_[955 : 980 : 10],\n",
    "    np.r_[-4 : 5 : 4],\n",
    "    lim[-1]\n",
    "]\n",
    "for i in range(3):\n",
    "    for j,l in enumerate(LAMBDA):\n",
    "        ax[i].plot(time / 60, measure[j][:,i] / measure_exact[0,i], \n",
    "               color=cmap(j), lw=1, label=r'$\\lambda={}$'.format(l))\n",
    "    ax[i].set_xlim([-1, 61])\n",
    "    ax[i].set_ylim(lim[i])\n",
    "    ax[i].set_xticks(np.r_[0 : 70 : 20])\n",
    "    if i != 2:\n",
    "        ax[i].set_xticklabels([])\n",
    "    ax[i].set_yticks(ticks[i])\n",
    "    ax[i].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "\n",
    "var_name = 'Vd_bus3'\n",
    "\n",
    "for i in range(LAMBDA.size):\n",
    "    n,edges = np.histogram(data[i][var_name], bins=101, density=True)\n",
    "    ax[3].plot(edges[:-1] + np.diff(edges[:2])[0] / 2, n, color=cmap(i), lw=1)\n",
    "    n,edges = np.histogram(data_normalized[i][var_name], bins=25, range=(-4,4), density=True)\n",
    "    ax[4].plot(edges[:-1] + np.diff(edges[:2])[0] / 2, n, color=cmap(i), lw=1)\n",
    "    f,Pxx = welch(data_normalized[i][var_name], 1/dt)\n",
    "    ax[5].plot(f, Pxx, color=cmap(i), lw=1)\n",
    "\n",
    "for i in range(3,6):\n",
    "    ax[i].set_xlim(lim[i])\n",
    "    ax[i].set_xticks(ticks[i])\n",
    "    ax[i].set_yticks([])\n",
    "\n",
    "ax[3].set_xlabel('Voltage [V]', fontsize=8)\n",
    "ax[4].set_xlabel('Norm. V', fontsize=8)\n",
    "ax[5].set_xlabel('Frequency [Hz]', fontsize=8)\n",
    "\n",
    "ax[3].set_ylabel('Distribution', fontsize=8)\n",
    "ax[5].set_ylabel('PSD', fontsize=8)\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.tick_params(axis='x', labelsize=8)\n",
    "    a.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "ax[1].set_ylabel(f'Normalized {area_measure}', fontsize=8)\n",
    "ax[2].set_xlabel('Time [min]', fontsize=8)\n",
    "output_filename = f'IEEE39_areas{\"-\".join(map(str, area_IDs))}_H_G1={H_G1}_' + \\\n",
    "    f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_overload_{experiment_ID[:6]}.pdf'\n",
    "fig.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinusoidal variation of the loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = data_dir + '/ieee39_sin_loads_500.000_30.300_35.800_28.600_26.000_34.800_26.400_24.300_34.500_42.000.h5'\n",
    "\n",
    "_,_,measure_exact,tstop = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "t, _, data_normalized, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                         var_names,\n",
    "                                                         None,\n",
    "                                                         data_std,\n",
    "                                                         window_dur,\n",
    "                                                         window_step,\n",
    "                                                         add_omega_ref = False,\n",
    "                                                         verbose = True)\n",
    "\n",
    "dt = np.diff(t[:2])[0]\n",
    "time, measure, _ = predict(model, data_sliding, window_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1)\n",
    "cmap = plt.get_cmap('gray',4)\n",
    "for i in range(3):\n",
    "    ax.plot(time[[0,-1]] / (60 * 60), measure_exact[i] + np.zeros(2), '--', lw=1, color=cmap(i))\n",
    "    ax.plot(time / (60 * 60), measure[:,i], color=cmap(i), lw=1, label=f'Area {i+1}')\n",
    "ax.legend(loc='center left')\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.set_xlabel('Time [hour]')\n",
    "ax.set_ylabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a 4th generator (a compensator) added in area 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_nom['Pg99'] = 100e6\n",
    "\n",
    "H_values = [\n",
    "    default_H,\n",
    "    OrderedDict([\n",
    "        ('Pg30', H_G1), ('Pg31', 30.3), ('Pg32', 35.8), ('Pg33', 28.6), ('Pg34', 26),\n",
    "        ('Pg35', 34.8), ('Pg36', 26.4), ('Pg37', 24.3), ('Pg38', 34.5), ('Pg39', 42),\n",
    "        ('Pg99', 10)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('Pg30', H_G1), ('Pg31', 30.3), ('Pg32', 35.8), ('Pg33', 28.6), ('Pg34', 26),\n",
    "        ('Pg35', 34.8), ('Pg36', 26.4), ('Pg37', 24.3), ('Pg38', 34.5), ('Pg39', 42),\n",
    "        ('Pg99', 20)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('Pg30', H_G1), ('Pg31', 30.3), ('Pg32', 35.8), ('Pg33', 28.6), ('Pg34', 26),\n",
    "        ('Pg35', 34.8), ('Pg36', 26.4), ('Pg37', 24.3), ('Pg38', 34.5), ('Pg39', 42),\n",
    "        ('Pg99', 40)\n",
    "    ])\n",
    "]\n",
    "N_H = len(H_values)\n",
    "\n",
    "data_normalized = []\n",
    "measure = []\n",
    "measure_exact = []\n",
    "for H in H_values:\n",
    "    if 'Pg99' in H:\n",
    "        data_file = data_dir + '/ieee39_compensator_' + '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['compensator'], P_nom, area_measure)\n",
    "    else:\n",
    "        data_file = data_dir + '/ieee39_' + '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "\n",
    "    measure_exact.append([v[area_ID - 1] for area_ID in area_IDs])\n",
    "\n",
    "    t, _, data_norm, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                        var_names,\n",
    "                                                        None,\n",
    "                                                        data_std,\n",
    "                                                        window_dur,\n",
    "                                                        window_step,\n",
    "                                                        add_omega_ref = False,\n",
    "                                                        verbose = True)\n",
    "    data_normalized.append(data_norm)\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    time, pred, _ = predict(model, data_sliding, window_step)\n",
    "    measure.append(pred)\n",
    "measure_exact = np.array(measure_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.nanmean(m, axis=0) for m in measure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3, 1, sharex=True, figsize=(9,9))\n",
    "cmap = plt.get_cmap('jet', N_H+1)\n",
    "for i,a in enumerate(ax):\n",
    "    for j in range(N_H):\n",
    "        if i == 0:\n",
    "            a.plot(time[[0,-1]] / 60, measure_exact[j,i] + np.zeros(2), '--', color=cmap(j), lw=1)\n",
    "        elif j == 0:\n",
    "            a.plot(time[[0,-1]] / 60, measure_exact[j,i] + np.zeros(2), '--', color='k', lw=1)\n",
    "        a.plot(time / 60, measure[j][:,i], color=cmap(j), lw=1.5)\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.set_ylabel(f'Area {i+1}')\n",
    "ax[-1].set_xlabel('Time [min]')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_vars = len(var_names_fmt)\n",
    "fig = plt.figure(figsize=(9, n_vars * 3))\n",
    "gs = fig.add_gridspec(n_vars+1, 4)\n",
    "ax = []\n",
    "for i in range(n_vars):\n",
    "    ax.append([fig.add_subplot(gs[i, :3]), fig.add_subplot(gs[i, 3])])\n",
    "ax.append([fig.add_subplot(gs[-1, :])])\n",
    "\n",
    "col = [[.2,.2,.2], [.8,0,0], [0,.7,0], [0,0,.7]]\n",
    "\n",
    "bus_ID = rec_bus_IDs[0]\n",
    "\n",
    "idx = t < 60\n",
    "\n",
    "dm = np.max(measure_exact) - np.min(measure_exact)\n",
    "ylim = [np.min(measure_exact) - dm / 2, np.max(measure_exact) + dm / 2]\n",
    "\n",
    "for i in range(N_H):\n",
    "    for j,var_name in enumerate(var_names_fmt):\n",
    "        key = var_name.format(bus_ID)\n",
    "        value = data_normalized[i][key]\n",
    "        n,edges = np.histogram(value, bins=25, range=(-4,4), density=True)\n",
    "        ax[j][0].plot(t[idx], value[idx], color=col[i], lw=1, \\\n",
    "                      label=f'{abbrv[area_measure]} = {measure_exact[i]:.2f} {measure_units}')\n",
    "        ax[j][1].plot(n, edges[:-1] + np.diff(edges[:2])[0] / 2, color=col[i], lw=1)\n",
    "        for a in ax[j]:\n",
    "            a.set_ylim([-4,4])\n",
    "        ax[j][0].set_ylabel(key)\n",
    "    ax[-1][0].plot(time / 60, measure[i], color=col[i], lw=1)\n",
    "    ax[-1][0].plot(time[[0,-1]] / 60, measure_exact[i] + np.zeros(2), '--', color=col[i], lw=1)\n",
    "    ax[-1][0].set_ylim(ylim)\n",
    "    ax[-1][0].set_xlabel('Time [min]')\n",
    "\n",
    "for aa in ax:\n",
    "    for side in 'right','top':\n",
    "        for a in aa:\n",
    "            a.spines[side].set_visible(False)\n",
    "for i in range(n_vars):\n",
    "    for j in range(2):\n",
    "        ax[i][j].grid(axis='y', lw=0.5, linestyle=':')\n",
    "\n",
    "ax[0][0].legend(loc='best')\n",
    "ax[-1][0].set_xlim([0,60])\n",
    "ax[-1][0].set_ylabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "ax[-2][0].set_xlabel('Time [s]')\n",
    "ax[-2][1].set_xlabel('Fraction')\n",
    "fig.tight_layout()\n",
    "output_filename = f'IEEE39_area{area_ID}_H_G1={H_G1}_' + \\\n",
    "    f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_compensator.pdf'\n",
    "fig.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
