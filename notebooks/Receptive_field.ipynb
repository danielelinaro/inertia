{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.nn import compute_receptive_field\n",
    "\n",
    "tf.random.set_seed(5061983)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple model\n",
    "\n",
    "This CNN will be used to compute effective receptive field size and effective stride. Note that using an activation function or a max pooling layer (instead of the average pooling used below) might invalidate the first assertion in the last cell. To understand why, consider for instance the case in which we are using a max pooling layer: when we change the value of a sample inside the receptive field, this change will not be propagated to the downstream layer if the changed value is not the maximum in the pooling window. As a consequence, the assertion will fail, even though the computed effective receptive field size is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4096, 1)]         0         \n",
      "                                                                 \n",
      " conv_1 (Conv1D)             (None, 4093, 2)           8         \n",
      "                                                                 \n",
      " avg_pool_1 (AveragePooling1  (None, 2046, 2)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_2 (Conv1D)             (None, 1020, 4)           64        \n",
      "                                                                 \n",
      " avg_pool_2 (AveragePooling1  (None, 255, 4)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_3 (Conv1D)             (None, 60, 8)             512       \n",
      "                                                                 \n",
      " avg_pool_3 (AveragePooling1  (None, 7, 8)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 56)                0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 16)                912       \n",
      "                                                                 \n",
      " fc_2 (Dense)                (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,513\n",
      "Trainable params: 1,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 11:45:49.693901: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "N_samples = 4096\n",
    "filters = [2, 4, 8]\n",
    "kernel_size = [4, 8, 16]\n",
    "kernel_stride = [1, 2, 4]\n",
    "pool_size = [2, 4, 8]\n",
    "pool_stride = [2, 4, 8]\n",
    "fc_units = [16, 1]\n",
    "kernel_init = 'glorot_uniform'\n",
    "use_bias = False\n",
    "bias_init = 'ones' if use_bias else 'zeros'\n",
    "input_layer = keras.layers.Input(shape=(N_samples,1), name='input', dtype=tf.float32)\n",
    "L = input_layer\n",
    "for i,(n,ksz,kstrd,psz,pstrd) in enumerate(zip(filters, kernel_size, kernel_stride,\n",
    "                                               pool_size, pool_stride)):\n",
    "    L = keras.layers.Conv1D(filters=n,\n",
    "                            kernel_size=ksz,\n",
    "                            strides=kstrd,\n",
    "                            activation=None,\n",
    "                            padding='valid',\n",
    "                            kernel_initializer=kernel_init,\n",
    "                            use_bias=use_bias,\n",
    "                            bias_initializer=bias_init,\n",
    "                            name=f'conv_{i+1}')(L)\n",
    "#     L = keras.layers.ReLU(name=f'relu_{i+1}')(L)\n",
    "    if psz is not None:\n",
    "        L = keras.layers.AveragePooling1D(pool_size=psz,\n",
    "                                          strides=pstrd,\n",
    "                                          name=f'avg_pool_{i+1}')(L)\n",
    "#         L = keras.layers.MaxPooling1D(pool_size=psz, name=f'max_pool_{i+1}')(L)\n",
    "L = keras.layers.Flatten(name='flatten')(L)\n",
    "for i,n in enumerate(fc_units):\n",
    "    L = keras.layers.Dense(units=n,\n",
    "                           activation='ReLU',\n",
    "                           kernel_initializer='ones',\n",
    "                           name=f'fc_{i+1}')(L)\n",
    "model = keras.Model(inputs=[input_layer], outputs=[L])\n",
    "multi_output_model = keras.Model(inputs=[model.layers[0].input],\n",
    "                                 outputs=[layer.output for layer in model.layers[1:]])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute effective receptive field size and effective stride for each layer in the model\n",
    "\n",
    "We stop at the `Flatten` layer: RF size and stride make no sense for fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective receptive field size:\n",
      "0. input ............... 1\n",
      "1. conv_1 .............. 4\n",
      "2. avg_pool_1 .......... 5\n",
      "3. conv_2 .............. 19\n",
      "4. avg_pool_2 .......... 31\n",
      "5. conv_3 .............. 271\n",
      "6. avg_pool_3 .......... 719\n",
      "\n",
      "Effective stride:\n",
      "0. input ............... 1\n",
      "1. conv_1 .............. 1\n",
      "2. avg_pool_1 .......... 2\n",
      "3. conv_2 .............. 4\n",
      "4. avg_pool_2 .......... 16\n",
      "5. conv_3 .............. 64\n",
      "6. avg_pool_3 .......... 512\n"
     ]
    }
   ],
   "source": [
    "effective_RF_size,effective_stride = compute_receptive_field(model, stop_layer='flatten')\n",
    "print('Effective receptive field size:')\n",
    "for i,(k,v) in enumerate(effective_RF_size.items()):\n",
    "    print(f'{i}. {k} ' + '.' * (20 - len(k)) + ' {:d}'.format(v))\n",
    "print()\n",
    "print('Effective stride:')\n",
    "for i,(k,v) in enumerate(effective_stride.items()):\n",
    "    print(f'{i}. {k} ' + '.' * (20 - len(k)) + ' {:d}'.format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that the computed values are correct\n",
    "\n",
    "To do so, we change one sample inside and one outside the effective receptive field: we expect that the output will change only when the modified sample is inside the RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'avg_pool_3'\n",
    "for layer_id,layer in enumerate(model.layers):\n",
    "    if layer.name == layer_name:\n",
    "        break\n",
    "_, N_neurons, N_kernels = model.layers[layer_id].output.shape\n",
    "neuron = np.random.randint(0, N_neurons)\n",
    "kernel = np.random.randint(0, N_kernels)\n",
    "x = np.random.uniform(size=(1, N_samples))\n",
    "x_mod_1 = x.copy()\n",
    "x_mod_2 = x.copy()\n",
    "\n",
    "# change the last value inside the receptive field\n",
    "x_mod_1[0, effective_stride[layer_name] * neuron + effective_RF_size[layer_name] - 1] *= 2\n",
    "\n",
    "# change the first value outside the receptive field\n",
    "x_mod_2[0, effective_stride[layer_name] * neuron + effective_RF_size[layer_name]] *= 2\n",
    "\n",
    "multi_y = multi_output_model(x)\n",
    "multi_y_mod_1 = multi_output_model(x_mod_1)\n",
    "multi_y_mod_2 = multi_output_model(x_mod_2)\n",
    "assert multi_y[layer_id-1][0, neuron, kernel] != multi_y_mod_1[layer_id-1][0, neuron, kernel]\n",
    "assert multi_y[layer_id-1][0, neuron, kernel] == multi_y_mod_2[layer_id-1][0, neuron, kernel]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python-3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
