{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from comet_ml.api import API, APIExperiment\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import load_data_areas\n",
    "from dlml.nn import compute_receptive_field, compute_correlations\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_print(msg, fd=sys.stdout):\n",
    "    fd.write(msg)\n",
    "    fd.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that we have the model requested by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_ID = '98475b819ecb4d569646d7e1467d7c9c'\n",
    "experiment_ID = '474d2016e33b441889ce8b17531487cb'\n",
    "experiments_path = '../experiments/neural_network'\n",
    "model_dir = os.path.join(experiments_path, experiment_ID)\n",
    "if not os.path.isdir(model_dir):\n",
    "    raise Exception(f'{model_dir}: no such directory')\n",
    "network_parameters = pickle.load(open(os.path.join(model_dir, 'parameters.pkl'), 'rb'))\n",
    "low_high = network_parameters['low_high'] if 'low_high' in network_parameters else False\n",
    "binary_classification = network_parameters['loss_function']['name'].lower() == 'binarycrossentropy'\n",
    "if 'use_fft' in network_parameters and network_parameters['use_fft']:\n",
    "    raise Exception('This script assumes that the input data be in the time domain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some info about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "experiment = api.get_experiment('danielelinaro', 'inertia', experiment_ID)\n",
    "sys.stdout.write(f'Getting metrics for experiment {experiment_ID[:6]}... ')\n",
    "sys.stdout.flush()\n",
    "metrics = experiment.get_metrics()\n",
    "sys.stdout.write('done.\\n')\n",
    "val_loss = []\n",
    "for m in metrics:\n",
    "    if m['metricName'] == 'val_loss':\n",
    "        val_loss.append(float(m['metricValue']))\n",
    "    elif m['metricName'] == 'mape_prediction':\n",
    "        MAPE = float(m['metricValue'])\n",
    "val_loss = np.array(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pooling_type = network_parameters['model_arch']['pooling_type']\n",
    "except:\n",
    "    pooling_type = ''\n",
    "checkpoint_path = os.path.join(model_dir, 'checkpoints')\n",
    "checkpoint_files = glob.glob(checkpoint_path + '/*.h5')\n",
    "try:\n",
    "    epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "except:\n",
    "    best_checkpoint = checkpoint_files[-1]\n",
    "try:\n",
    "    model = keras.models.load_model(best_checkpoint)\n",
    "    custom_objects = None\n",
    "except:\n",
    "    if pooling_type == 'downsample':\n",
    "        from dlml.nn import DownSampling1D\n",
    "        custom_objects = {'DownSampling1D': DownSampling1D}\n",
    "    elif pooling_type == 'spectral':\n",
    "        from dlml.nn import SpectralPooling\n",
    "        custom_objects = {'SpectralPooling': SpectralPooling}\n",
    "    elif pooling_type == 'argmax':\n",
    "        from dlml.nn import MaxPooling1DWithArgmax\n",
    "        custom_objects = {'MaxPooling1DWithArgmax': MaxPooling1DWithArgmax}\n",
    "    with keras.utils.custom_object_scope(custom_objects):\n",
    "        model = keras.models.load_model(best_checkpoint)\n",
    "\n",
    "if pooling_type == 'argmax':\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, MaxPooling1DWithArgmax):\n",
    "            print(f'Setting store_argmax = True for layer \"{layer.name}\".')\n",
    "            layer.store_argmax = True\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "var_names = network_parameters['var_names']\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Variable names: {var_names}')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute effective receptive field size and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_layer = None\n",
    "if stop_layer is None:\n",
    "    effective_RF_size,effective_stride = compute_receptive_field(model, stop_layer=keras.layers.Flatten,\n",
    "                                                                 include_stop_layer=False)\n",
    "else:\n",
    "    effective_RF_size,effective_stride = compute_receptive_field(model, stop_layer=stop_layer,\n",
    "                                                                 include_stop_layer=True)\n",
    "print('Effective receptive field size:')\n",
    "for i,(k,v) in enumerate(effective_RF_size.items()):\n",
    "    print(f'{i}. {k} ' + '.' * (20 - len(k)) + ' {:d}'.format(v))\n",
    "print()\n",
    "print('Effective stride:')\n",
    "for i,(k,v) in enumerate(effective_stride.items()):\n",
    "    print(f'{i}. {k} ' + '.' * (20 - len(k)) + ' {:d}'.format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = 'test'\n",
    "data_dirs = []\n",
    "for area_ID,data_dir in zip(network_parameters['area_IDs'], network_parameters['data_dirs']):\n",
    "    data_dirs.append(os.path.join('..', data_dir.format(area_ID)))\n",
    "data_dir = data_dirs[0]\n",
    "data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                      network_parameters['generators_areas_map'][:1],\n",
    "                      network_parameters['generators_Pnom'],\n",
    "                      network_parameters['area_measure'],\n",
    "                      trial_dur=network_parameters['trial_duration'],\n",
    "                      max_block_size=1000,\n",
    "                      use_tf=False, add_omega_ref=True,\n",
    "                      use_fft=False)\n",
    "\n",
    "t = ret[0]\n",
    "X = [(ret[1][set_name][i] - m) / s for i,(m,s) in enumerate(zip(x_train_mean, x_train_std))]\n",
    "y = ret[2][set_name]\n",
    "ds = 10\n",
    "X[0] = X[0][::ds,:]\n",
    "y = y[::ds]\n",
    "\n",
    "if binary_classification:\n",
    "    IDX = [np.where(y < y.mean())[0], np.where(y > y.mean())[0]]\n",
    "    n_mom_values = len(IDX)\n",
    "    y[IDX[0]] = 0\n",
    "    y[IDX[1]] = 1\n",
    "    classes = [np.round(tf.keras.activations.sigmoid(model.predict(X[0][jdx]))) for jdx in IDX]\n",
    "    _,_,accuracy = model.evaluate(tf.squeeze(X[0]), y, verbose=0)\n",
    "    print(f'Prediction accuracy (with optimized weights): {accuracy*100:.2f}%.')\n",
    "else:\n",
    "    if low_high:\n",
    "        below,_ = np.where(y < y.mean())\n",
    "        above,_ = np.where(y > y.mean())\n",
    "        y[below] = y[below].mean()\n",
    "        y[above] = y[above].mean()\n",
    "    ### Predict the momentum using the model\n",
    "    IDX = [np.where(y == mom)[0] for mom in np.unique(y)]\n",
    "    n_mom_values = len(IDX)\n",
    "    momentum = [np.squeeze(model.predict(X[0][jdx])) for jdx in IDX]\n",
    "    mean_momentum = [m.mean() for m in momentum]\n",
    "    stddev_momentum = [m.std() for m in momentum]\n",
    "    print('Mean momentum (with optimized weights):', mean_momentum)\n",
    "    print(' Std momentum (with optimized weights):', stddev_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the trained model\n",
    "This initializes the cloned model with new random weights and will be used in the\n",
    "following as a control for the correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinit_model = model.__class__.from_config(model.get_config(), custom_objects)\n",
    "if custom_objects is not None:\n",
    "    # we have some subclassed layers\n",
    "    for i in range(len(model.layers)):\n",
    "        reinit_model.layers[i]._name = model.layers[i].name\n",
    "if binary_classification:\n",
    "    reinit_model.compile(metrics=['binary_crossentropy', 'acc'])\n",
    "    reinit_classes = [np.round(tf.keras.activations.sigmoid(reinit_model.predict(X[0][jdx]))) for jdx in IDX]\n",
    "    _,_,reinit_accuracy = reinit_model.evaluate(tf.squeeze(X[0]), y, verbose=0)\n",
    "    print(f'Prediction accuracy (with random weights): {reinit_accuracy*100:.2f}%.')\n",
    "else:\n",
    "    reinit_momentum = [np.squeeze(reinit_model.predict(X[0][jdx])) for jdx in IDX]\n",
    "    mean_reinit_momentum = [m.mean() for m in reinit_momentum]\n",
    "    stddev_reinit_momentum = [m.std() for m in reinit_momentum]\n",
    "    print('Mean momentum (with random weights):', mean_reinit_momentum)\n",
    "    print(' Std momentum (with random weights):', stddev_reinit_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model with as many outputs as there are convolutional or pooling layers\n",
    "\n",
    "Also, build a control model with the same (multiple-output) architecture as the previous one but random weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers \\\n",
    "           if layer.name in effective_RF_size.keys() and not isinstance(layer, keras.layers.InputLayer)]\n",
    "multi_output_model = keras.Model(inputs=model.inputs, outputs=outputs)\n",
    "\n",
    "ctrl_outputs = [layer.output for layer in reinit_model.layers \\\n",
    "                if layer.name in effective_RF_size.keys() and not isinstance(layer, keras.layers.InputLayer)]\n",
    "ctrl_model = keras.Model(inputs=reinit_model.inputs, outputs=ctrl_outputs)\n",
    "print(f'The model has {len(outputs)} outputs, corresponding to the following layers:')\n",
    "for i,layer in enumerate(multi_output_model.layers):\n",
    "    if not isinstance(layer, keras.layers.InputLayer):\n",
    "        print(f'    {i}. {layer.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations in the actual model\n",
    "Define some variables used here and for the control model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = 'log'\n",
    "N_bands = 20\n",
    "filter_order = 6\n",
    "verbose = True\n",
    "\n",
    "dt = np.diff(t[:2])[0]\n",
    "fs = np.round(1/dt)\n",
    "if spacing == 'lin':\n",
    "    edges = np.linspace(0.05, 0.5/dt, N_bands+1)\n",
    "else:\n",
    "    edges = np.logspace(np.log10(0.05), np.log10(0.5/dt), N_bands+1)\n",
    "edges_ctrl = edges\n",
    "bands = [[a,b] for a,b in zip(edges[:-1], edges[1:])]\n",
    "N_bands = len(bands)\n",
    "_, N_neurons, N_filters = multi_output_model.layers[-1].output.shape\n",
    "N_trials = X[0].shape[0]\n",
    "output_file = os.path.join(model_dir,\n",
    "                           f'correlations_{experiment_ID[:6]}_{N_bands}-bands_' + \\\n",
    "                           f'{N_filters}-filters_{N_neurons}-neurons_{N_trials}-trials_' + \\\n",
    "                           f'{filter_order}-butter_{multi_output_model.layers[-1].name}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R,p = compute_correlations(multi_output_model,\n",
    "                           X[0],\n",
    "                           fs,\n",
    "                           bands,\n",
    "                           effective_RF_size,\n",
    "                           effective_stride,\n",
    "                           filter_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the input in various frequency bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trials, N_samples = X[0].shape\n",
    "N_bands = len(bands)\n",
    "X_filt = np.zeros((N_bands, N_trials, N_samples))\n",
    "if verbose: my_print(f'Filtering the input in {N_bands} frequency bands... ')\n",
    "for i in tqdm(range(N_bands)):\n",
    "    b,a = butter(filter_order//2, bands[i], 'bandpass', fs=fs)\n",
    "    X_filt[i,:,:] = filtfilt(b, a, X[0])\n",
    "if verbose: print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the envelope of the filtered signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose: my_print(f'Computing the envelope of the filtered signals... ')\n",
    "X_filt_envel = np.abs(hilbert(X_filt))\n",
    "if verbose: print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "fig,ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "ax.plot(t, X[0][i,:], 'k', lw=1)\n",
    "cmap = plt.get_cmap('viridis', N_bands)\n",
    "for j in range(0, N_bands, 2):\n",
    "    ax.plot(t, X_filt[j,i,:], '-.', color=cmap(j), lw=1)\n",
    "    ax.plot(t, X_filt_envel[j,i,:], '-', color=cmap(j), lw=1)\n",
    "ax.set_xlim([10, 20])\n",
    "ax.set_ylim([-1, 2])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the outputs of the last layer before the fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = multi_output_model.layers[-1].name\n",
    "if verbose: my_print(f'Computing the output of layer \"{layer_name}\"... ')\n",
    "multi_Y = multi_output_model(X)\n",
    "if verbose: print('done.')\n",
    "Y = multi_Y[-1].numpy() if isinstance(multi_Y, list) else multi_Y\n",
    "_, N_neurons, N_filters = Y.shape\n",
    "if verbose: print(f'Layer \"{layer_name}\" has {N_filters} filters, each with {N_neurons} neurons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose: my_print(f'Computing the output of layer \"{layer_name}\"... ')\n",
    "multi_Y = ctrl_model(X)\n",
    "if verbose: print('done.')\n",
    "Y_ctrl = multi_Y[-1].numpy() if isinstance(multi_Y, list) else multi_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filt_envel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the mean squared envelope for each receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_sz, RF_str = effective_RF_size[layer_name], effective_stride[layer_name]\n",
    "if verbose: print(f'The effective RF size and stride of layer \"{layer_name}\" are {RF_sz} and {RF_str} respectively.')\n",
    "mean_squared_envel = np.zeros((N_trials, N_bands, N_neurons))\n",
    "mean_envel = np.zeros((N_trials, N_bands, N_neurons))\n",
    "if verbose: my_print('Computing the mean squared envelope for each receptive field... ')\n",
    "for i in range(N_neurons):\n",
    "    start, stop = i * RF_str, i * RF_str + RF_sz\n",
    "    X_filt_envel_sub = X_filt_envel[:, :, start:stop]\n",
    "    mean_squared_envel[:,:,i] = np.mean(X_filt_envel_sub ** 2, axis=2).T\n",
    "    mean_envel[:,:,i] = np.mean(X_filt_envel_sub, axis=2).T\n",
    "if verbose: print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the correlation using `pearsonr`\n",
    "For each frequency band, compute the correlation between mean squared envelope\n",
    "of the input (to each receptive field) and the output of each neuron in the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "libcorr = ctypes.CDLL(os.path.join('..', 'libcorr.so'))\n",
    "libcorr.pearsonr.argtypes = [ctypes.POINTER(ctypes.c_double),\n",
    "                             ctypes.POINTER(ctypes.c_double),\n",
    "                             ctypes.c_size_t,\n",
    "                             ctypes.POINTER(ctypes.c_double),\n",
    "                             ctypes.POINTER(ctypes.c_double)]\n",
    "pointer = ctypes.POINTER(ctypes.c_double)\n",
    "R_pointer = pointer(ctypes.c_double(0.0))\n",
    "p_pointer = pointer(ctypes.c_double(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pearsonr(x, y):\n",
    "    x = x.copy().astype(np.float64)\n",
    "    y = y.copy()\n",
    "    x_pointer = x.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
    "    y_pointer = y.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
    "    libcorr.pearsonr(x_pointer, y_pointer, x.size, R_pointer, p_pointer)\n",
    "    return R_pointer[0], p_pointer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols = 5,4\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(2*cols, 2*rows))\n",
    "cmap = plt.get_cmap('viridis', N_filters)\n",
    "for j in range(N_bands):\n",
    "    a = ax[j//cols][j%cols]\n",
    "    for i in range(N_trials):\n",
    "        for k in range(N_filters):\n",
    "            a.plot(Y[i,:,k], mean_squared_envel[i,j,:], 'o', color=cmap(k), ms=2)\n",
    "        break\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.zeros((N_trials, N_bands, N_filters))\n",
    "p = np.zeros((N_trials, N_bands, N_filters))\n",
    "if verbose: print('Computing the correlations tensor...')\n",
    "for i in tqdm(range(N_trials)):\n",
    "    for j in range(N_bands):\n",
    "        for k in range(N_filters):\n",
    "            R[i,j,k], p[i,j,k] = my_pearsonr(Y[i,:,k], mean_squared_envel[i,j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(R)\n",
    "i = idx // (N_bands * N_filters)\n",
    "j = (idx - i * (N_bands * N_filters)) // N_filters\n",
    "k = (idx - i * (N_bands * N_filters)) % N_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I,J,K = np.where((R>0.495) & (R<0.505) & (p<0.05))\n",
    "n = 5\n",
    "i,j,k = I[n],J[n],K[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y[i,:,k], mean_squared_envel[i,j,:], 'o', color='k', ms=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('jet', N_bands)\n",
    "rows, cols = N_bands // 4, 4\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(3*cols, 1.5*rows), sharex=True, sharey=True)\n",
    "trial = 0\n",
    "neuron = 30\n",
    "start, stop = neuron * RF_str, neuron * RF_str + RF_sz\n",
    "for k in range(N_bands):\n",
    "    i,j = k//cols, k%cols\n",
    "    ax[i,j].plot(t, X[0][trial, :], color=[.6,.6,.6], lw=0.5)\n",
    "    ax[i,j].plot(t, X_filt[k, trial, :].T, color='k', lw=1)\n",
    "    ax[i,j].plot(t, X_filt_envel[k, trial, :].T, color=cmap(k), lw=1)\n",
    "#     ax[i,j].plot(t[[start,stop]], mean_envel[trial, k, neuron] + np.zeros(2), color=cmap(k), lw=4)\n",
    "    ax[i,j].plot(t[[start,stop]], mean_squared_envel[trial, k, neuron] + np.zeros(2), color=cmap(k), lw=4)\n",
    "ax[0,0].set_ylim([-1, 1])\n",
    "xlim, ylim = ax[0,0].get_xlim(), ax[0,0].get_ylim()\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = i * cols + j\n",
    "        ax[i,j].text(xlim[1], ylim[1], f'{bands[k][0]:.4f} - {bands[k][1]:.4f}',\n",
    "                     ha='right', va='top', color='m')\n",
    "        for side in 'right','top':\n",
    "            ax[i,j].spines[side].set_visible(False)\n",
    "    ax[i,0].set_ylabel('Norm. V')\n",
    "for i in range(cols):\n",
    "    ax[-1,i].set_xlabel('Time [s]')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('jet', N_bands)\n",
    "rows, cols = N_bands // 4, 4\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(3*cols, 1.5*rows), sharex=True, sharey=True)\n",
    "# fig,ax = plt.subplots(rows, cols, figsize=(3*cols, 1.5*rows))\n",
    "filt = 0\n",
    "ms = 5\n",
    "R, p = np.zeros((rows, cols)), np.zeros((rows, cols))\n",
    "R_ctrl, p_ctrl = np.zeros((rows, cols)), np.zeros((rows, cols))\n",
    "for k in range(N_bands):\n",
    "    i,j = k//cols, k%cols\n",
    "    R[i,j],p[i,j] = pearsonr(Y[trial,:,filt], mean_squared_envel[trial,k,:])\n",
    "    R_ctrl[i,j],p_ctrl[i,j] = pearsonr(Y_ctrl[trial,:,filt], mean_squared_envel[trial,k,:])\n",
    "    ax[i,j].plot(mean_squared_envel[trial, k, :], Y_ctrl[trial, :, filt], 'o', color='k',\n",
    "                 markersize=ms-1, markerfacecolor='w')\n",
    "    ax[i,j].plot(mean_squared_envel[trial, k, :], Y[trial, :, filt], 'o', color=cmap(k),\n",
    "                 markersize=ms)\n",
    "xlim, ylim = ax[0,0].get_xlim(), ax[0,0].get_ylim()\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = i * cols + j\n",
    "        ax[i,j].text(xlim[1], ylim[1], f'{bands[k][0]:.4f} - {bands[k][1]:.4f}',\n",
    "                     ha='right', va='top', color='m')\n",
    "        col = 'k' if p[i][j] < 0.05 else 'r'\n",
    "        ax[i,j].text(xlim[1], ylim[1]-np.diff(ylim)/5, f'{R[i][j]:.3f}, {p[i][j]:.2f}',\n",
    "                     ha='right', va='top', color=col)\n",
    "        col = 'k' if p_ctrl[i][j] < 0.05 else 'r'\n",
    "        ax[i,j].text(xlim[1], ylim[1]-np.diff(ylim)/5*2, f'{R_ctrl[i][j]:.3f}, {p_ctrl[i][j]:.2f}',\n",
    "                     ha='right', va='top', color=col)\n",
    "        for side in 'right','top':\n",
    "            ax[i,j].spines[side].set_visible(False)\n",
    "    ax[i,0].set_ylabel('Layer output')\n",
    "for i in range(cols):\n",
    "    ax[-1,i].set_xlabel('Mean squared envel.')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
