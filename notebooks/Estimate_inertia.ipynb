{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from comet_ml.api import API, APIExperiment\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from deep_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "1. D=2, DZA=1: damping, super-wide dead-band\n",
    "1. D=2, DZA=36e-3/60: damping, realistic dead-band\n",
    "1. D=0, DZA=0.36/60: no damping, wide dead-band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A couple of functions used in the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_files, var_names, data_mean = None, data_std = None, window_dur = 60, window_step = 10, verbose=False):\n",
    "    fids = [tables.open_file(data_file, 'r') for data_file in data_files]\n",
    "    n_files = len(data_files)\n",
    "    time = [fids[0].root.time.read()]\n",
    "    for i in range(1, n_files):\n",
    "        time.append(fids[i].root.time.read() + time[i-1][-1])\n",
    "    time = np.concatenate(time)\n",
    "    N_samples = time.size\n",
    "    data = {var_name: np.concatenate([fid.root[var_name] for fid in fids]) for var_name in var_names}\n",
    "    if data_mean is None:\n",
    "        data_mean = {var_name: np.mean(data[var_name]) for var_name in var_names}\n",
    "        data_std = {var_name: np.std(data[var_name]) for var_name in var_names}\n",
    "    data_normalized = {var_name: (data[var_name] - data_mean[var_name]) / data_std[var_name] for var_name in var_names}\n",
    "    params = fids[0].root.parameters.read()\n",
    "    dt = 1 / params['frand'][0]\n",
    "    window_size = int(window_dur / dt)\n",
    "    if verbose:\n",
    "        print('Window size: {:d} samples'.format(window_size))\n",
    "    data_sliding = {}\n",
    "    indexes = {}\n",
    "    for var_name in var_names:\n",
    "        data_sliding[var_name], indexes[var_name] = slide_window(data_normalized[var_name],\n",
    "                                                                  window_size,\n",
    "                                                                  window_step=window_step)\n",
    "    if verbose:\n",
    "        print('Number of trials: {:d}'.format(data_sliding[var_names[0]].shape[0]))\n",
    "\n",
    "    for fid in fids:\n",
    "        fid.close()\n",
    "    \n",
    "    return time, data, data_normalized, data_sliding, indexes\n",
    "\n",
    "\n",
    "def predict(data_sliding, model, window_step, dt, rolling_length=50):\n",
    "    var_names = data_sliding.keys()\n",
    "    if len(model.inputs) == 2:\n",
    "        x = {var_name: tf.constant(data_sliding[var_name], dtype=tf.float32) for var_name in var_names}\n",
    "    elif len(model.inputs) == 1 and len(data_sliding.keys()) == 2:\n",
    "        x = tf.constant(list(data_sliding.values()), dtype=tf.float32)\n",
    "        x = tf.transpose(x, perm=(1,2,0))\n",
    "    else:\n",
    "        x = tf.constant(data_sliding[var_names[0]], dtype=tf.float32)\n",
    "    y = np.squeeze(model.predict(x))\n",
    "    H = pd.DataFrame(data = {'inertia': y}).rolling(rolling_length).mean().to_numpy()\n",
    "    time = np.arange(H.size) * window_step * dt\n",
    "    return time, H, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### D = 2  DZA = 60\n",
    "# no ReLU\n",
    "# experiment_ID = 'f0dc559c19584ecb82668b0f585819e8' # MAPE = 0.54%\n",
    "# ReLU after convolution\n",
    "experiment_ID = '2bfabe9a6a7d46c389fec10fb198bfed'  # MAPE = 0.50%\n",
    "# ReLU after pooling\n",
    "# experiment_ID = 'f9b54681f58f4bf3a417a86646e8f57e'  # MAPE = 0.65%\n",
    "# ReLU after pooling - no Pe\n",
    "#experiment_ID = '465ab6a9d3af45048d7d31b84c5ee68b'\n",
    "#experiment_ID = 'd7f30fef5806435897e97f27606fa30a'\n",
    "# no ReLU - 2D convolution\n",
    "# experiment_ID = '67dd7c399e1d4b18a0a78fc1bcc589c6'  # MAPE = 0.81%\n",
    "\n",
    "### D = 2  DZA = 0.036\n",
    "# no ReLU\n",
    "# experiment_ID = '62c738aa78494601be167e9cdfeb788f'  # MAPE = 0.75%\n",
    "# experiment_ID = 'a40cb482442046cc8d69df5b1b6b0469'  # MAPE = 0.82%\n",
    "# ReLU after convolution\n",
    "# experiment_ID = '22616aa16c484eaf9c0fde653a4c9989'  # MAPE = 0.89%\n",
    "# ReLU after pooling\n",
    "\n",
    "### D = 0  DZA = 0.36\n",
    "# no ReLU\n",
    "# experiment_ID = 'e44fa1f69054480baa2d0ca890c82e9e'  # MAPE = 0.82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "network_parameters = pickle.load(open(experiments_path + experiment_ID \\\n",
    "                                      + '/parameters.pkl', 'rb'))\n",
    "val_loss = [float(file[:-3].split('-')[-1]) for file in checkpoint_files]\n",
    "best_checkpoint = checkpoint_files[np.argmin(val_loss)]\n",
    "model = keras.models.load_model(best_checkpoint, compile=True)\n",
    "data_dir = '../' + network_parameters['data_dir']\n",
    "# we need mean and standard deviation of the training set to normalize the data\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "if not os.path.isdir(data_dir):\n",
    "    data_dir = '../data/var_H_G1/' + os.path.split(data_dir)[-1]\n",
    "print('Loaded network from {}.'.format(best_checkpoint))\n",
    "print('Data directory is {}.'.format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_api = API(api_key = os.environ['COMET_ML_API_KEY'])\n",
    "experiments = comet_api.get(workspace='danielelinaro', project_name='inertia')\n",
    "for experiment in experiments:\n",
    "    if experiment.id == experiment_ID:\n",
    "        metrics = experiment.get_metrics()\n",
    "        for m in metrics:\n",
    "            if m['metricName'] == 'mape_prediction':\n",
    "                mape = float(m['metricValue'])\n",
    "                break\n",
    "        break\n",
    "print(f'Experiment {experiment_ID[:9]} has a MAPE of {mape:.2f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=False, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step of inertia\n",
    "1. H steps **instantaneously** from 3.5 to 3.8\n",
    "1. **omega** and **Pe** of the first generator used for the estimation\n",
    "1. two simulations joined together (i.e., **no transient** during the step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_dur = 60\n",
    "window_step = 10\n",
    "H_values = [3.5, 3.8]\n",
    "data_files = [f'{data_dir}/H_{h:.3f}.h5' for h in H_values]\n",
    "gen_id = 1\n",
    "var_names = [f'omega_G{gen_id}', f'Pe_G{gen_id}']\n",
    "if gen_id == 1:\n",
    "    data_mean = {var_name: x_train_mean[i] for i,var_name in enumerate(var_names)}\n",
    "    data_std = {var_name: x_train_std[i] for i,var_name in enumerate(var_names)}\n",
    "else:\n",
    "    data_mean = None\n",
    "    data_std = None\n",
    "t, data, data_normalized, data_sliding, _ = load_data(data_files,\n",
    "                                                      var_names,\n",
    "                                                      data_mean,\n",
    "                                                      data_std,\n",
    "                                                      window_dur,\n",
    "                                                      window_step,\n",
    "                                                      verbose=True)\n",
    "dt = np.diff(t[:2])[0]\n",
    "time, H, _ = predict(data_sliding, model, window_step, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 3, figsize=(14,4))\n",
    "ax[0].plot(t, data_normalized[var_names[0]], 'k', lw=1)\n",
    "ax[0].plot([3600, 3600], ax[0].get_ylim(), '--', lw=2, color=[.6,.6,.6])\n",
    "ax[1].plot(t, data_normalized[var_names[1]], 'r', lw=1)\n",
    "ax[1].plot([3600, 3600], ax[0].get_ylim(), '--', lw=2, color=[.6,.6,.6])\n",
    "ax[2].plot([0, 3600], H_values[0] + np.zeros(2), 'r:', lw=3)\n",
    "ax[2].plot([3600, 7200], H_values[1] + np.zeros(2), 'r:', lw=3, label='Real')\n",
    "ax[2].plot(time, H, 'k', lw=1, label='Estimated')\n",
    "\n",
    "ax[2].legend(loc='lower right')\n",
    "ax[0].set_ylabel(r'$\\omega_{\\mathrm{G}_1}$')\n",
    "ax[1].set_ylabel(r'$Pe_{\\mathrm{G}_1}$')\n",
    "ax[2].set_ylabel('Inertia')\n",
    "for a in ax:\n",
    "    a.set_xlabel('Time [s]')\n",
    "    if a != ax[2]:\n",
    "        a.set_xlim([3300, 3900])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ramp of inertia\n",
    "H increases **gradually** from 3.5 to 6.5 in 100 seconds (from t = 3550s to t=3650s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_dur = 60\n",
    "window_step = 10\n",
    "H_values = [3.5, 6.5]\n",
    "data_file = f'{data_dir}/H_{H_values[0]:.3f}_{H_values[1]:.3f}.h5'\n",
    "gen_id = 1\n",
    "var_names = [f'omega_G{gen_id}', f'Pe_G{gen_id}']\n",
    "if gen_id == 1:\n",
    "    data_mean = {var_name: x_train_mean[i] for i,var_name in enumerate(var_names)}\n",
    "    data_std = {var_name: x_train_std[i] for i,var_name in enumerate(var_names)}\n",
    "else:\n",
    "    data_mean = None\n",
    "    data_std = None\n",
    "t, data, data_normalized, data_sliding, _ = load_data([data_file],\n",
    "                                                      var_names,\n",
    "                                                      data_mean,\n",
    "                                                      data_std,\n",
    "                                                      window_dur,\n",
    "                                                      window_step,\n",
    "                                                      verbose=True)\n",
    "dt = np.diff(t[:2])[0]\n",
    "time, H, _ = predict(data_sliding, model, window_step, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 3, figsize=(14,4))\n",
    "ax[0].plot(t, data_normalized[var_names[0]], 'k', lw=1)\n",
    "ax[1].plot(t, data_normalized[var_names[1]], 'r', lw=1)\n",
    "ax[2].plot([0, 3550, 3650, 7200], [H_values[0], H_values[0], H_values[1], H_values[1]], 'r:', lw=3, label='Real')\n",
    "ax[2].plot(time, H, 'k', lw=1, label='Estimated')\n",
    "\n",
    "ax[2].legend(loc='lower right')\n",
    "ax[0].set_ylabel(r'$\\omega_{\\mathrm{G}_1}$')\n",
    "ax[1].set_ylabel(r'$Pe_{\\mathrm{G}_1}$')\n",
    "ax[2].set_ylabel('Inertia')\n",
    "for a in ax:\n",
    "    a.set_xlabel('Time [s]')\n",
    "    if a != ax[2]:\n",
    "        a.set_xlim([3500, 3700])\n",
    "    else:\n",
    "        a.set_xlim([3000, 4000])\n",
    "        a.set_ylim([3,7])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
