{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, FuncNorm\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FixedLocator, NullLocator, FixedFormatter\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.data import load_data_areas\n",
    "\n",
    "fontsize = 8\n",
    "lw = 0.75\n",
    "\n",
    "matplotlib.rc('font', **{'family': 'Times New Roman', 'size': fontsize})\n",
    "matplotlib.rc('font', **{'size': fontsize})\n",
    "matplotlib.rc('axes', **{'linewidth': 0.75, 'labelsize': fontsize})\n",
    "matplotlib.rc('xtick', **{'labelsize': fontsize})\n",
    "matplotlib.rc('ytick', **{'labelsize': fontsize})\n",
    "matplotlib.rc('xtick.major', **{'width': lw, 'size':3})\n",
    "matplotlib.rc('ytick.major', **{'width': lw, 'size':3})\n",
    "matplotlib.rc('ytick.minor', **{'width': lw, 'size':1.5})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aca8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_data_files(data_dir, set_name, grid_sorted=True, verbose=False):\n",
    "    momentum = lambda H, S, fn=60: 2 * H@S / fn * 1e-3\n",
    "    S = np.array([700., 800., 100.])\n",
    "    files = sorted(glob.glob(os.path.join(data_dir, f'*_{set_name}_set.h5')))\n",
    "    n_files = len(files)\n",
    "    N = int(np.sqrt(n_files))\n",
    "    files = [[files[i*N + j] for j in range(N)] for i in range(N)]\n",
    "    i,j = 0,0\n",
    "    sorted_files = []\n",
    "    while len(sorted_files) < n_files:\n",
    "        try:\n",
    "            sorted_files.append(files[i][j])\n",
    "            if verbose:\n",
    "                H = list(map(float, re.findall('\\d.\\d+', os.path.basename(sorted_files[-1]))))\n",
    "                H_G2 = H[1]\n",
    "                H_G3 = H[2]\n",
    "                H_Comp11 = H[-3]\n",
    "                print('({},{}): {:.4f}'.format(i, j, momentum(np.array([H_G2, H_G3, H_Comp11]), S)))\n",
    "        except:\n",
    "            pass\n",
    "        if i == 0:\n",
    "            i,j = j+1, 0\n",
    "        else:\n",
    "            i,j = i-1, j+1\n",
    "    return sorted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26874675",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_comp = np.array([0.1, 1., 2., 2.5, 3., 4., 5., 6.])\n",
    "N_H = len(H_comp)\n",
    "data_dirs = [\n",
    "    '../data/IEEE39/converted_from_PowerFactory/all_stoch_loads/var_H_area_1_comp_grid/' + \\\n",
    "    f'coarse_H_comp11_{H:.1f}' for H in H_comp]\n",
    "set_name = 'training'\n",
    "data_files = [list_data_files(data_dir, set_name) for data_dir in data_dirs]\n",
    "offset = 0\n",
    "IDX = []\n",
    "for files in data_files:\n",
    "    IDX.append(offset + np.arange(len(files)))\n",
    "    offset += len(files)\n",
    "data_files = [f for files in data_files for f in files]\n",
    "n_data_files = len(data_files)\n",
    "print(f'Found {n_data_files} data files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "buses = 3, #14, 17, 39\n",
    "N_buses = len(buses)\n",
    "var_names = [f'Vd_bus{bus}' for bus in buses]\n",
    "generators_areas_map = [\n",
    "    [\"G02\", \"G03\", \"Comp11\"],\n",
    "    [\"G04\", \"G05\", \"G06\", \"G07\", \"Comp21\"],\n",
    "    [\"G08\", \"G09\", \"G10\", \"Comp31\"],\n",
    "    [\"G01\"]\n",
    "]\n",
    "generators_Pnom = {\n",
    "    \"G01\": 10000e6, \"G02\": 700e6, \"G03\": 800e6, \"G04\":  800e6, \"G05\":  300e6,\n",
    "    \"G06\":   800e6, \"G07\": 700e6, \"G08\": 700e6, \"G09\": 1000e6, \"G10\": 1000e6,\n",
    "    \"Comp11\": 100e6, \"Comp21\": 100e6, \"Comp31\": 100e6\n",
    "}\n",
    "area_measure = 'momentum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_block_size = 100\n",
    "cutoff = 0.1\n",
    "force = True\n",
    "filename = f'spectra_compensators_buses={\"-\".join(map(str,buses))}_cutoff={cutoff:.02f}_blocks={max_block_size}'\n",
    "if not os.path.isfile(filename + '.npz') or force:\n",
    "    ret_fft = load_data_areas({set_name: data_files},\n",
    "                              var_names,\n",
    "                              generators_areas_map[:1],\n",
    "                              generators_Pnom,\n",
    "                              area_measure,\n",
    "                              trial_dur=60,\n",
    "                              max_block_size=max_block_size,\n",
    "                              use_tf=False, add_omega_ref=True,\n",
    "                              use_fft=True,\n",
    "                              Wn=cutoff, filter_order=8, btype='hp')\n",
    "    F = ret_fft[0]\n",
    "    Xf = ret_fft[1][set_name]\n",
    "    y = np.squeeze(ret_fft[2][set_name])\n",
    "    block_size = Xf[0].shape[0] // n_data_files\n",
    "    print(f'Block size: {block_size}.')\n",
    "    Xfm = np.array([[Xf[var_idx, j*block_size : (j+1)*block_size, :].mean(axis=0)\n",
    "                     for j in range(n_data_files)] for var_idx in range(N_buses)])\n",
    "    ym = y[::block_size]\n",
    "    \n",
    "    Fpeak = np.zeros((N_buses, N_H))\n",
    "    jdx, = np.where(F > 3.)\n",
    "    for i,bus in enumerate(buses):\n",
    "        for j,idx in enumerate(IDX):\n",
    "            m = Xfm[i, idx, :].mean(axis=0)\n",
    "            kdx = np.argmax(m[jdx])\n",
    "            Fpeak[i,j] = F[jdx[kdx]]\n",
    "        \n",
    "    np.savez_compressed(filename + '.npz', max_block_size=max_block_size, block_size=block_size,\n",
    "                        F=F, Xfm=Xfm, ym=ym, cutoff=cutoff, buses=buses, var_names=var_names,\n",
    "                        data_files=data_files, n_data_files=n_data_files, data_dirs=data_dirs,\n",
    "                        set_name=set_name, H_comp=H_comp, Fpeak=Fpeak, IDX=IDX)\n",
    "else:\n",
    "    data = np.load(filename + '.npz')\n",
    "    for key in data.files:\n",
    "        globals()[key] = data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_fft = Xfm.min(axis=(1,2))\n",
    "max_fft = Xfm.max(axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_names = 'summer', 'winter', 'cool', 'jet', 'Greens', 'Blues', 'PuRd', 'BuPu'\n",
    "cmaps = [plt.get_cmap(name, len(IDX[i])) for i,name in enumerate(cmap_names)]\n",
    "rows,cols = 1,1\n",
    "w,h = 6,4\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(cols*w, rows*h), squeeze=False)\n",
    "for k,bus in enumerate(buses):\n",
    "    i,j = k//cols, k%cols\n",
    "    for n,(cmap,idx) in enumerate(zip(cmaps,IDX)):\n",
    "        for m in idx:\n",
    "            if m == idx[-1]:\n",
    "                lbl = 'H_comp = {:.1f} s'.format(H_comp[n])\n",
    "            else:\n",
    "                lbl = None\n",
    "            ax[i][j].semilogx(F, 20*np.log10(Xfm[k, m, :]), lw=1, color=cmap(m-idx[0]), label=lbl)\n",
    "    for side in 'right','top':\n",
    "        ax[i][j].spines[side].set_visible(False)\n",
    "    ax[i][j].grid(which='major', axis='both', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "ax[i][j].legend(loc='lower left', frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ad773",
   "metadata": {},
   "outputs": [],
   "source": [
    "_forward = lambda x: 20 * np.log10(x)\n",
    "_inverse = lambda y: 10 ** (y/20)\n",
    "ticks = np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20])\n",
    "cmap = plt.cm.YlGnBu_r\n",
    "rows,cols = 1,1\n",
    "w,h = 4,1\n",
    "fig,ax = plt.subplots(rows*N_H, cols, figsize=(cols*w, rows*h*N_H), sharex=True, squeeze=False)\n",
    "for r in range(rows):\n",
    "    for j in range(cols):\n",
    "        for k,idx in enumerate(IDX):\n",
    "            i = r*N_H + k\n",
    "            norm = FuncNorm((_forward, _inverse), vmin=min_fft[r*cols+j], vmax=max_fft[r*cols+j])\n",
    "            X,Y = np.meshgrid(F, ym[idx])\n",
    "            ax[i][j].pcolor(X, Y, Xfm[r*cols+j, idx, :], cmap=cmap, norm=norm)\n",
    "            ax[i][j].set_xscale('log')\n",
    "            ax[i][j].set_xlim(ticks[[0,-1]] + np.array([0,1]))\n",
    "            ax[i][j].xaxis.set_major_locator(FixedLocator(ticks))\n",
    "            ax[i][j].xaxis.set_minor_locator(NullLocator())\n",
    "            ax[i][j].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "            ax[i][j].set_ylim([Y.min(), Y.max()])\n",
    "            ax[i][j].set_yticks([Y.min(), Y.max()])\n",
    "            for side in 'right','top':\n",
    "                ax[i][j].spines[side].set_visible(False)\n",
    "        break\n",
    "    break\n",
    "ax[0][0].set_xlim([cutoff, F[-1]])\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
