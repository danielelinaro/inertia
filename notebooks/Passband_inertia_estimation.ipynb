{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import butter, filtfilt\n",
    "# from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import dtw\n",
    "# import umap\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import read_area_values, load_data_areas, load_data_slide\n",
    "from dlml.nn import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36871b",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f123e00",
   "metadata": {},
   "source": [
    "area_ID = 1\n",
    "area_measure = 'momentum'\n",
    "stoch_load_bus_IDs = []\n",
    "rec_bus_IDs = [3]\n",
    "H_G1, D, DZA = None, None, None # 500, 2, 0\n",
    "additional_tags = ['ReLU_none', 'converted_from_PowerFactory', 'all_stoch_loads', 'data_subset']\n",
    "missing_tags = []\n",
    "use_FFT = True\n",
    "if use_FFT:\n",
    "    additional_tags.append('fft')\n",
    "else:\n",
    "    missing_tags.append('fft')\n",
    "# experiments = collect_experiments(area_ID, area_measure=area_measure, D=D, DZA=DZA, \\\n",
    "#                                   stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=H_G1, \\\n",
    "#                                   rec_bus_IDs=rec_bus_IDs, additional_tags=additional_tags, \\\n",
    "#                                   missing_tags=missing_tags, verbose=True)\n",
    "# experiment_IDs = list(experiments.keys())\n",
    "# experiment_ID = experiment_IDs[np.argmin([expt['val_loss'].min() for expt in experiments.values()])]\n",
    "# experiment_ID = experiment_IDs[np.argmin([expt['MAPE'] for expt in experiments.values()])]\n",
    "# MAPE = experiments[experiment_ID]['MAPE']\n",
    "# loss = experiments[experiment_ID]['loss']\n",
    "# val_loss = experiments[experiment_ID]['val_loss']\n",
    "# batch_loss = experiments[experiment_ID]['batch_loss']\n",
    "# tags = experiments[experiment_ID]['tags']\n",
    "# print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE:.4f}%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on frequency data, 2 output values\n",
    "# experiment_ID = '9ea493c789b542bf979c51a6031f4044'\n",
    "# training on frequency data, 4 output values\n",
    "experiment_ID = 'f6d9a03f1cfe450288e9cb86da94235f'\n",
    "# training on time data, 2 output values\n",
    "# experiment_ID = '034a1edb0797475b985f0e1335dab383'\n",
    "# training on time data, 4 output values\n",
    "# experiment_ID = 'b346a89d384c4db2ba4058a2c83c4f12'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0a7fe",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81320651",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "network_parameters = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'parameters.pkl'), 'rb'))\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "try:\n",
    "    epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "except:\n",
    "    best_checkpoint = checkpoint_files[-1]\n",
    "model = keras.models.load_model(best_checkpoint)\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "try:\n",
    "    x_train_min = network_parameters['x_train_min']\n",
    "    x_train_max = network_parameters['x_train_max']\n",
    "except:\n",
    "    pass\n",
    "var_names = network_parameters['var_names']\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Variable names: {var_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e540f",
   "metadata": {},
   "source": [
    "#### Plot the model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f8316",
   "metadata": {},
   "source": [
    "#### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08887b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = 'test'\n",
    "use_fft = network_parameters['use_fft'] if 'use_fft' in network_parameters else False\n",
    "data_dirs = []\n",
    "for area_ID,data_dir in zip(network_parameters['area_IDs'], network_parameters['data_dirs']):\n",
    "    data_dirs.append(data_dir.format(area_ID))\n",
    "data_dir = os.path.join('..', data_dirs[0])\n",
    "data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))[:3]\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=100,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=use_fft)\n",
    "y = ret[2][set_name]\n",
    "X = [[(ret[1][set_name][i] - m) / (M - m) for i,(m,M) in enumerate(zip(x_train_min, x_train_max))]]\n",
    "F = ret[0]\n",
    "\n",
    "# load the same file(s) filtered in different bands\n",
    "bands = [[0.1, 0.4], [0.4, 0.9], [0.9, 2], [2, 10]]\n",
    "btypes =  ['bp', 'bp', 'bp', 'bp']\n",
    "filter_orders = [6, 10, 10, 10]\n",
    "for band,btype,order in zip(bands, btypes, filter_orders):\n",
    "    ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                            network_parameters['generators_areas_map'][:1],\n",
    "                            network_parameters['generators_Pnom'],\n",
    "                            network_parameters['area_measure'],\n",
    "                            trial_dur=network_parameters['trial_duration'],\n",
    "                            max_block_size=100,\n",
    "                            use_tf=False, add_omega_ref=True,\n",
    "                            use_fft=use_fft, btype=btype, Wn=band, filter_order=order)\n",
    "    X.append([(ret[1][set_name][i] - m) / (M - m) for i,(m,M) in enumerate(zip(x_train_min, x_train_max))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd7e90",
   "metadata": {},
   "source": [
    "#### Read the exact values of momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_momentum = []\n",
    "for data_file in data_files:\n",
    "    _,_,v,_ = read_area_values(data_file,\n",
    "                               network_parameters['generators_areas_map'],\n",
    "                               network_parameters['generators_Pnom'],\n",
    "                               'momentum')\n",
    "    exact_momentum.append(v[0])\n",
    "exact_momentum = np.array(exact_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f46974",
   "metadata": {},
   "source": [
    "#### Predict the momentum using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [np.where(y == mom)[0] for mom in np.unique(y)]\n",
    "n_mom_values = len(idx)\n",
    "momentum = [[np.squeeze(model.predict(x[0][jdx])) for jdx in idx] for x in X]\n",
    "mean_momentum = [[m.mean() for m in mom] for mom in momentum]\n",
    "stddev_momentum = [[m.std() for m in mom] for mom in momentum]\n",
    "print('Mean momentum:', mean_momentum)\n",
    "# print(' Std momentum:', stddev_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4263c",
   "metadata": {},
   "source": [
    "#### Plot the spectra of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8366a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('jet', len(X))\n",
    "fig,ax = plt.subplots(1, n_mom_values, figsize=(5*n_mom_values,4), sharex=True, sharey=True)\n",
    "if n_mom_values == 1:\n",
    "    ax = [ax]\n",
    "for i in range(n_mom_values):\n",
    "    for j in range(len(X)):\n",
    "        mean = X[j][0][idx[i]].mean(axis=0)\n",
    "        stddev = X[j][0][idx[i]].std(axis=0)\n",
    "        ci = 1.96 * stddev / np.sqrt(idx[i].size)\n",
    "        if j == 0:\n",
    "            col = 'k'\n",
    "        else:\n",
    "            col = cmap(j)\n",
    "        ax[i].fill_between(F, mean + ci, mean - ci, color=col)\n",
    "    #ax[i].set_xscale('log')\n",
    "    for side in 'right','top':\n",
    "        ax[i].spines[side].set_visible(False)\n",
    "    ax[i].grid(which='major', axis='both', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "    ax[i].set_xlabel('Frequency [Hz]')\n",
    "ax[0].set_ylabel('Normalized FFT')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76797ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "ms = 8\n",
    "ax.plot(exact_momentum, exact_momentum, '--', color=[1,.5,.5], lw=10, label='Exact')\n",
    "for i,mom in enumerate(mean_momentum):\n",
    "    if i == 0:\n",
    "        ax.plot(exact_momentum, mom, 'ko-', lw=2, markersize=ms,\n",
    "                markerfacecolor='w', markeredgewidth=2, label='Full spectrum')\n",
    "    else:\n",
    "        ax.plot(exact_momentum, mom, 'o-', color=cmap(i), lw=2, markersize=ms,\n",
    "                markerfacecolor='w', markeredgewidth=2)\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel(r'Exact momentum [GW$\\cdot$s$^2$]')\n",
    "ax.set_ylabel(r'Estimated momentum [GW$\\cdot$s$^2$]')\n",
    "ax.grid(which='major', axis='both', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
