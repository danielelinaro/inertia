{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "from tqdm import tqdm\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import read_area_values, load_data_areas, load_data_slide\n",
    "from dlml.nn import predict, DownSampling1D, SpectralPooling, MaxPooling1DWithArgmax, compute_receptive_field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36871b",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b90255",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ID = 1\n",
    "area_measure = 'momentum'\n",
    "stoch_load_bus_IDs = []\n",
    "rec_bus_IDs = [3]\n",
    "H_G1, D, DZA = None, None, None # 500, 2, 0\n",
    "additional_tags = ['ReLU_none', 'converted_from_PowerFactory', 'all_stoch_loads', 'data_subset']\n",
    "missing_tags = []\n",
    "use_FFT = False\n",
    "if use_FFT:\n",
    "    additional_tags.append('fft')\n",
    "else:\n",
    "    missing_tags.append('fft')\n",
    "pooling_type = ''\n",
    "if pooling_type is not None and pooling_type != '':\n",
    "    additional_tags.append(pooling_type + '_pooling')\n",
    "\n",
    "# training on frequency data, 2 output values\n",
    "# experiment_ID = '9ea493c789b542bf979c51a6031f4044'\n",
    "# training on frequency data, 4 output values\n",
    "# experiment_ID = 'f6d9a03f1cfe450288e9cb86da94235f'\n",
    "# training on time series data, 2 output values\n",
    "experiment_ID = '034a1edb0797475b985f0e1335dab383'\n",
    "# training on time series data, 4 output values\n",
    "# experiment_ID = 'b346a89d384c4db2ba4058a2c83c4f12'\n",
    "# training on time series data, 2 output values, with MaxPooling1DWithArgmax layer\n",
    "# experiment_ID = '9034f8bc4f874c938dfa5f1f9ee04e82'\n",
    "# experiment_ID = None\n",
    "\n",
    "if experiment_ID is not None:\n",
    "    from comet_ml.api import API, APIExperiment\n",
    "    api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "    experiment = api.get_experiment('danielelinaro', 'inertia', experiment_ID)\n",
    "    sys.stdout.write(f'Getting metrics for experiment {experiment_ID[:6]}... ')\n",
    "    sys.stdout.flush()\n",
    "    metrics = experiment.get_metrics()\n",
    "    sys.stdout.write('done.\\n')\n",
    "    val_loss = []\n",
    "    for m in metrics:\n",
    "        if m['metricName'] == 'val_loss':\n",
    "            val_loss.append(float(m['metricValue']))\n",
    "        elif m['metricName'] == 'mape_prediction':\n",
    "            MAPE = float(m['metricValue'])\n",
    "    val_loss = np.array(val_loss)\n",
    "else:\n",
    "    # find the best experiment that matches the set of tags above\n",
    "    experiments = collect_experiments(area_ID, area_measure=area_measure, D=D, DZA=DZA, \\\n",
    "                                      stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=H_G1, \\\n",
    "                                      rec_bus_IDs=rec_bus_IDs, additional_tags=additional_tags, \\\n",
    "                                      missing_tags=missing_tags, verbose=True)\n",
    "    experiment_IDs = list(experiments.keys())\n",
    "    experiment_ID = experiment_IDs[np.argmin([expt['val_loss'].min() for expt in experiments.values()])]\n",
    "#     experiment_ID = experiment_IDs[np.argmin([expt['MAPE'] for expt in experiments.values()])]\n",
    "\n",
    "    MAPE = experiments[experiment_ID]['MAPE']\n",
    "    loss = experiments[experiment_ID]['loss']\n",
    "    val_loss = experiments[experiment_ID]['val_loss']\n",
    "    batch_loss = experiments[experiment_ID]['batch_loss']\n",
    "    tags = experiments[experiment_ID]['tags']\n",
    "print(f'Selected experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE:.4f}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0a7fe",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81320651",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "network_parameters = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'parameters.pkl'), 'rb'))\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "try:\n",
    "    epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "except:\n",
    "    best_checkpoint = checkpoint_files[-1]\n",
    "try:\n",
    "    model = keras.models.load_model(best_checkpoint)\n",
    "except:\n",
    "    if pooling_type == 'downsample':\n",
    "        custom_objects = {'DownSampling1D': DownSampling1D}\n",
    "    elif pooling_type == 'spectral':\n",
    "        custom_objects = {'SpectralPooling': SpectralPooling}\n",
    "    elif pooling_type == 'argmax':\n",
    "        custom_objects = {'MaxPooling1DWithArgmax': MaxPooling1DWithArgmax}\n",
    "    with keras.utils.custom_object_scope(custom_objects):\n",
    "        model = keras.models.load_model(best_checkpoint)\n",
    "if pooling_type == 'argmax':\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, MaxPooling1DWithArgmax):\n",
    "            print(f'Setting store_argmax = True for layer \"{layer.name}\".')\n",
    "            layer.store_argmax = True\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "try:\n",
    "    x_train_min = network_parameters['x_train_min']\n",
    "    x_train_max = network_parameters['x_train_max']\n",
    "except:\n",
    "    pass\n",
    "var_names = network_parameters['var_names']\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Variable names: {var_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e540f",
   "metadata": {},
   "source": [
    "#### Plot the model topology"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9635a2c2",
   "metadata": {},
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77a2a3",
   "metadata": {},
   "source": [
    "### Effective receptive field size and stride of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97025c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_RF_size,effective_stride = compute_receptive_field(model, stop_layer=keras.layers.Flatten)\n",
    "print('Effective receptive field size:')\n",
    "for i,(k,v) in enumerate(effective_RF_size.items()):\n",
    "    print(f'{i}. {k} ' + '.' * (20 - len(k)) + ' {:d}'.format(v))\n",
    "print()\n",
    "print('Effective stride:')\n",
    "for i,(k,v) in enumerate(effective_stride.items()):\n",
    "    print(f'{i}. {k} ' + '.' * (20 - len(k)) + ' {:d}'.format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f8316",
   "metadata": {},
   "source": [
    "#### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08887b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = 'test'\n",
    "use_fft = network_parameters['use_fft'] if 'use_fft' in network_parameters else False\n",
    "data_dirs = []\n",
    "for area_ID,data_dir in zip(network_parameters['area_IDs'], network_parameters['data_dirs']):\n",
    "    data_dirs.append(data_dir.format(area_ID))\n",
    "data_dir = os.path.join('..', data_dirs[0])\n",
    "data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=100,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=use_fft)\n",
    "y = ret[2][set_name]\n",
    "if use_fft:\n",
    "    X = [(ret[1][set_name][i] - m) / (M - m) for i,(m,M) in enumerate(zip(x_train_min, x_train_max))]\n",
    "    F = ret[0]\n",
    "else:\n",
    "    X = [(ret[1][set_name][i] - m) / s for i,(m,s) in enumerate(zip(x_train_mean, x_train_std))]\n",
    "    t = ret[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f46974",
   "metadata": {},
   "source": [
    "#### Predict the momentum using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6537dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [np.where(y == mom)[0] for mom in np.unique(y)]\n",
    "n_mom_values = len(idx)\n",
    "momentum = [np.squeeze(model.predict(X[0][jdx])) for jdx in idx]\n",
    "mean_momentum = [m.mean() for m in momentum]\n",
    "stddev_momentum = [m.std() for m in momentum]\n",
    "print('Mean momentum:', mean_momentum)\n",
    "print(' Std momentum:', stddev_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4a70d",
   "metadata": {},
   "source": [
    "### Plot the inputs and their FFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8366a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10', n_mom_values)\n",
    "if use_fft:\n",
    "    Xf = X\n",
    "else:\n",
    "    data_files_training = sorted(glob.glob(data_dir + os.path.sep + f'*_training_set.h5'))\n",
    "    if len(data_files_training) == 0:\n",
    "        data_files_training = sorted(glob.glob(data_dir + os.path.sep + f'*_test_set.h5'))\n",
    "    ret_fft = load_data_areas({'training': data_files_training}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=200,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=True)\n",
    "    x_train_min_fft = np.array([val.min() for val in ret_fft[1]['training']], dtype=np.float32)\n",
    "    x_train_max_fft = np.array([val.max() for val in ret_fft[1]['training']], dtype=np.float32)\n",
    "    ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=100,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=True)\n",
    "    F = ret[0]\n",
    "    Xf = [(ret[1][set_name][i] - m) / (M - m) for i,(m,M) in enumerate(zip(x_train_min_fft,\n",
    "                                                                           x_train_max_fft))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "for j,jdx in enumerate(idx):\n",
    "    mean = X[0][jdx].mean(axis=0)\n",
    "    stddev = X[0][jdx].std(axis=0)\n",
    "    ci = 1.96 * stddev / np.sqrt(jdx.size)\n",
    "    ax[0].fill_between(t, mean + ci, mean - ci, color=cmap(j))\n",
    "    mean = Xf[0][jdx].mean(axis=0)\n",
    "    stddev = Xf[0][jdx].std(axis=0)\n",
    "    ci = 1.96 * stddev / np.sqrt(jdx.size)\n",
    "    ax[1].fill_between(F, mean + ci, mean - ci, color=cmap(j))\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.grid(which='major', axis='both', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "ax[1].set_xscale('log')\n",
    "ax[0].set_xlabel('Time [min]')\n",
    "ax[0].set_ylabel('Normalized trace')\n",
    "ax[1].set_xlabel('Frequency [Hz]')\n",
    "ax[1].set_ylabel('Normalized FFT')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'spectra_{n_mom_values}_momentum_levels.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0e5e4",
   "metadata": {},
   "source": [
    "### Build a model with as many outputs as there are convolutional or pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7aaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers \\\n",
    "           if layer.name in effective_RF_size.keys() and not isinstance(layer, keras.layers.InputLayer)]\n",
    "multi_output_model = keras.Model(inputs=model.inputs, outputs=outputs)\n",
    "# Y = [multi_output_model.predict(X[0][jdx]) for jdx in idx]\n",
    "print(f'The model has {len(outputs)} outputs, corresponding to the following layers:')\n",
    "for i,layer in enumerate(multi_output_model.layers):\n",
    "    if not isinstance(layer, keras.layers.InputLayer):\n",
    "        print(f'    {i}. {layer.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e127d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation(model, x, dt, bands,\n",
    "                        effective_RF_size, effective_stride,\n",
    "                        filter_order=6, verbose=False):\n",
    "\n",
    "    ## Filter the input in a series of bands and compute the signal envelope\n",
    "    N_samples = x.size\n",
    "    N_bands = len(bands)\n",
    "    # filter the input in various frequency bands\n",
    "    x_filt = np.zeros((N_bands, N_samples))\n",
    "    for i in range(N_bands):\n",
    "        b,a = butter(filter_order//2, bands[i], 'bandpass', fs=1/dt)\n",
    "        x_filt[i,:] = filtfilt(b, a, x)\n",
    "    # compute the envelope of the filtered signal\n",
    "    x_filt_envel = np.abs(hilbert(x_filt))\n",
    "    \n",
    "    ## Compute the outputs of the last layer before the fully connected layer\n",
    "    layer_name = model.layers[-1].name\n",
    "    multi_y = model(x[np.newaxis, :])\n",
    "    y = np.squeeze(multi_y[-1].numpy())\n",
    "    N_neurons, N_filters = y.shape\n",
    "    if verbose:\n",
    "        print(f'Layer \"{layer_name}\" has {N_filters} filters, each with {N_neurons} neurons.')\n",
    "    \n",
    "    ## Compute the mean squared envelope for each receptive field\n",
    "    RF_sz, RF_str = effective_RF_size[layer_name], effective_stride[layer_name]\n",
    "    if verbose:\n",
    "        print(f'The effective RF size and stride of layer \"{layer_name}\" are {RF_sz} and {RF_str} respectively.')\n",
    "    squared_mean_envel = np.zeros((N_bands, N_neurons, N_filters))\n",
    "    mean_squared_envel = np.zeros((N_bands, N_neurons, N_filters))\n",
    "    for i in range(N_neurons):\n",
    "        start = i * RF_str\n",
    "        stop = start + RF_sz\n",
    "        for j in range(N_filters):\n",
    "            x_filt_envel_sub = x_filt_envel[:, start : stop]\n",
    "            squared_mean_envel[:, i, j] = np.mean(x_filt_envel_sub, axis=1) ** 2\n",
    "            mean_squared_envel[:, i, j] = np.mean(x_filt_envel_sub ** 2, axis=1)\n",
    "            \n",
    "    ## For each frequency band, compute the correlation between mean squared envelope\n",
    "    ## of the input (to each receptive field) and the output of each neuron in the layer\n",
    "    R = np.zeros((N_bands, N_filters))\n",
    "    for i in range(N_bands):\n",
    "        for j in range(N_filters):\n",
    "            R[i, j] = np.corrcoef(y[:, j], mean_squared_envel[i, :, j])[0,1]\n",
    "            \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.diff(t[:2])[0]\n",
    "edges = np.logspace(-1, 1, 20)\n",
    "bands = [[a,b] for a,b in zip(edges[:-1], edges[1:])]\n",
    "N_bands = len(bands)\n",
    "N_filters = multi_output_model.layers[-1].output.shape[-1]\n",
    "N_traces = 1000\n",
    "R = np.zeros((N_traces, N_bands, N_filters))\n",
    "for i in tqdm(range(N_traces)):\n",
    "    R[i,:,:] = compute_correlation(multi_output_model, X[0][i,:], dt, bands,\n",
    "                                   effective_RF_size, effective_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327613cc",
   "metadata": {},
   "source": [
    "1. Choose the frequency bands appropriately\n",
    "1. Perform the same type of analysis on an untrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ff72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_mean = R.mean(axis=0)\n",
    "edge = 10\n",
    "idx = np.argsort(R_mean[edge,:])\n",
    "R_mean = R_mean[:,idx]\n",
    "\n",
    "cmap = plt.get_cmap('bwr')\n",
    "fig,ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "x = np.arange(N_filters)\n",
    "y = edges[:-1]\n",
    "X,Y = np.meshgrid(x, y)\n",
    "im = ax.pcolor(X, Y, R_mean, shading='auto', cmap=cmap)\n",
    "ax.set_yscale('log')\n",
    "cbar = plt.colorbar(im, label='Correlation')\n",
    "ax.set_xlabel('Filter #')\n",
    "ax.set_ylabel('Frequency [Hz]')\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6644c",
   "metadata": {},
   "source": [
    "### Filter the input in a series of bands and compute the signal envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dada4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take an input time series\n",
    "i = 0\n",
    "x = X[0][i,:]\n",
    "# filter it in various frequency ranges\n",
    "dt = np.diff(t[:2])[0]\n",
    "filter_order = 6\n",
    "bands = [[0.1, 0.2], [0.5, 2], [3, 10]]\n",
    "N_bands = len(bands)\n",
    "x_filt = []\n",
    "for band in bands:\n",
    "    b,a = butter(filter_order//2, band, 'bandpass', fs=1/dt)\n",
    "    x_filt.append(filtfilt(b, a, x))\n",
    "x_filt = np.array(x_filt)\n",
    "# compute the envelope of the filtered signal\n",
    "x_filt_envel = np.abs(hilbert(x_filt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb9912",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(t, x, 'k', lw=1, label='Broad-band')\n",
    "cmap = plt.get_cmap('spring', n_bands)\n",
    "for i in range(n_bands):\n",
    "    ax.plot(t, x_filt[i,:], color=cmap(i), lw=1, label=bands[i])\n",
    "    ax.plot(t, x_filt_envel[i,:], color=cmap(i), lw=3)\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('Normalized voltage')\n",
    "ax.legend(loc='best', frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca9b15",
   "metadata": {},
   "source": [
    "### Compute the outputs of the last layer before the fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38032650",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_y = multi_output_model(x[np.newaxis, :])\n",
    "y = np.squeeze(multi_y[-1].numpy())\n",
    "N_neurons, N_filters = y.shape\n",
    "print(f'Layer \"{layer_name}\" has {N_filters} filters, each with {N_neurons} neurons.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d377b94",
   "metadata": {},
   "source": [
    "### Compute the mean squared envelope for each receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431966f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = 6\n",
    "layer_name = model.layers[layer_id].name\n",
    "RF_sz, RF_str = effective_RF_size[layer_name], effective_stride[layer_name]\n",
    "print(f'The effective RF size and stride of layer \"{layer_name}\" are {RF_sz} and {RF_str} respectively.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_mean_envel = np.zeros((N_bands, N_neurons, N_filters))\n",
    "mean_squared_envel = np.zeros((N_bands, N_neurons, N_filters))\n",
    "for i in range(N_neurons):\n",
    "    start = i * RF_str\n",
    "    stop = start + RF_sz\n",
    "    for j in range(N_filters):\n",
    "        x_filt_envel_sub = x_filt_envel[:, start : stop]\n",
    "        squared_mean_envel[:, i, j] = np.mean(x_filt_envel_sub, axis=1) ** 2\n",
    "        mean_squared_envel[:, i, j] = np.mean(x_filt_envel_sub ** 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.zeros((N_bands, N_filters))\n",
    "for i in range(N_bands):\n",
    "    for j in range(N_filters):\n",
    "        R[i, j] = np.corrcoef(y[:, j], mean_squared_envel[i, :, j])[0,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
