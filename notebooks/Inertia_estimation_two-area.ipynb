{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from comet_ml.api import API, APIExperiment\n",
    "from comet_ml.query import Tag\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from deep_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "workspace = 'danielelinaro'\n",
    "project_name = 'inertia'\n",
    "area_IDs = [1]\n",
    "D = 2\n",
    "DZA = 60\n",
    "query = Tag('two-area') & \\\n",
    "        Tag('_'.join([f'area{area_id}' for area_id in area_IDs])) & \\\n",
    "        Tag(f'D={D}') & \\\n",
    "        Tag(f'DZA={DZA}') & \\\n",
    "        Tag('1D_pipeline')\n",
    "experiments = api.query(workspace, project_name, query, archived=False)\n",
    "experiment_IDs = []\n",
    "MAPE = []\n",
    "val_loss = []\n",
    "tags =  []\n",
    "for experiment in experiments:\n",
    "    ID = experiment.id\n",
    "    experiment_IDs.append(ID)\n",
    "    sys.stdout.write(f'Downloading data for experiment ID {ID}... ')\n",
    "    metrics = experiment.get_metrics()\n",
    "    sys.stdout.write('done.\\n')\n",
    "    val_loss.append(np.array([float(m['metricValue']) for m in metrics if m['metricName'] == 'val_loss']))\n",
    "    has_MAPE = False\n",
    "    for m in metrics:\n",
    "        if m['metricName'] == 'mape_prediction':\n",
    "            val = m['metricValue']\n",
    "            try:\n",
    "                MAPE.append(float(val))\n",
    "            except:\n",
    "                MAPE.append(list(map(float, val[1:-1].split(' ')[:2])))\n",
    "            has_MAPE = True\n",
    "            break\n",
    "    tags.append(experiment.get_tags())\n",
    "    print(f'  val_loss: {val_loss[-1].min():.4f}')\n",
    "    if has_MAPE:\n",
    "        print(f'      MAPE: {MAPE[-1]}%')\n",
    "    else:\n",
    "        print('      MAPE: [experiment not terminated]')\n",
    "    print('      Tags: \"{}\"'.format('\" \"'.join(tags[-1])))\n",
    "# idx = np.argmin(MAPE)\n",
    "idx = np.argmin([loss.min() for loss in val_loss])\n",
    "experiment_ID = experiment_IDs[idx]\n",
    "MAPE = MAPE[idx]\n",
    "val_loss = val_loss[idx]\n",
    "tags = tags[idx]\n",
    "print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE}%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "network_parameters = pickle.load(open(experiments_path + experiment_ID \\\n",
    "                                      + '/parameters.pkl', 'rb'))\n",
    "epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "model = keras.models.load_model(best_checkpoint, compile=True)\n",
    "try:\n",
    "    data_dirs = ['../' + data_dir.format(area_id) for area_id in network_parameters['area_IDs'] \\\n",
    "                 for data_dir in network_parameters['data_dirs']]\n",
    "except:\n",
    "    data_dirs = ['../' + data_dir.format(gen_id) for gen_id in network_parameters['generator_IDs'] \\\n",
    "                 for data_dir in network_parameters['data_dirs']]\n",
    "# we need mean and standard deviation of the training set to normalize the data\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "if not os.path.isdir(data_dirs[0]):\n",
    "    data_dirs[0] = '../data/var_H_G1/' + os.path.split(data_dirs[0])[-1]\n",
    "print('Loaded network from {}.'.format(best_checkpoint))\n",
    "print('Data directories are {}.'.format(data_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=False, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bus = 7\n",
    "default_H = [6.5, 6.175]\n",
    "bus_IDs = [7, 9]\n",
    "\n",
    "window_dur = 60\n",
    "window_step = 10\n",
    "\n",
    "H_values = [3.5, 8.5]\n",
    "N_H = len(H_values)\n",
    "\n",
    "fig = plt.figure(figsize=(10, (N_H + 2) * 3))\n",
    "gs = fig.add_gridspec(N_H * 2 + 2, 4)\n",
    "ax = []\n",
    "for i in range(0, len(H_values)*2, 2):\n",
    "    ax.append([fig.add_subplot(gs[i, :3]), fig.add_subplot(gs[i, 3])]),\n",
    "    ax.append([fig.add_subplot(gs[i+1, :3]), fig.add_subplot(gs[i+1, 3])]),\n",
    "ax.append([fig.add_subplot(gs[-2:,:2]), fig.add_subplot(gs[-2:,2:])])\n",
    "\n",
    "col = [[.2,.2,.2], [.8,0,0]]\n",
    "H = [0,0]\n",
    "for i, bus_to_predict in enumerate(bus_IDs):\n",
    "    other_bus = bus_IDs[1 - i]\n",
    "    for j,h in enumerate(H_values):\n",
    "        H[i] = h\n",
    "        H[1-i] = default_H[1-i]\n",
    "        data_file = data_dirs[0] + f'/inertia_{H[0]:.3f}_{H[0]:.3f}_{H[1]:.3f}_{H[1]:.3f}.h5'\n",
    "\n",
    "        var_names = [f'omegael_bus{bus_to_predict}', f'Pe_bus{bus_to_predict}']\n",
    "\n",
    "        if bus_to_predict == training_bus:\n",
    "            data_mean = {var_name: x_train_mean[k] for k,var_name in enumerate(var_names)}\n",
    "            data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "        else:\n",
    "            data_mean = None\n",
    "            data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "\n",
    "        t, data, data_normalized, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                                    var_names,\n",
    "                                                                    data_mean,\n",
    "                                                                    data_std,\n",
    "                                                                    window_dur,\n",
    "                                                                    window_step,\n",
    "                                                                    verbose = True)\n",
    "        \n",
    "        idx = t < 60\n",
    "        for k,(key,value) in enumerate(data_normalized.items()):\n",
    "            n,edges = np.histogram(value, bins=31, range=(-3,3), density=True)\n",
    "            m = j * N_H + k\n",
    "            ax[m][0].plot(t[idx], value[idx], color=col[i], lw=1, label=key.split('_')[1])\n",
    "            ax[m][1].plot(n, edges[:-1] + np.diff(edges[:2])[0] / 2, color=col[i], lw=1)\n",
    "        ax[j * 2][0].set_title(f'H = {h} /s')\n",
    "\n",
    "        if bus_to_predict != training_bus:\n",
    "            for src in var_names:\n",
    "                dst = src.replace(str(bus_to_predict), str(training_bus))\n",
    "                data_sliding[dst] = data_sliding.pop(src)\n",
    "        dt = np.diff(t[:2])[0]\n",
    "        time, inertia, _ = predict(model, data_sliding, window_step, dt)\n",
    "\n",
    "        ax[-1][i].plot(time[[0,-1]] / 60, h + np.zeros(2), '--', color=col[i], lw=1)\n",
    "        ax[-1][i].plot(time[[0,-1]] / 60, default_H[1-i] + np.zeros(2), '--', color=col[1-i], lw=1)\n",
    "        ax[-1][i].plot(time / 60, inertia, color=col[i], lw=1)\n",
    "    ax[-1][i].set_xlabel('Time [min]')\n",
    "    \n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        for i in range(2):\n",
    "            a[i].spines[side].set_visible(False)\n",
    "\n",
    "ax[0][0].legend(loc='best')\n",
    "for i in range(len(ax)):\n",
    "    if i < len(ax) - 2:\n",
    "        ax[i][0].get_shared_x_axes().join(ax[i][0], ax[i+1][0])\n",
    "    ax[i][0].get_shared_y_axes().join(ax[i][0], ax[i][1])\n",
    "    ax[i][1].set_yticklabels([])\n",
    "\n",
    "for i in range(0, len(ax)-1, 2):\n",
    "    ax[i][0].set_ylabel(r'$\\omega_{e}$')\n",
    "    ax[i+1][0].set_ylabel(r'$P_{e}$')\n",
    "ax[-1][0].get_shared_x_axes().join(ax[-1][0], ax[-1][1])\n",
    "\n",
    "ax[-1][0].set_xlim([0,30])\n",
    "ax[-1][0].set_ylim([2.5,10])\n",
    "ax[-1][0].set_ylabel(r'Inertia [$s^{-1}$]')\n",
    "ax[-2][0].set_xlabel('Time [s]')\n",
    "ax[-2][1].set_xlabel('Fraction')\n",
    "fig.tight_layout()\n",
    "fig.savefig('area1_prediction_area1_area2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step of inertia\n",
    "1. H steps **instantaneously** from 3.5 to 3.8\n",
    "1. **omega** and **Pe** of the first generator used for the estimation\n",
    "1. two simulations joined together (i.e., **no transient** during the step)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "window_dur = 60\n",
    "window_step = 10\n",
    "H_values = [3.5, 8.5]\n",
    "data_files = [f'{data_dir}/H_{h:.3f}.h5' for h in H_values]\n",
    "gen_id = 1\n",
    "var_names = [f'omega_G{gen_id}', f'Pe_G{gen_id}']\n",
    "if gen_id == generator_ID:\n",
    "    data_mean = {var_name: x_train_mean[i] for i,var_name in enumerate(var_names)}\n",
    "    data_std = {var_name: x_train_std[i] for i,var_name in enumerate(var_names)}\n",
    "else:\n",
    "    data_mean = None\n",
    "    data_std = None\n",
    "t, data, data_normalized, data_sliding, _ = load_data(data_files,\n",
    "                                                      var_names,\n",
    "                                                      data_mean,\n",
    "                                                      data_std,\n",
    "                                                      window_dur,\n",
    "                                                      window_step,\n",
    "                                                      verbose=True)\n",
    "if gen_id != generator_ID:\n",
    "    data_sliding[f'omega_G{generator_ID}'] = data_sliding.pop(f'omega_G{gen_id}')\n",
    "    data_sliding[f'Pe_G{generator_ID}'] = data_sliding.pop(f'Pe_G{gen_id}')\n",
    "dt = np.diff(t[:2])[0]\n",
    "time, H, _ = predict(model, data_sliding, window_step, dt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig,ax = plt.subplots(1, 3, figsize=(14,4))\n",
    "ax[0].plot(t, data_normalized[var_names[0]], 'k', lw=1)\n",
    "ax[0].plot([3600, 3600], ax[0].get_ylim(), '--', lw=2, color=[.6,.6,.6])\n",
    "ax[1].plot(t, data_normalized[var_names[1]], 'r', lw=1)\n",
    "ax[1].plot([3600, 3600], ax[0].get_ylim(), '--', lw=2, color=[.6,.6,.6])\n",
    "if gen_id == generator_ID:\n",
    "    ax[2].plot([0, 3600], H_values[0] + np.zeros(2), 'r:', lw=3)\n",
    "    ax[2].plot([3600, 7200], H_values[1] + np.zeros(2), 'r:', lw=3, label='Real')\n",
    "else:\n",
    "    ax[2].plot([0, 7200], default_H[gen_id] + np.zeros(2), 'r:', lw=2, label='Real')\n",
    "ax[2].plot(time, H, 'k', lw=1, label='Estimated')\n",
    "\n",
    "ax[2].legend(loc='lower right')\n",
    "ax[0].set_ylabel(r'$\\omega_{\\mathrm{G}_1}$')\n",
    "ax[1].set_ylabel(r'$Pe_{\\mathrm{G}_1}$')\n",
    "ax[2].set_ylabel('Inertia')\n",
    "for a in ax:\n",
    "    a.set_xlabel('Time [s]')\n",
    "    if a != ax[2]:\n",
    "        a.set_xlim([3300, 3900])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ramp of inertia\n",
    "H increases **gradually** from 3.5 to 6.5 in 100 seconds (from t = 3550s to t=3650s)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "window_dur = 60\n",
    "window_step = 10\n",
    "H_values = [3.5, 6.5]\n",
    "data_file = f'{data_dir}/H_{H_values[0]:.3f}_{H_values[1]:.3f}.h5'\n",
    "gen_id = 1\n",
    "var_names = [f'omega_G{gen_id}', f'Pe_G{gen_id}']\n",
    "if gen_id == 1:\n",
    "    data_mean = {var_name: x_train_mean[i] for i,var_name in enumerate(var_names)}\n",
    "    data_std = {var_name: x_train_std[i] for i,var_name in enumerate(var_names)}\n",
    "else:\n",
    "    data_mean = None\n",
    "    data_std = None\n",
    "t, data, data_normalized, data_sliding, _ = load_data([data_file],\n",
    "                                                      var_names,\n",
    "                                                      data_mean,\n",
    "                                                      data_std,\n",
    "                                                      window_dur,\n",
    "                                                      window_step,\n",
    "                                                      verbose=True)\n",
    "dt = np.diff(t[:2])[0]\n",
    "time, H, _ = predict(model, data_sliding, window_step, dt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig,ax = plt.subplots(1, 3, figsize=(14,4))\n",
    "ax[0].plot(t, data_normalized[var_names[0]], 'k', lw=1)\n",
    "ax[1].plot(t, data_normalized[var_names[1]], 'r', lw=1)\n",
    "ax[2].plot([0, 3550, 3650, 7200], [H_values[0], H_values[0], H_values[1], H_values[1]], 'r:', lw=3, label='Real')\n",
    "ax[2].plot(time, H, 'k', lw=1, label='Estimated')\n",
    "\n",
    "ax[2].legend(loc='lower right')\n",
    "ax[0].set_ylabel(r'$\\omega_{\\mathrm{G}_1}$')\n",
    "ax[1].set_ylabel(r'$Pe_{\\mathrm{G}_1}$')\n",
    "ax[2].set_ylabel('Inertia')\n",
    "for a in ax:\n",
    "    a.set_xlabel('Time [s]')\n",
    "    if a != ax[2]:\n",
    "        a.set_xlim([3500, 3700])\n",
    "    else:\n",
    "        a.set_xlim([3000, 4000])\n",
    "        a.set_ylim([3,7])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
