{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from time import strftime, localtime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.fft import fft\n",
    "from scipy.io import loadmat\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from deep_utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fix the seed of the RNG, for reproducibility purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_good_seed = False\n",
    "\n",
    "with open('/dev/random', 'rb') as fid:\n",
    "    seed = int.from_bytes(fid.read(4), 'little')\n",
    "\n",
    "if use_good_seed:\n",
    "    seed = 1057901520\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print('Seed: {}'.format(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../pan/npz_files/'\n",
    "inertia = {key: np.arange(2,11) + i/3 for i,key in enumerate(('training', 'test', 'validation'))}\n",
    "time, x, y = load_data(data_folder, inertia)\n",
    "x['train'] = x.pop('training')\n",
    "y['train'] = y.pop('training')\n",
    "N = x['train'].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x['train'])\n",
    "x_train_std = np.std(x['train'])\n",
    "for key in x:\n",
    "    x[key] = (x[key] - x_train_mean) / x_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "ax.plot(time, tf.transpose(x['train'][:100,:]), 'k')\n",
    "ax.plot(time, tf.transpose(x['train'][-100:,:]), 'r')\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel(r'$\\omega_{\\mathrm{COI}}$ [Hz]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx,_ = np.where(y['train'] == 2)\n",
    "n,edges = np.histogram(np.ndarray.flatten(x['train'].numpy()[idx,:]), bins=100, range=[-4,4], \\\n",
    "                       density=True)\n",
    "plt.plot(edges[:-1], n, 'k.')\n",
    "idx,_ = np.where(y['train'] == 10)\n",
    "n,edges = np.histogram(np.ndarray.flatten(x['train'].numpy()[idx,:]), bins=100, range=[-4,4], \\\n",
    "                       density=True)\n",
    "plt.plot(edges[:-1], n, 'r.')\n",
    "# plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "The network topology used here is taken from the following paper:\n",
    "\n",
    "George, D., & Huerta, E. A. (2018). Deep neural networks to enable real-time multimessenger astrophysics. Physical Review D, 97(4), 044039. http://doi.org/10.1103/PhysRevD.97.044039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_dropout = False\n",
    "dropout_coeff = 0.2\n",
    "depth_level = 1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "N_units = {}\n",
    "\n",
    "if depth_level == 1:\n",
    "    N_units['conv'] = [16, 32, 64]\n",
    "elif depth_level == 2:\n",
    "    N_units['conv'] = [64, 128, 256, 512]\n",
    "\n",
    "N_units['pooling'] = [4 for _ in range(len(N_units['conv']))]\n",
    "kernel_size = [5 for _ in range(len(N_units['conv']))]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((N,1), input_shape=(N,)),\n",
    "])\n",
    "\n",
    "for N_conv,N_pooling,sz in zip(N_units['conv'], N_units['pooling'], kernel_size):\n",
    "    model.add(tf.keras.layers.Conv1D(N_conv, sz, activation=None))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(N_pooling))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "if depth_level == 2:\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    \n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "if with_dropout:\n",
    "    model.add(tf.keras.layers.Dropout(dropout_coeff))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(y['train'].shape[1]))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = strftime('%Y%m%d-%H%M%S', localtime())\n",
    "path = 'inertia/' + ts\n",
    "checkpoint_path = path + '/checkpoints'\n",
    "\n",
    "os.makedirs(checkpoint_path)\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path + \\\n",
    "                                                 '/weights.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                                                 save_weights_only=False,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 verbose=0)\n",
    "\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 128\n",
    "N_batches = np.ceil(x['train'].shape[0] / BATCH_SIZE)\n",
    "STEPS_PER_EPOCH = np.max([N_batches, 100])\n",
    "history = model.fit(x['train'], y['train'], epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, validation_data=(x['val'], y['val']),\n",
    "                    verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the loss as a function of the epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.r_[0 : len(history.history['loss'])] + 1\n",
    "plt.plot(epochs, history.history['loss'], 'k', label='Training')\n",
    "plt.plot(epochs, history.history['val_loss'], 'r', label='Validation')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best model based on the validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/daniele/Research/deep-power/trained_networks/20201206-221201/checkpoints'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '/*.h5')\n",
    "val_loss = [float(file[:-3].split('-')[-1]) for file in checkpoint_files]\n",
    "best_checkpoint = checkpoint_files[np.argmin(val_loss)]\n",
    "best_model = tf.keras.models.load_model(best_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the network prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn = best_model.predict(x['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the Mean Absolute Percentage Error on the CNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_cnn = tf.keras.losses.mean_absolute_percentage_error(tf.transpose(y['test']), \\\n",
    "                                                          tf.transpose(y_cnn)).numpy()[0]\n",
    "print('MAPE on CNN prediction ... {:.2f}%'.format(mape_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results obtained with the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "limits = np.squeeze(y['train'].numpy()[[0,-1]])\n",
    "limits[1] += 1\n",
    "ax.plot(limits, limits, 'g--')\n",
    "ax.plot(y['test'], y_cnn, 'o', color=[1,.7,1], markersize=4, \\\n",
    "        markerfacecolor='w', markeredgewidth=1)\n",
    "for i in range(int(limits[0]), int(limits[1])):\n",
    "    idx,_ = np.where(np.abs(y['test'] - (i + 1/3)) < 1e-3)\n",
    "    m = np.mean(y_cnn[idx])\n",
    "    s = np.std(y_cnn[idx])\n",
    "    ax.plot(i+1/3 + np.zeros(2), m + s * np.array([-1,1]), 'm-', linewidth=2)\n",
    "    ax.plot(i+1/3, m, 'ms', markersize=8, markerfacecolor='w', \\\n",
    "            markeredgewidth=2)\n",
    "ax.set_title('CNN')\n",
    "ax.set_xlabel('Expected value')\n",
    "ax.set_ylabel('Predicted value')\n",
    "ax.axis([1.8, limits[1], 0, limits[1]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'N_samples': N, 'seed': seed, 'with_dropout': with_dropout,\n",
    "              'depth_level': depth_level, 'N_units': N_units, 'kernel_size': kernel_size,\n",
    "              'N_epochs': EPOCHS, 'batch_size': BATCH_SIZE, 'steps_per_epoch': STEPS_PER_EPOCH,\n",
    "              'mape_cnn': mape_cnn, 'learning_rate': learning_rate, 'y_test': y['test'],\n",
    "              'y_cnn': y_cnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(path)\n",
    "pickle.dump(parameters, open(path + '/parameters.pkl', 'wb'))\n",
    "pickle.dump(history.history, open(path + '/history.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
