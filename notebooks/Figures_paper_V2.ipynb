{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import shelve\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.colors import LogNorm, FuncNorm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FixedLocator, NullLocator, FixedFormatter\n",
    "from matplotlib.patches import Polygon\n",
    "import seaborn as sns\n",
    "\n",
    "fontsize = 8\n",
    "lw = 0.75\n",
    "\n",
    "matplotlib.rc('font', **{'family': 'Times New Roman', 'size': fontsize})\n",
    "matplotlib.rc('axes', **{'linewidth': 0.75, 'labelsize': fontsize})\n",
    "matplotlib.rc('xtick', **{'labelsize': fontsize})\n",
    "matplotlib.rc('ytick', **{'labelsize': fontsize})\n",
    "matplotlib.rc('xtick.major', **{'width': lw, 'size':3})\n",
    "matplotlib.rc('ytick.major', **{'width': lw, 'size':3})\n",
    "matplotlib.rc('ytick.minor', **{'width': lw, 'size':1.5})\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.data import load_data_files, load_data_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_axes(rows, cols, x_offset, y_offset, x_space, y_space, squeeze=True):\n",
    "    w = (1 - np.sum(x_offset) - x_space * (cols - 1)) / cols\n",
    "    h = (1 - np.sum(y_offset) - y_space * (rows - 1)) / rows\n",
    "    \n",
    "    ax = [[plt.axes([x_offset[0] + (w + x_space) * j,\n",
    "                     y_offset[0] + (h + y_space) * i,\n",
    "                     w, h]) for j in range(cols)] for i in range(rows-1, -1, -1)]\n",
    "    \n",
    "    for row in ax:\n",
    "        for a in row:\n",
    "            for side in 'right','top':\n",
    "                a.spines[side].set_visible(False)\n",
    "\n",
    "    if squeeze:\n",
    "        if rows == 1 and cols == 1:\n",
    "            return ax[0][0]\n",
    "        if rows == 1:\n",
    "            return ax[0]\n",
    "        if cols == 1:\n",
    "            return [a[0] for a in ax]\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(R, p, R_ctrl, p_ctrl, edges, idx, ax, sort_freq=1.0,\n",
    "                      vmin=None, vmax=None, legend_bbox=[0.4, -0.05]):\n",
    "    if p is not None:\n",
    "        R = R.copy()\n",
    "        R[p > 0.05] = np.nan\n",
    "    if R_ctrl is not None and p_ctrl is not None:\n",
    "        R_ctrl = R_ctrl.copy()\n",
    "        R_ctrl[p_ctrl > 0.05] = np.nan\n",
    "    rows, cols = ax.shape\n",
    "    if rows != len(idx):\n",
    "        raise Exception('Number of rows of ax does not match len(idx)')\n",
    "    R_mean = [np.nanmean(R[jdx], axis=0) for jdx in idx]\n",
    "    R_abs_mean = [np.mean(np.abs(r), axis=1) for r in R_mean]\n",
    "    if R_ctrl is not None:\n",
    "        R_ctrl_mean = [np.nanmean(R_ctrl[jdx], axis=0) for jdx in idx]\n",
    "        R_ctrl_abs_mean = [np.mean(np.abs(r), axis=1) for r in R_ctrl_mean]\n",
    "    else:\n",
    "        R_ctrl_mean = [None for _ in range(rows)]\n",
    "        R_ctrl_abs_mean = None\n",
    "    if np.isscalar(sort_freq):\n",
    "        sort_freq += np.zeros(rows)\n",
    "    edge = np.array([np.abs(edges - freq).argmin() for freq in sort_freq])\n",
    "    for i in range(rows):\n",
    "        kdx = np.argsort(R_mean[i][edge[i],:])\n",
    "        R_mean[i] = R_mean[i][:,kdx]\n",
    "        if R_ctrl is not None:\n",
    "            R_ctrl_mean[i] = R_ctrl_mean[i][:,kdx]\n",
    "\n",
    "    make_symmetric = False\n",
    "    if vmin is None:\n",
    "        vmin = min([r.min() for r in R_mean])\n",
    "        make_symmetric = True\n",
    "    if vmax is None:\n",
    "        vmax = max([r.max() for r in R_mean])\n",
    "        if make_symmetric:\n",
    "            if vmax > np.abs(vmin):\n",
    "                vmin = -vmax\n",
    "            else:\n",
    "                vmax = -vmin\n",
    "    print(f'Color bar bounds: ({vmin:.2f},{vmax:.2f}).')\n",
    "    ticks = np.linspace(vmin, vmax, 7)\n",
    "    ticklabels = [f'{tick:.2f}' for tick in ticks]\n",
    "\n",
    "    cmap = plt.get_cmap('bwr')\n",
    "    y = edges[:-1] + np.diff(edges) / 2\n",
    "    for i in range(rows):\n",
    "        for j,R in enumerate((R_mean[i], R_ctrl_mean[i])):\n",
    "            if R is not None:\n",
    "                x = np.arange(R.shape[-1])\n",
    "                im = ax[i][j].pcolormesh(x, y, R, vmin=vmin, vmax=vmax, shading='auto', cmap=cmap)\n",
    "                for side in 'right','top':\n",
    "                    ax[i][j].spines[side].set_visible(False)\n",
    "                ax[i][j].set_xticks(np.linspace(0, x[-1], 3, dtype=np.int32))\n",
    "        if cols > 1:\n",
    "            cbar = plt.colorbar(im, fraction=0.1, shrink=1, aspect=20, label='Correlation',\n",
    "                                orientation='vertical', ax=ax[i][1], ticks=ticks)\n",
    "            cbar.ax.set_yticklabels(ticklabels, fontsize=fontsize-1)\n",
    "            if R_ctrl_abs_mean is not None:\n",
    "                ax[i][-1].plot(R_abs_mean[i], y, 'r', lw=1, label='Tr.')\n",
    "                ax[i][-1].plot(R_ctrl_abs_mean[i], y, 'g--', lw=1, label='Untr.')\n",
    "                ax[i][-1].plot(R_abs_mean[i] - R_ctrl_abs_mean[i], y, 'k', lw=1, label='Diff.')\n",
    "                ax[i][-1].legend(loc='lower left', bbox_to_anchor=legend_bbox,\n",
    "                                 frameon=False, fontsize=fontsize-1)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax[i][j].set_ylim(edges[[0,-2]])\n",
    "            ax[i][j].set_yscale('log')\n",
    "\n",
    "    return vmin, vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_output_hist(Y, group_index, N_bins, cols=8, w=2, h=1.5, cmap=None, ax=None, labels=None):\n",
    "    N_trials, N_samples, N_filters = Y.shape\n",
    "    N_groups = len(group_index)\n",
    "    N = np.zeros((N_filters, N_groups, N_bins))\n",
    "    edges = np.zeros((N_filters, N_groups, N_bins+1))\n",
    "    for i in range(N_filters):\n",
    "        for j,jdx in enumerate(group_index):\n",
    "            N[i,j,:],edges[i,j,:] = np.histogram(Y[jdx, :, i], N_bins)\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('tab10', N_groups)\n",
    "    if ax is None:\n",
    "        rows = N_filters // cols\n",
    "        fig,ax = plt.subplots(rows, cols, figsize=(w*cols, h*rows))\n",
    "    else:\n",
    "        fig = None\n",
    "        N_filters = ax.size\n",
    "    ax = ax.flatten()\n",
    "    for i in range(N_filters):\n",
    "        for j in range(N_groups):\n",
    "            de = np.diff(edges[i, j, :])[0]\n",
    "            col = np.max([[0,0,0], cmap(j)[:3] - 1/3 * np.ones(3)], axis=0)\n",
    "            ax[i].bar(edges[i, j, :-1], N[i, j, :], width=de*0.8, align='edge',\n",
    "                     facecolor=cmap(j), edgecolor=col, linewidth=0.5, alpha=0.85)\n",
    "        xlim = [edges[i, :, 2:-3].min(), edges[i, j, 2:-3].max()]\n",
    "        ylim = ax[i].get_ylim()\n",
    "#         ax[i].set_xlim(xlim)\n",
    "#         ax[i].set_xticks(xlim)\n",
    "        if labels is not None:\n",
    "            ax[i].text(xlim[0] - 0.1 * np.diff(xlim), ylim[1],\n",
    "                       labels[i], fontsize=fontsize-1, verticalalignment='top',\n",
    "                       horizontalalignment='left')\n",
    "        ax[i].set_xticklabels([])\n",
    "        ax[i].set_yticks(ax[i].get_ylim())\n",
    "        ax[i].set_yticklabels([])\n",
    "        for side in 'right','top':\n",
    "            ax[i].spines[side].set_visible(False)\n",
    "    if fig is not None:\n",
    "        fig.tight_layout()\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, Xf = {}, {}, {}\n",
    "group_index, n_mom_groups = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'traces_hist_spectra_comp_grid.npz'\n",
    "force = False\n",
    "set_name = 'training'\n",
    "if not os.path.isfile(data_file) or force:\n",
    "    data_dir = '../data/IEEE39/converted_from_PowerFactory/all_stoch_loads/' + \\\n",
    "        'var_H_area_1_comp_grid/coarse_H_comp11_0.1/diagonal'\n",
    "    data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))\n",
    "    var_names = ['Vd_bus3']\n",
    "    generators_areas_map = [['G02', 'G03', 'Comp11'],\n",
    "                            ['G04', 'G05', 'G06', 'G07', 'Comp21'],\n",
    "                            ['G08', 'G09', 'G10', 'Comp31'],\n",
    "                            ['G01']]\n",
    "    generators_Pnom = {'G01': 10e9, 'G02': 700e6, 'G03': 800e6, 'G04': 800e6, 'G05': 300e6,\n",
    "                       'G06': 800e6, 'G07': 700e6, 'G08': 700e6, 'G09': 1000e6, 'G10': 1000e6,\n",
    "                       'Comp11': 100e6, 'Comp21': 100e6, 'Comp31': 100e6}\n",
    "    area_measure = 'momentum'\n",
    "    ret = load_data_areas({set_name: data_files}, var_names,\n",
    "                          generators_areas_map[:1],\n",
    "                          generators_Pnom,\n",
    "                          area_measure,\n",
    "                          trial_dur=60,\n",
    "                          max_block_size=1000,\n",
    "                          use_tf=False,\n",
    "                          add_omega_ref=True,\n",
    "                          use_fft=False)\n",
    "    t = ret[0]\n",
    "    X_raw = ret[1][set_name]\n",
    "    y[set_name] = ret[2][set_name]\n",
    "    group_index[set_name] = [np.where(y[set_name] == mom)[0] for mom in np.unique(y[set_name])]\n",
    "    n_mom_groups[set_name] = len(group_index[set_name])\n",
    "    X_mean, X_std = X_raw.mean(axis=(1,2)), X_raw.std(axis=(1,2))\n",
    "    X[set_name] = (X_raw - X_mean) / X_std\n",
    "    X[set_name] = X[set_name].squeeze()\n",
    "    y[set_name] = y[set_name].squeeze()\n",
    "\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    N_samples = t.size\n",
    "    Xf[set_name] = fft(X[set_name])\n",
    "    Xf[set_name] = 2.0 / N_samples * np.abs(Xf[set_name][:, :N_samples//2])\n",
    "    F = fftfreq(N_samples, dt)[:N_samples//2]\n",
    "\n",
    "    data_dir = '../data/IEEE39/converted_from_PowerFactory/all_stoch_loads/' + \\\n",
    "        'var_H_area_1_comp_grid/subset_8_H_comp11_0.1'\n",
    "    data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))\n",
    "    var_names = ['Vd_bus3']\n",
    "    ret = load_data_areas({set_name: data_files}, var_names,\n",
    "                          generators_areas_map[:1],\n",
    "                          generators_Pnom,\n",
    "                          area_measure,\n",
    "                          trial_dur=60,\n",
    "                          max_block_size=1000,\n",
    "                          use_tf=False,\n",
    "                          add_omega_ref=True,\n",
    "                          use_fft=False)    \n",
    "    X_raw = ret[1][set_name]\n",
    "    y['var_G2_G3'] = ret[2][set_name]\n",
    "    group_index['var_G2_G3'] = [np.where(y['var_G2_G3'] == mom)[0] for mom in np.unique(y['var_G2_G3'])]\n",
    "    n_mom_groups['var_G2_G3'] = len(group_index['var_G2_G3'])\n",
    "    X['var_G2_G3'] = (X_raw - X_mean) / X_std\n",
    "    X['var_G2_G3'] = X['var_G2_G3'].squeeze()\n",
    "    y['var_G2_G3'] = y['var_G2_G3'].squeeze()\n",
    "    Xf['var_G2_G3'] = fft(X['var_G2_G3'])\n",
    "    Xf['var_G2_G3'] = 2.0 / N_samples * np.abs(Xf['var_G2_G3'][:, :N_samples//2])\n",
    "\n",
    "    np.savez_compressed(data_file, t=t, X=X, y=y, Xf=Xf, F=F,\n",
    "                        group_index=group_index, n_mom_groups=n_mom_groups)\n",
    "else:\n",
    "    data = np.load(data_file, allow_pickle=True)\n",
    "    t = data['t']\n",
    "    X = data['X'].item()\n",
    "    y = data['y'].item()\n",
    "    F = data['F']\n",
    "    Xf = data['Xf'].item()\n",
    "    group_index = data['group_index'].item()\n",
    "    n_mom_groups = data['n_mom_groups'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplot_mosaic(\n",
    "    '''\n",
    "    AAAAAAAA\n",
    "    BBBBBCCC\n",
    "    DDDDEEEE\n",
    "    ''',\n",
    "    figsize=(3.5,4)\n",
    ")\n",
    "cmap = plt.get_cmap('Set1')\n",
    "N_div_cmap = 10\n",
    "div_cmap = plt.get_cmap('bwr', N_div_cmap)\n",
    "\n",
    "###########################################\n",
    "momentum = lambda H, S, fn: 2 * H@S / fn * 1e-3\n",
    "\n",
    "N = 11, 11\n",
    "h_G2_0, h_G3_0 = 4.33, 4.47\n",
    "h_G2 = h_G2_0 + np.linspace(-1, 1, N[0])\n",
    "h_G3 = h_G3_0 + np.linspace(-1, 1, N[1])\n",
    "H_G2, H_G3 = np.meshgrid(*[h_G2, h_G3])\n",
    "\n",
    "M = np.zeros(N)\n",
    "S = np.array([700, 800])\n",
    "fn = 60\n",
    "for i in range(N[0]):\n",
    "    for j in range(N[1]):\n",
    "        H = np.array([H_G2[i,j], H_G3[i,j]])\n",
    "        M[i,j] = momentum(H, S, fn)\n",
    "        \n",
    "gray_cmap = plt.get_cmap('gray')\n",
    "cont = ax['A'].contourf(H_G2, H_G3, M, levels=100, cmap=gray_cmap, zorder=-1)\n",
    "cbar = plt.colorbar(cont, ax=ax['A'])\n",
    "white = [1,1,1]\n",
    "magenta = [1,0,1]\n",
    "green = [0,1,0]\n",
    "yellow = [1,1,0]\n",
    "blue = [0,.5,1]\n",
    "red = [1,.333,.333]\n",
    "orange = [1, .5, 0]\n",
    "gray = [.6, .6, .6]\n",
    "zord = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax['A'].plot(H_G2[i,j], H_G3[i,j], 's', markersize=4, lw=1, color=div_cmap(i*2+j), zorder=zord)\n",
    "        ax['A'].plot(H_G2[-1-i,-1-j], H_G3[-1-i,-1-j], 's', markersize=4, lw=1,\n",
    "                     color=div_cmap(N_div_cmap-1-i*2-j), zorder=zord)\n",
    "        zord += 2\n",
    "for i in range(0, N[0], 2):\n",
    "    ax['A'].plot(H_G2[i,i], H_G3[i,i], 'o', color=cmap(i//2), markersize=3, lw=1, zorder=zord)\n",
    "    zord += 1\n",
    "ax['A'].plot(H_G2[:2,:2].mean(), H_G3[:2,:2].mean(), 'x', color=magenta, markersize=4,\n",
    "             markeredgewidth=1, zorder=zord)\n",
    "zord += 1\n",
    "ax['A'].plot(H_G2[-2:,-2:].mean(), H_G3[-2:,-2:].mean(), 'x', color=magenta, markersize=4,\n",
    "             markeredgewidth=1, zorder=zord)\n",
    "zord += 1\n",
    "ax['A'].scatter(H_G2[::2, ::2], H_G3[::2, ::2], s=5, c='w', edgecolors='k', lw=0.5, marker='o', zorder=zord)\n",
    "ax['A'].set_xlabel(r'$H_{G_2}$ [s]')\n",
    "ax['A'].set_ylabel(r'$H_{G_3}$ [s]')\n",
    "ax['A'].set_xlim([h_G2_0 - 1.1, h_G2_0 + 1.1])\n",
    "ax['A'].set_ylim([h_G3_0 - 1.1, h_G3_0 + 1.1])\n",
    "ax['A'].set_xticks([h_G2_0 - 1, h_G2_0, h_G2_0 + 1])\n",
    "ax['A'].set_yticks([h_G3_0 - 1, h_G3_0, h_G3_0 + 1])\n",
    "cbar.set_label(r'Momentum [GW$\\cdot$s$^2$]')\n",
    "cbar.set_ticks(np.r_[0.17 : 0.28 : 0.02])\n",
    "###########################################\n",
    "\n",
    "tend = 10\n",
    "jdx, = np.where(t < tend)\n",
    "for i,idx in enumerate(group_index[set_name]):\n",
    "    n,edges = np.histogram(X[set_name][idx,:], bins=50, density=True)\n",
    "    ax['B'].plot(t[jdx], X[set_name][idx[0]+1, jdx], lw=1, color=cmap(i))\n",
    "    ax['C'].plot(n, edges[1:], lw=1, color=cmap(i))\n",
    "    ax['D'].plot(F, 20 * np.log10(Xf[set_name][idx,:].mean(axis=0)), lw=1,\n",
    "               color=cmap(i), label=r'{:.3f} GW$\\cdot$s$^2$'.format(y[set_name][idx[0]+1]))\n",
    "\n",
    "for i,idx in enumerate(group_index['var_G2_G3']):\n",
    "    if i < 4:\n",
    "        ax['E'].plot(F, 20 * np.log10(Xf['var_G2_G3'][idx,:].mean(axis=0)), lw=1,\n",
    "                   color=div_cmap(i))\n",
    "    else:\n",
    "        ax['E'].plot(F, 20 * np.log10(Xf['var_G2_G3'][idx,:].mean(axis=0)), lw=1,\n",
    "                   color=div_cmap(N_div_cmap - (i - 3)))\n",
    "\n",
    "for key in 'BC':\n",
    "    ax[key].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "for key in 'DE':\n",
    "    ax[key].grid(which='major', axis='x', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "for a in ax.values():\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "for key in 'BC':\n",
    "    ax[key].set_ylim([-3.5, 3.5])\n",
    "    ax[key].set_yticks(np.r_[-3 : 4 : 1.5])\n",
    "for key in 'DE':\n",
    "    ax[key].set_ylim([-55, -10])\n",
    "    ax[key].set_yticks(np.r_[-50 : -9 : 10])\n",
    "    ax[key].set_xscale('log')\n",
    "    ax[key].set_xlabel('Frequency [Hz]')\n",
    "    ticks = np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20])\n",
    "    ax[key].set_xlim(ticks[[0,-1]] + np.array([0,1]))\n",
    "    ax[key].xaxis.set_major_locator(FixedLocator(ticks))\n",
    "    ax[key].xaxis.set_minor_locator(NullLocator())\n",
    "    ax[key].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "ax['C'].set_yticklabels([])\n",
    "ax['E'].set_yticklabels([])\n",
    "\n",
    "ax['B'].set_xlabel('Time [s]')\n",
    "ax['B'].set_ylabel('Norm. V')\n",
    "ax['C'].set_xlabel('Distr.')\n",
    "ax['D'].set_ylabel('Power [dB]')\n",
    "\n",
    "ticks = np.r_[0 : 10.5 : 2]\n",
    "ax['B'].set_xlim(ticks[[0,-1]])\n",
    "ax['B'].xaxis.set_major_locator(FixedLocator(ticks))\n",
    "ax['B'].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "\n",
    "ticks = np.r_[0 : 0.51 : 0.25]\n",
    "ax['C'].set_xlim(ticks[[0,-1]])\n",
    "ax['C'].xaxis.set_major_locator(FixedLocator(ticks))\n",
    "ax['C'].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-0.45, -0.05, fig.dpi_scale_trans)\n",
    "for label in 'ABD':\n",
    "    ax[label].text(0.0, 1.0, label, transform=ax[label].transAxes + trans, fontsize=10, va='bottom')\n",
    "trans = mtransforms.ScaledTranslation(-0.15, -0.05, fig.dpi_scale_trans)\n",
    "for label in 'CE':\n",
    "    ax[label].text(0.0, 1.0, label, transform=ax[label].transAxes + trans, fontsize=10, va='bottom')\n",
    "\n",
    "fig.tight_layout(pad=0)\n",
    "plt.savefig('traces_hist_spectra_comp_grid.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ID = '474d2016e33b441889ce8b17531487cb' # replaces '98475b819ecb4d569646d7e1467d7c9c'\n",
    "# experiment_ID = 'd0e4cb94211c4190828fd8cd856cdd94' # replaces 'ed79ae2784274401a9dba5f5ccee98d8'\n",
    "experiments_path = '../experiments/neural_network/'\n",
    "history = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'history.pkl'), 'rb'))\n",
    "test_results = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'test_results.pkl'), 'rb'))\n",
    "N_bands = 40\n",
    "filter_order = 6\n",
    "if experiment_ID == '474d2016e33b441889ce8b17531487cb': # replaces '98475b819ecb4d569646d7e1467d7c9c'\n",
    "    N_trials = 4000\n",
    "elif experiment_ID == 'd0e4cb94211c4190828fd8cd856cdd94': # replaces 'ed79ae2784274401a9dba5f5ccee98d8'\n",
    "    N_trials = 1000\n",
    "else:\n",
    "    raise Exception(f'Unknown number of trials for experiment {experiment_ID[:6]}')\n",
    "correlations_file = f'correlations_{experiment_ID[:6]}_{N_bands}-bands_64-filters_' + \\\n",
    "    f'36-neurons_{N_trials}-trials_{filter_order}-butter_Vd_bus3_pool_1_3.npz'\n",
    "correlations = np.load(os.path.join(experiments_path, experiment_ID, correlations_file))\n",
    "for key in correlations.files:\n",
    "    exec(f'{key} = correlations[\"{key}\"]')\n",
    "corr_idx = idx\n",
    "corr_edges = edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'var_G2_G3'\n",
    "\n",
    "fig = plt.figure(figsize=(3.5 * 2, 4))\n",
    "\n",
    "offset = 0.07, 0.1\n",
    "border = 0.01, 0.02\n",
    "space = ((0.05, 0.1, 0.1), (0.075, 0.075, 0.13)), 0.17\n",
    "rows = 2\n",
    "h = (1 - offset[1] - border[1] - space[1] * (rows-1)) / rows\n",
    "w_rel = [\n",
    "    [3, 2, 3, 2],\n",
    "    [2, 3, 3, 2]\n",
    "]\n",
    "\n",
    "w_rel_sum = np.sum(w_rel, axis=1)\n",
    "cols = list(map(len, w_rel))\n",
    "w_total = [1 - offset[0] - border[0] - np.sum(sp) for sp in space[0]]\n",
    "w = []\n",
    "for i in range(rows):\n",
    "    w.append([])\n",
    "    for j in range(cols[i]):\n",
    "        w[-1].append(w_total[i] * w_rel[i][j] / w_rel_sum[i])\n",
    "\n",
    "labels = ['ABCD','EFGH']\n",
    "ax = {}\n",
    "for i in range(rows):\n",
    "    for j in range(cols[i]):\n",
    "        ax[labels[i][j]] = fig.add_axes([offset[0] + np.sum(space[0][i][:j]) + np.sum(w[i][:j]),\n",
    "                                         1 - border[1] - h * (i+1) - space[1] * i,\n",
    "                                         w[i][j],\n",
    "                                         h])\n",
    "\n",
    "# ############# Panel A #############\n",
    "cmap = plt.get_cmap('tab10')\n",
    "green, magenta = cmap(2), cmap(6)\n",
    "jdx, = np.where(t < tend)\n",
    "ax['A'].plot(t[jdx], X[key][:5, jdx].T, color=green, lw=0.5)\n",
    "ax['A'].plot(t[jdx], X[key][-10:-5, jdx].T, color=magenta, lw=0.5)\n",
    "\n",
    "# ############# Panel B #############\n",
    "idx = np.concatenate(group_index[key][:4])\n",
    "n,edges = np.histogram(X[key][idx,:], bins=50, density=True)\n",
    "ax['B'].plot(n, edges[1:], lw=1, color=green)\n",
    "m = Xf[key][idx,:].mean(axis=0)\n",
    "ci = 1.96 * Xf[key][idx,:].std(axis=0) / np.sqrt(idx.size)\n",
    "ax['E'].plot(20 * np.log10(m), F, color=green, lw=1)\n",
    "idx = np.concatenate(group_index[key][4:])\n",
    "n,edges = np.histogram(X[key][idx,:], bins=50, density=True)\n",
    "ax['B'].plot(n, edges[1:], lw=1, color=magenta)\n",
    "m = Xf[key][idx,:].mean(axis=0)\n",
    "ci = 1.96 * Xf[key][idx,:].std(axis=0) / np.sqrt(idx.size)\n",
    "ax['E'].plot(20 * np.log10(m), F, color=magenta, lw=1)\n",
    "ax['B'].set_xlim([0, 0.5])\n",
    "ticks = np.r_[0 : 0.51 : 0.25]\n",
    "ax['B'].xaxis.set_major_locator(FixedLocator(ticks))\n",
    "ax['B'].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "ax['B'].set_yticklabels([])\n",
    "\n",
    "# ############# Panel C #############\n",
    "ax['C'].plot(history['loss'], 'k', lw=1, label='Training')\n",
    "ax['C'].plot(history['val_loss'], 'r', lw=1, label='Validation')\n",
    "ax['C'].legend(loc='upper right', frameon=False, fontsize=fontsize)\n",
    "\n",
    "# ############# Panel D #############\n",
    "target_values = np.unique(exact_momentum)\n",
    "df = pd.DataFrame(data={'exact': exact_momentum, 'pred': np.concatenate(pred_momentum)})\n",
    "df_ctrl = pd.DataFrame(data={'exact': exact_momentum, 'pred': np.concatenate(pred_momentum_ctrl)})\n",
    "# sns.violinplot(x='exact', y='pred', data=df_ctrl, cut=0, inner='quartile',\n",
    "#                palette='gray', ax=ax['D'], linewidth=0.5)\n",
    "sns.violinplot(x='exact', y='pred', data=df, cut=0, inner='quartile',\n",
    "               palette=[green, magenta], ax=ax['D'], linewidth=0.5)\n",
    "ax['D'].xaxis.set_major_locator(FixedLocator([0, 1]))\n",
    "ax['D'].xaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in target_values]))\n",
    "ax['D'].yaxis.set_major_locator(FixedLocator(target_values))\n",
    "ax['D'].yaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in target_values]))\n",
    "\n",
    "# ############# Panels F, G ########\n",
    "plot_correlations(R, p, R_ctrl, p_ctrl, corr_edges,\n",
    "                  [np.concatenate(corr_idx)], sort_freq=[1.1],\n",
    "                  ax=np.array([[ax['F'], ax['G'], ax['H']]]))\n",
    "ax['H'].plot(np.zeros(2), ax['H'].get_ylim(), ':', lw=1, color=[.6,.6,.6])\n",
    "ax['F'].set_title('Trained network', fontsize=fontsize+1)\n",
    "ax['G'].set_title('Untrained network', fontsize=fontsize+1)\n",
    "\n",
    "for label in 'AB':\n",
    "    ax[label].set_ylim([-3.5, 3.5])\n",
    "    ax[label].set_yticks(np.r_[-3 : 3.1])\n",
    "\n",
    "for label in 'ABE':\n",
    "    ax[label].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "\n",
    "for a in ax.values():\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "for label in 'EFG':\n",
    "    ax[label].set_yscale('log')\n",
    "    ax[label].set_ylim([0.05, 20])\n",
    "\n",
    "# ax['E'].invert_xaxis()\n",
    "# ax['E'].yaxis.tick_right()\n",
    "# ax['E'].spines['right'].set_visible(True)\n",
    "# ax['E'].spines['left'].set_visible(False)\n",
    "ax['E'].set_xlim([-10, -55])\n",
    "ax['E'].set_xticks(np.r_[-50 : -9 : 10])\n",
    "\n",
    "for label in 'EFGH':\n",
    "    ticks = np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20])\n",
    "    ax[label].set_ylim(ticks[[0,-1]])\n",
    "    ax[label].yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    ax[label].yaxis.set_minor_locator(NullLocator())\n",
    "    if label == 'F' or True:\n",
    "        ax[label].yaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "\n",
    "ax['A'].set_xlabel('Time [s]')\n",
    "ax['A'].set_ylabel('Norm. V')\n",
    "ax['B'].set_xlabel('Distribution')\n",
    "ax['C'].set_xlabel('Epoch')\n",
    "ax['C'].set_ylabel('Loss')\n",
    "ax['D'].set_xlabel(r'Exact M [GW$\\cdot$s$^2$]')\n",
    "ax['D'].set_ylabel(r'Predicted M [GW$\\cdot$s$^2$]')\n",
    "ax['E'].set_xlabel('Power [dB]')\n",
    "ax['E'].set_ylabel('Frequency [Hz]')\n",
    "ax['F'].set_xlabel('Filter #')\n",
    "ax['G'].set_xlabel('Filter #')\n",
    "ax['H'].set_xlabel('Correlation')\n",
    "ax['F'].set_xticklabels([1, 32, 64])\n",
    "ax['G'].set_xticklabels([1, 32, 64])\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-0.2, -0.05, fig.dpi_scale_trans)\n",
    "ax['B'].text(0.0, 1.0, 'B', transform=ax['B'].transAxes + trans, fontsize=10, va='bottom')\n",
    "trans = mtransforms.ScaledTranslation(-0.55, -0.05, fig.dpi_scale_trans)\n",
    "ax['C'].text(0.0, 1.0, 'C', transform=ax['C'].transAxes + trans, fontsize=10, va='bottom')\n",
    "trans = mtransforms.ScaledTranslation(-0.4, -0.05, fig.dpi_scale_trans)\n",
    "for label in 'ADEFGH':\n",
    "    ax[label].text(0.0, 1.0, label, transform=ax[label].transAxes + trans, fontsize=10, va='bottom')\n",
    "\n",
    "plt.savefig(f'low_high_momentum_{experiment_ID[:6]}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(experiments_path, experiment_ID, 'stopband_momentum_estimation.npz'))\n",
    "for key in data.files:\n",
    "    exec(f'{key} = data[\"{key}\"]')\n",
    "N_bands = len(bands)\n",
    "Xfm = np.zeros((len(group_index), F.size))\n",
    "Xfci = np.zeros((len(group_index), F.size))\n",
    "for i,idx in enumerate(group_index):\n",
    "    Xfm[i] = Xf[idx].mean(axis=0)\n",
    "    Xfci[i] = 1.96 * Xf[idx].std(axis=0) / np.sqrt(idx.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplot_mosaic(\n",
    "    '''\n",
    "    AAAA.\n",
    "    BBBB.\n",
    "    ''',\n",
    "    figsize=(3.5,4)\n",
    ")\n",
    "\n",
    "cmap2 = plt.get_cmap('Set1')\n",
    "y_m = [y[idx].mean() for idx in group_index]\n",
    "y_s = [y[idx].std() for idx in group_index]\n",
    "y_pred_m = np.array([[pred[jdx].mean() for jdx in group_index] for pred in y_pred])\n",
    "y_pred_s = np.array([[pred[jdx].std() for jdx in group_index] for pred in y_pred])\n",
    "add_band = False\n",
    "last_band = N_bands + 1 if add_band else N_bands + 1\n",
    "for i in range(last_band):\n",
    "    if i == 0:\n",
    "        lbl = 'Broadband'\n",
    "    else:\n",
    "        lbl = f'[{bands[i-1][0]}-{bands[i-1][1]:g}] Hz'\n",
    "    ax['A'].plot(y_m, y_pred_m[i], color=cmap2(i), lw=1, label=lbl)\n",
    "    for j in range(len(group_index)):\n",
    "        ax['A'].plot(y_m[j] + np.zeros(2),\n",
    "                   y_pred_m[i,j] + y_pred_s[i,j] * np.array([-1,1]),\n",
    "                   color=cmap2(i), lw=1)\n",
    "        ax['A'].plot(y_m[j] + y_s[j] * np.array([-1,1]),\n",
    "                   y_pred_m[i,j] + np.zeros(2),\n",
    "                   color=cmap2(i), lw=1)\n",
    "        ax['A'].plot(y_m[j], y_pred_m[i,j], 'o', color=cmap2(i),\n",
    "                   markerfacecolor='w', markersize=4, markeredgewidth=1)\n",
    "for side in 'right','top':\n",
    "    ax['A'].spines[side].set_visible(False)\n",
    "ax['A'].legend(loc='center left', bbox_to_anchor=[0.875, 0.5], frameon=False, fontsize=fontsize-1)\n",
    "ax['A'].set_xlabel(r'Exact M [GW$\\cdot$s$^2$]')\n",
    "ax['A'].set_ylabel(r'Predicted M [GW$\\cdot$s$^2$]')\n",
    "ax['A'].set_xlim(y_m + np.diff(y_m) * np.array([-1/10, 1/5]))\n",
    "ax['A'].set_ylim(y_m + np.diff(y_m) / 3 * np.array([-1,1]))\n",
    "ax['A'].xaxis.set_major_locator(FixedLocator(y_m))\n",
    "ax['A'].xaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in y_m]))\n",
    "ax['A'].yaxis.set_major_locator(FixedLocator(y_m))\n",
    "ax['A'].yaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in y_m]))\n",
    "\n",
    "axr = ax['B'].twinx()\n",
    "for i,(m,ci,col) in enumerate(zip(Xfm, Xfci, (green,magenta))):\n",
    "    ax['B'].plot(F, 20*np.log10(m), color=col,\n",
    "                 label=r'M = {:.2f} GW$\\cdot$s$^2$'.format(y[group_index[i]].mean()))\n",
    "ax['B'].legend(loc='lower left', frameon=False, fontsize=fontsize-1, bbox_to_anchor=[0.0, 0.13])\n",
    "axr.plot(ax['B'].get_xlim(), scores[0] + np.zeros(2), '--', color=cmap2(0), lw=2)\n",
    "for i,band in enumerate(bands):\n",
    "    if i >= last_band-1:\n",
    "        break\n",
    "    axr.axvline(band[0], color=[.6,.6,.6], ls=':', lw=0.5)\n",
    "    axr.plot(band, scores[i+1] + np.zeros(2), color=cmap2(i+1), lw=2)\n",
    "ax['B'].set_xlabel('Frequency [Hz]')\n",
    "ax['B'].set_ylabel('Power [dB]')\n",
    "axr.set_ylabel(r'R$^2$ score')\n",
    "ax['B'].set_xscale('log')\n",
    "\n",
    "ticks = np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20])\n",
    "ax['B'].set_xlim(ticks[[0,-1]] + np.array([0,1]))\n",
    "ax['B'].xaxis.set_major_locator(FixedLocator(ticks))\n",
    "ax['B'].xaxis.set_minor_locator(NullLocator())\n",
    "ax['B'].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "axr.set_ylim((-0.25, 1.05))\n",
    "axr.set_yticks(np.r_[-0.2 : 1.05 : 0.2])\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-0.45, -0.05, fig.dpi_scale_trans)\n",
    "for label in 'AB':\n",
    "    ax[label].text(0.0, 1.0, label, transform=ax[label].transAxes + trans, fontsize=10, va='bottom')\n",
    "\n",
    "fig.tight_layout(pad=0.2)\n",
    "if add_band:\n",
    "    fig.savefig(f'stopband_momentum_estimation_{experiment_ID}_{last_band}.pdf')\n",
    "else:\n",
    "    fig.savefig(f'stopband_momentum_estimation_{experiment_ID[:6]}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = np.load(os.path.join(experiments_path, experiment_ID, 'layer_outputs.npz'))\n",
    "multi_output = {}\n",
    "for key in data.files:\n",
    "    if 'multi_output' in key:\n",
    "        i = int(key.split('_')[-1])\n",
    "        multi_output[i] = data[key]\n",
    "    else:\n",
    "        exec(f'{key} = data[\"{key}\"]')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w, h = 3/2.54, 1.5/2.54\n",
    "rows, cols = len(multi_output), 5\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(cols*w, rows*h))\n",
    "for i in range(rows):\n",
    "    dst = np.abs(np.diff(np.array([multi_output[i][idx,:,:].mean(axis=(0,1)) \\\n",
    "                                   for idx in group_index]), axis=0)).squeeze()\n",
    "    idx = np.argsort(dst)[::-1]\n",
    "    tmp = multi_output[i][:, :, idx]\n",
    "    _,_ = plot_layer_output_hist(tmp, group_index, N_bins=16, ax=ax[i],\n",
    "                                 labels=[f'#{j}' for j in idx],\n",
    "                                 cmap = lambda i: [green, magenta][i])\n",
    "    ss = layer_names[i+1].split('_')\n",
    "    lbl = ' '.join([ss[2].capitalize(), ss[4]])\n",
    "    ax[i,0].set_ylabel(lbl)\n",
    "fig.tight_layout(pad=0.5)\n",
    "fig.savefig(f'layer_outputs_distr_{experiment_ID[:6]}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following experiment IDs replace the previously used ones:\n",
    "# '98475b819ecb4d569646d7e1467d7c9c' and '302a21340f354ac2949184be98d8e907'\n",
    "experiment_IDs = '474d2016e33b441889ce8b17531487cb', 'c6f72abb5e364c4cb7770250e135bd73'\n",
    "experiments_path = '../experiments/neural_network/'\n",
    "\n",
    "data, correlations = {}, {}\n",
    "N_bands = 40\n",
    "filter_order = 6\n",
    "for experiment_ID,N_trials in zip(experiment_IDs, (4000,4000)):\n",
    "    key = experiment_ID[:6]\n",
    "    tmp = np.load(os.path.join(experiments_path, experiment_ID, f'variable_inertia_{key}.npz'),\n",
    "                  allow_pickle=True)\n",
    "    data[key] = {}\n",
    "    for fname in tmp.files:\n",
    "        try:\n",
    "            exec(f'data[\"{key}\"][\"{fname}\"] = tmp[\"{fname}\"].item()')\n",
    "        except:\n",
    "            exec(f'data[\"{key}\"][\"{fname}\"] = tmp[\"{fname}\"]')\n",
    "    correlations_file = f'correlations_{key}_{N_bands}-bands_64-filters_' + \\\n",
    "        f'36-neurons_{N_trials}-trials_{filter_order}-butter_Vd_bus3_pool_1_3.npz'\n",
    "    correlations[key] = np.load(os.path.join(experiments_path, experiment_ID, correlations_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.5*1.8,4))\n",
    "\n",
    "cols = 2\n",
    "offset = np.array([[0.075, 0.1], [0.14, 0.03]])\n",
    "space = {\n",
    "    'AB': 0.125,\n",
    "    'BC': 0.05,\n",
    "    'LR': 0.1,\n",
    "    'DE': 0.125,\n",
    "    'EF': 0.035\n",
    "}\n",
    "width = {'A': 0.4}\n",
    "height = {'A': 0.4}\n",
    "width['B'] = (width['A'] - space['BC']) / 2\n",
    "width['C'] = width['B']\n",
    "height['B'] = 1 - np.sum(offset[:,1]) - height['A'] - space['AB']\n",
    "height['C'] = height['B']\n",
    "width['D'] = 1 - np.sum(offset[:,0]) - space['LR'] - width['A'] + 0.1\n",
    "width['E'], width['F'] = width['D'] - 0.06, width['D']\n",
    "height['D'] = (1 - np.sum(offset[:,1]) - space['DE'] - space['EF']) / 2.5\n",
    "height['E'] = (1 - np.sum(offset[:,1]) - space['DE'] - space['EF'] - height['D']) / 2\n",
    "height['F'] = height['E']\n",
    "\n",
    "ax = {\n",
    "    'A': plt.axes([offset[0,0],\n",
    "                   offset[0,1] + space['AB'] + height['B'],\n",
    "                   width['A'], height['A']]),\n",
    "    'B': plt.axes([offset[0,0],\n",
    "                   offset[0,1],\n",
    "                   width['B'],\n",
    "                   height['B']]),\n",
    "    'C': plt.axes([offset[0,0] + space['BC'] + width['B'],\n",
    "                   offset[0,1],\n",
    "                   width['C'], height['C']]),\n",
    "    'D': plt.axes([offset[0,0] + width['A'] + space['LR'],\n",
    "                   offset[0,1] + 2*height['E'] + space['EF'] + space['DE'],\n",
    "                   width['D'], height['D']]),\n",
    "    'E': plt.axes([offset[0,0] + width['A'] + space['LR'],\n",
    "                   offset[0,1] + height['F'] + space['EF'],\n",
    "                   width['E'], height['E']]),\n",
    "    'F': plt.axes([offset[0,0] + width['A'] + space['LR'],\n",
    "                   offset[0,1],\n",
    "                   width['F'], height['F']]),\n",
    "}\n",
    "\n",
    "cmap_name = 'tab10'\n",
    "cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "################### Panels A, B and C ###################\n",
    "key = experiment_IDs[0][:6]\n",
    "xticks = {'A': np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20]),\n",
    "          'B': np.array([0.4, 0.5, 0.7, 1, 1.5]),\n",
    "          'C': np.array([8, 10, 12, 15])}\n",
    "yticks = {'A': np.r_[-60 : -5 : 10],\n",
    "          'B': np.r_[-30 : -9 : 5],\n",
    "          'C': np.r_[-56 : -44 : 3]}\n",
    "for a in 'ABC':\n",
    "    n = 0\n",
    "    for i,(k,v) in enumerate(data[key]['Xf'].items()):\n",
    "        for j in range(data[key]['n_mom_groups'][k]):\n",
    "            lbl = r'{:.3f} GW$\\cdot$s$^2$'.format(data[key]['ym'][k][j])\n",
    "            if k == 'var_G2_G3':\n",
    "                lbl += ' (GEN)'\n",
    "            elif k == 'var_Comp11':\n",
    "                lbl += ' (COMP)'\n",
    "            m = v[data[key]['group_index'][k][j], :].mean(axis=0)\n",
    "            s = v[data[key]['group_index'][k][j], :].std(axis=0)\n",
    "            ci = 1.96 * s / np.sqrt(data[key]['group_index'][k][j].size)\n",
    "            ax[a].fill_between(data[key]['F'],\n",
    "                               20*np.log10(m + ci),\n",
    "                               20*np.log10(m - ci),\n",
    "                               color=cmap(n), facecolor=cmap(n), edgecolor=cmap(n),\n",
    "                               alpha=0.5, label=lbl)\n",
    "            n += 1\n",
    "    ax[a].set_xscale('log')\n",
    "    ax[a].set_xlabel('Frequency [Hz]')\n",
    "    for side in 'right','top':\n",
    "        ax[a].spines[side].set_visible(False)\n",
    "    ax[a].set_xlim(xticks[a][[0,-1]] + np.array([0,1]))\n",
    "    ax[a].xaxis.set_major_locator(FixedLocator(xticks[a]))\n",
    "    ax[a].xaxis.set_minor_locator(NullLocator())\n",
    "    ax[a].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in xticks[a]]))\n",
    "    ax[a].yaxis.set_major_locator(FixedLocator(yticks[a]))\n",
    "    ax[a].yaxis.set_minor_locator(NullLocator())\n",
    "    ax[a].yaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in yticks[a]]))\n",
    "\n",
    "ax['A'].legend(loc='lower left', frameon=False, fontsize=6)\n",
    "ax['A'].set_ylabel('Power [dB]')\n",
    "ax['B'].set_ylabel('Power [dB]')\n",
    "ax['A'].set_ylim([-60, -10])\n",
    "ax['B'].set_xlim([0.4, 1.5])\n",
    "ax['C'].set_xlim([8, 15])\n",
    "ax['B'].set_ylim([-31, -9])\n",
    "ax['C'].set_ylim([-57, -46])\n",
    "\n",
    "################### Panel D ###################\n",
    "key = experiment_IDs[0][:6]\n",
    "ax['D'].plot(data[key]['ym']['test'], data[key]['ym']['test'], 'k--', lw=2, markerfacecolor='w')\n",
    "m = 'so'\n",
    "markers = {ID[:6]: m[i] for i,ID in enumerate(experiment_IDs)}\n",
    "lw, ms = 1, 6\n",
    "for ID in experiment_IDs:\n",
    "    n = 0\n",
    "    key = ID[:6]\n",
    "    ym = data[key]['ym']\n",
    "    ym_pred = data[key]['ym_pred']\n",
    "    ys_pred = data[key]['ys_pred']\n",
    "    for cond in ym:\n",
    "        for i in range(len(ym[cond])):\n",
    "            ax['D'].plot(ym[cond][i] + np.zeros(2),\n",
    "                         ym_pred[cond][i] + ys_pred[cond][i] * np.array([-1,1]),\n",
    "                         color=cmap(n), linewidth=lw)\n",
    "            ax['D'].plot(ym[cond][i], ym_pred[cond][i], markers[key], color=cmap(n), markersize=ms,\n",
    "                     markerfacecolor='w', markeredgewidth=lw)\n",
    "            n += 1\n",
    "ax['D'].plot(1, 1, 'k'+m[0], markersize=ms, markerfacecolor='w',\n",
    "             markeredgewidth=lw, label='without var. comp. in tr.')\n",
    "ax['D'].plot(1, 1, 'k'+m[1], markersize=ms, markerfacecolor='w',\n",
    "             markeredgewidth=lw, label='with var. comp. in tr.')\n",
    "ax['D'].legend(loc='lower right', frameon=False, fontsize=fontsize-1, bbox_to_anchor=[1, -0.05])\n",
    "ax['D'].set_xlabel(r'Exact M [GW$\\cdot$s$^2$]')\n",
    "ax['D'].set_ylabel(r'Predicted M [GW$\\cdot$s$^2$]')\n",
    "ym = ym['test']\n",
    "ticks = [ym[0], 0.197, ym[1]]\n",
    "ax['D'].set_xlim(ym + np.diff(ym) * np.array([-1/10, 1/10]))\n",
    "ax['D'].set_ylim(ym + np.diff(ym) * np.array([-1/10, 1/10]))\n",
    "ax['D'].xaxis.set_major_locator(FixedLocator(ticks))\n",
    "ax['D'].xaxis.set_major_formatter(FixedFormatter([f'{tick:.3f}' for tick in ticks]))\n",
    "ax['D'].yaxis.set_major_locator(FixedLocator(ticks))\n",
    "ax['D'].yaxis.set_major_formatter(FixedFormatter([f'{tick:.3f}' for tick in ticks]))\n",
    "\n",
    "################### Panels E and F ###################\n",
    "key = experiment_IDs[1][:6]\n",
    "plot_correlations(correlations[key]['R'],\n",
    "                  correlations[key]['p'],\n",
    "                  None,\n",
    "                  None,\n",
    "                  correlations[key]['edges'],\n",
    "                  [np.concatenate(correlations[key]['idx'])],\n",
    "                  sort_freq=[1.5],\n",
    "                  ax=np.array([[ax['E']]]))\n",
    "plot_correlations(correlations[key]['R'],\n",
    "                  correlations[key]['p'],\n",
    "                  None,\n",
    "                  None,\n",
    "                  correlations[key]['edges'],\n",
    "                  [np.concatenate(correlations[key]['idx'])],\n",
    "                  sort_freq=[10],\n",
    "                  ax=np.array([[ax['F'], ax['F']]]))\n",
    "\n",
    "for lbl in 'EF':\n",
    "    ax[lbl].set_ylim(xticks['A'][[0,-1]] + np.array([0,1]))\n",
    "    ax[lbl].yaxis.set_major_locator(FixedLocator(xticks['A']))\n",
    "    ax[lbl].yaxis.set_minor_locator(NullLocator())\n",
    "    ax[lbl].yaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in xticks['A']]))\n",
    "    ax[lbl].set_ylabel('Frequency [Hz]')\n",
    "    ax[lbl].set_xticks([1, 32, 64])\n",
    "ax['E'].set_xticklabels([])\n",
    "ax['F'].set_xlabel('Filter #')\n",
    "\n",
    "for lbl in ax:\n",
    "    for side in 'right','top':\n",
    "        ax[lbl].spines[side].set_visible(False)\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-0.4, -0.04, fig.dpi_scale_trans)\n",
    "ax['A'].text(0.0, 1.0, 'A', transform=ax['A'].transAxes + trans,\n",
    "             fontsize=10, va='bottom')\n",
    "trans = mtransforms.ScaledTranslation(-0.45, -0.04, fig.dpi_scale_trans)\n",
    "for key,lbl in zip('DEF', 'BCD'):\n",
    "    ax[key].text(0.0, 1.0, lbl, transform=ax[key].transAxes + trans,\n",
    "                 fontsize=10, va='bottom')\n",
    "\n",
    "pdf_file = f'variable_inertia_{experiment_IDs[0][:6]}_{experiment_IDs[1][:6]}.pdf'\n",
    "fig.savefig(pdf_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig,ax = plt.subplot_mosaic(\n",
    "    '''\n",
    "    AAABBBCC\n",
    "    DDDEEEFF\n",
    "    ''',\n",
    "    figsize=(3.5 * 1.8, 3.5)\n",
    ")\n",
    "\n",
    "cmap_name = 'tab10'\n",
    "cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "################### Panels A and B ###################\n",
    "key = experiment_IDs[0][:6]\n",
    "ticks = {'A': np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20]),\n",
    "         'B': np.array([0.4, 0.5, 0.7, 1, 1.5])}\n",
    "for a in 'AB':\n",
    "    n = 0\n",
    "    for i,(k,v) in enumerate(data[key]['Xf'].items()):\n",
    "        for j in range(data[key]['n_mom_groups'][k]):\n",
    "            lbl = r'{:.3f} GW$\\cdot$s$^2$'.format(data[key]['ym'][k][j])\n",
    "            if k == 'var_G2_G3':\n",
    "                lbl += ' (GEN)'\n",
    "            elif k == 'var_Comp11':\n",
    "                lbl += ' (COMP)'\n",
    "            m = v[data[key]['group_index'][k][j], :].mean(axis=0)\n",
    "            s = v[data[key]['group_index'][k][j], :].std(axis=0)\n",
    "            ci = 1.96 * s / np.sqrt(data[key]['group_index'][k][j].size)\n",
    "            ax[a].fill_between(data[key]['F'],\n",
    "                               20*np.log10(m + ci),\n",
    "                               20*np.log10(m - ci),\n",
    "                               color=cmap(n), facecolor=cmap(n), edgecolor=cmap(n),\n",
    "                               alpha=0.5, label=lbl)\n",
    "            n += 1\n",
    "    ax[a].set_xscale('log')\n",
    "    ax[a].set_xlabel('Frequency [Hz]')\n",
    "    for side in 'right','top':\n",
    "        ax[a].spines[side].set_visible(False)\n",
    "    ax[a].set_xlim(ticks[a][[0,-1]] + np.array([0,1]))\n",
    "    ax[a].xaxis.set_major_locator(FixedLocator(ticks[a]))\n",
    "    ax[a].xaxis.set_minor_locator(NullLocator())\n",
    "    ax[a].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks[a]]))\n",
    "ax['A'].legend(loc='lower left', frameon=False, fontsize=6)\n",
    "ax['A'].set_ylabel('Power [dB]')\n",
    "ax['A'].set_ylim([-60, -10])\n",
    "ax['B'].set_xlim([0.4, 1.5])\n",
    "ax['B'].set_ylim([-33, -10])\n",
    "\n",
    "################### Panel C ###################\n",
    "key = experiment_IDs[0][:6]\n",
    "ax['C'].plot(data[key]['ym']['test'], data[key]['ym']['test'], 'k--', lw=2, markerfacecolor='w')\n",
    "m = 'so'\n",
    "markers = {ID[:6]: m[i] for i,ID in enumerate(experiment_IDs)}\n",
    "lw, ms = 2, 6\n",
    "for ID in experiment_IDs:\n",
    "    n = 0\n",
    "    key = ID[:6]\n",
    "    ym = data[key]['ym']\n",
    "    ym_pred = data[key]['ym_pred']\n",
    "    ys_pred = data[key]['ys_pred']\n",
    "    for cond in ym:\n",
    "        for i in range(len(ym[cond])):\n",
    "            ax['C'].plot(ym[cond][i] + np.zeros(2),\n",
    "                         ym_pred[cond][i] + ys_pred[cond][i] * np.array([-1,1]),\n",
    "                         color=cmap(n), linewidth=lw)\n",
    "            ax['C'].plot(ym[cond][i], ym_pred[cond][i], markers[key], color=cmap(n), markersize=ms,\n",
    "                     markerfacecolor='w', markeredgewidth=lw)\n",
    "            n += 1\n",
    "ax['C'].set_xlabel(r'Exact M [GW$\\cdot$s$^2$]')\n",
    "ax['C'].set_ylabel(r'Predicted M [GW$\\cdot$s$^2$]')\n",
    "ym = ym['test']\n",
    "ax['C'].set_xlim(ym + np.diff(ym) * np.array([-1/7, 1/5]))\n",
    "ax['C'].set_ylim(ym + np.diff(ym) * np.array([-1/10, 1/10]))\n",
    "ax['C'].xaxis.set_major_locator(FixedLocator(ym))\n",
    "ax['C'].xaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in ym]))\n",
    "ax['C'].yaxis.set_major_locator(FixedLocator(ym))\n",
    "ax['C'].yaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in ym]))\n",
    "\n",
    "################### Panels D, E and F ###################\n",
    "key = experiment_IDs[1][:6]\n",
    "plot_correlations(correlations[key]['R'],\n",
    "                  correlations[key]['p'],\n",
    "                  correlations[key]['R_ctrl'],\n",
    "                  correlations[key]['p_ctrl'],\n",
    "                  correlations[key]['edges'],\n",
    "                  [np.concatenate(correlations[key]['idx'])],\n",
    "                  sort_freq=[1.1],\n",
    "                  ax=np.array([[ax['D'], ax['E'], ax['F']]]),\n",
    "                  legend_bbox=[0.3, -0.05])\n",
    "plot_correlations(correlations[key]['R'],\n",
    "                  correlations[key]['p'],\n",
    "                  None,\n",
    "                  None,\n",
    "                  correlations[key]['edges'],\n",
    "                  [np.concatenate(correlations[key]['idx'])],\n",
    "                  sort_freq=[5.75],\n",
    "                  ax=np.array([[ax['E']]]))\n",
    "\n",
    "ax['D'].set_ylabel('Frequency [Hz]')\n",
    "ax['D'].set_xlabel('Filter #')\n",
    "ax['E'].set_xlabel('Filter #')\n",
    "ax['F'].set_xlabel('Correlation')\n",
    "ax['D'].set_xticklabels([1, 32, 64])\n",
    "ax['E'].set_xticklabels([1, 32, 64])\n",
    "\n",
    "for lbl in 'DEF':\n",
    "    ax[lbl].set_ylim(ticks['A'][[0,-1]] + np.array([0,1]))\n",
    "    ax[lbl].yaxis.set_major_locator(FixedLocator(ticks['A']))\n",
    "    ax[lbl].yaxis.set_minor_locator(NullLocator())\n",
    "    ax[lbl].yaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks['A']]))\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-0.45, -0.05, fig.dpi_scale_trans)\n",
    "for lbl,a in ax.items():\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.text(0.0, 1.0, lbl, transform=a.transAxes + trans, fontsize=10, va='bottom')\n",
    "\n",
    "fig.tight_layout(pad=0)\n",
    "pdf_file = f'variable_inertia_{experiment_IDs[0][:6]}_{experiment_IDs[1][:6]}.pdf'\n",
    "fig.savefig(pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ID = 'f64bde90cab54d1ea770bb21f33c3ed1'\n",
    "# experiment_ID = 'a40658acee3c4e419c0ee34d0c59f4df'\n",
    "experiments_path = '../experiments/neural_network/'\n",
    "history = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'history.pkl'), 'rb'))\n",
    "test_results = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'test_results.pkl'), 'rb'))\n",
    "print('MAPE on the test set: {:.2f}%.'.format(test_results['mape_prediction'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert = False\n",
    "if vert:\n",
    "    fig,ax = plt.subplots(2, 1, figsize=(2.5,3))\n",
    "else:\n",
    "    fig,ax = plt.subplots(1, 2, figsize=(5,2))\n",
    "\n",
    "ax[0].plot(history['loss'], 'k', lw=1, label='Training')\n",
    "ax[0].plot(history['val_loss'], 'r', lw=1, label='Validation')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend(loc='upper right', frameon=False)\n",
    "\n",
    "y_test,y_pred = test_results['y_test'].squeeze(), test_results['y_prediction'].squeeze()\n",
    "# limits = np.array([y_test.min(), y_test.max()])\n",
    "# print(limits)\n",
    "if experiment_ID[:6] == 'a40658':\n",
    "    limits = [0.17, 0.3]\n",
    "    ticks = np.r_[0.18 : 0.31 : 0.03]\n",
    "elif experiment_ID[:6] == 'f64bde':\n",
    "    limits = [0.17, 0.28]\n",
    "    ticks = np.r_[0.18 : 0.31 : 0.03]\n",
    "else:\n",
    "    raise Exception('set limits and ticks')\n",
    "ax[1].plot(limits, limits, '--', lw=1, color=[.6,.6,.6])\n",
    "for y in np.unique(y_test):\n",
    "    idx = y_test == y\n",
    "    m = y_pred[idx].mean()\n",
    "    s = y_pred[idx].std()\n",
    "    ax[1].plot(y+np.zeros(2), m+s*np.array([-1,1]), 'k', lw=1)\n",
    "    ax[1].plot(y, m, 'ko', markersize=4, markerfacecolor='w', markeredgewidth=1)\n",
    "ax[1].set_xlabel(r'Exact M [GW$\\cdot$s$^2$]')\n",
    "ax[1].set_ylabel(r'Predicted M [GW$\\cdot$s$^2$]')\n",
    "ax[1].set_xticks(ticks)\n",
    "ax[1].set_yticks(ticks)\n",
    "ax[1].set_xlim(limits)\n",
    "ax[1].set_ylim(limits)\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)\n",
    "if vert:\n",
    "    fig.savefig(f'training_{experiment_ID[:6]}.pdf')\n",
    "else:\n",
    "    fig.savefig(f'/Users/daniele/Downloads/training_{experiment_ID[:6]}_horiz.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_IDs = '7d55f784f6b64f2caeb866804bda1a8b', '57dfd307a5a945d8b28e5cf501b41f13'\n",
    "experiment_IDs = 'a40658acee3c4e419c0ee34d0c59f4df', 'f64bde90cab54d1ea770bb21f33c3ed1'\n",
    "experiments_path = '../experiments/neural_network/'\n",
    "dbs = [shelve.open(os.path.join(experiments_path, ID, ID[:6]+'.out')) for ID in experiment_IDs]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig,ax = plt.subplot_mosaic(\n",
    "    '''\n",
    "    AAAB\n",
    "    CCCD\n",
    "    EEEF\n",
    "    GGGH\n",
    "    ''',\n",
    "    figsize=(3.5, 4)\n",
    ")\n",
    "\n",
    "ylim = [\n",
    "    [0.17, 0.27],\n",
    "    [0.17, 0.27],\n",
    "    [0.20, 0.25],\n",
    "    [0.20, 0.25]\n",
    "]\n",
    "yticks = [\n",
    "    np.r_[0.18 : 0.27 : 0.04],\n",
    "    np.r_[0.18 : 0.27 : 0.04],\n",
    "    np.r_[0.20 : 0.26 : 0.025],\n",
    "    np.r_[0.20 : 0.26 : 0.025],\n",
    "]\n",
    "nextch = lambda ch: chr(ord(ch) + 1)\n",
    "ithch = lambda n,start='A': chr(ord(start)+n)\n",
    "\n",
    "col = [.6+np.zeros(3), np.zeros(3)]\n",
    "col = [[.2,.8,.4], np.zeros(3)]\n",
    "magenta = [1,0,1]\n",
    "\n",
    "for i,db in enumerate(dbs):\n",
    "    for j,expt in enumerate(db['experiments']):\n",
    "        J = ithch(j*2)\n",
    "        time = expt['prediction_time']\n",
    "        prediction = np.squeeze(expt['prediction'])\n",
    "        exact = expt['exact']\n",
    "        mean_prediction = expt['mean_prediction']\n",
    "        N_blocks = len(expt['H_values'])\n",
    "        block_dur = np.ceil(expt['data_time'][-1]) / N_blocks\n",
    "        area_measure = 'M'\n",
    "        measure_units = r'GW$\\cdot$s$^2$'\n",
    "        for k in range(N_blocks):\n",
    "            t0,t1 = block_dur*k, block_dur*(k+1)\n",
    "            idx, = np.where((time >= t0) & (time < t1) & np.logical_not(np.isnan(prediction)))\n",
    "            n,x = np.histogram(prediction[idx], bins=10, density=True)\n",
    "            ax[J].plot(np.array([t0, t1])/60, mean_prediction[k] + np.zeros(2), color=col[i], lw=1)\n",
    "#             ax[nextch(J)].plot(n, x[1:], color=col[i], lw=1)\n",
    "            ax[nextch(J)].barh(x[:-1], n, height=0.5*(x[1]-x[0]), align='edge',\n",
    "                               facecolor=col[i], edgecolor=col[i], alpha=0.7)\n",
    "            if i == 1:\n",
    "                ax[J].plot(np.array([t0, t1])/60, exact[k] + np.zeros(2), '--', color=magenta, lw=1)\n",
    "                ax[nextch(J)].plot([0,150], exact[k] + np.zeros(2), '--', color=magenta, lw=1)\n",
    "        ax[J].plot(time/60, prediction, color=col[i], lw=0.75)\n",
    "        if i == 0:\n",
    "            for side in 'right','top':\n",
    "                ax[J].spines[side].set_visible(False)\n",
    "                ax[nextch(J)].spines[side].set_visible(False)\n",
    "            ax[J].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "            ax[nextch(J)].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "            ax[J].set_ylim(ylim[j])\n",
    "            ax[J].set_xticks(np.r_[0 : 181 : 30])\n",
    "            ax[J].set_yticks(yticks[j])\n",
    "            ax[nextch(J)].set_ylim(ylim[j])\n",
    "            ax[nextch(J)].set_yticks(yticks[j])\n",
    "            ax[nextch(J)].set_yticklabels([])\n",
    "            ax[nextch(J)].set_xticks(np.r_[0 : 151 : 50])\n",
    "            ax[J].set_ylabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "            \n",
    "ax['G'].set_xlabel('Time [min]')\n",
    "ax['H'].set_xlabel('PDF')\n",
    "for i in 'ABCDEF':\n",
    "    ax[i].set_xticklabels([])\n",
    "    \n",
    "trans = mtransforms.ScaledTranslation(-0.5, -0.05, fig.dpi_scale_trans)\n",
    "for lbl,LBL in zip('ACEG','ABCD'):\n",
    "    ax[lbl].text(0.0, 1.0, LBL, transform=ax[lbl].transAxes + trans, fontsize=10, va='bottom')\n",
    "\n",
    "fig.tight_layout(pad=0.2)\n",
    "pdf_file = f'area_momentum_estimation_grid_{experiment_IDs[0][:6]}_{experiment_IDs[1][:6]}.pdf'\n",
    "fig.savefig(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert = False\n",
    "if vert:\n",
    "    fig,ax = plt.subplot_mosaic(\n",
    "        '''\n",
    "        A\n",
    "        B\n",
    "        C\n",
    "        D\n",
    "        ''',\n",
    "        figsize=(3, 4)\n",
    "    )\n",
    "else:\n",
    "    fig,ax = plt.subplot_mosaic(\n",
    "        '''\n",
    "        AB\n",
    "        CD\n",
    "        ''',\n",
    "        figsize=(6.5, 2.5)\n",
    "    )\n",
    "\n",
    "ylim = [\n",
    "    [0.17, 0.27],\n",
    "    [0.17, 0.27],\n",
    "    [0.20, 0.25],\n",
    "    [0.20, 0.25]\n",
    "]\n",
    "yticks = [\n",
    "    np.r_[0.18 : 0.27 : 0.04],\n",
    "    np.r_[0.18 : 0.27 : 0.04],\n",
    "    np.r_[0.20 : 0.26 : 0.025],\n",
    "    np.r_[0.20 : 0.26 : 0.025],\n",
    "]\n",
    "nextch = lambda ch: chr(ord(ch) + 1)\n",
    "ithch = lambda n,start='A': chr(ord(start)+n)\n",
    "\n",
    "col = [.6+np.zeros(3), np.zeros(3)]\n",
    "col = [[.2,.8,.4], np.zeros(3)]\n",
    "magenta = [1,0,1]\n",
    "\n",
    "for i,db in enumerate(dbs):\n",
    "    for j,expt in enumerate(db['experiments']):\n",
    "        J = ithch(j)\n",
    "        time = expt['prediction_time']\n",
    "        prediction = np.squeeze(expt['prediction'])\n",
    "        exact = expt['exact']\n",
    "        mean_prediction = expt['mean_prediction']\n",
    "        N_blocks = len(expt['H_values'])\n",
    "        block_dur = np.ceil(expt['data_time'][-1]) / N_blocks\n",
    "        area_measure = 'M'\n",
    "        measure_units = r'GW$\\cdot$s$^2$'\n",
    "        for k in range(N_blocks):\n",
    "            t0,t1 = block_dur*k, block_dur*(k+1)\n",
    "            idx, = np.where((time >= t0) & (time < t1) & np.logical_not(np.isnan(prediction)))\n",
    "            n,x = np.histogram(prediction[idx], bins=10, density=True)\n",
    "            ax[J].plot(np.array([t0, t1])/60, mean_prediction[k] + np.zeros(2), color=col[i], lw=1)\n",
    "            if i == 1:\n",
    "                ax[J].plot(np.array([t0, t1])/60, exact[k] + np.zeros(2), '--', color=magenta, lw=1)\n",
    "        ax[J].plot(time/60, prediction, color=col[i], lw=0.75)\n",
    "        if i == 0:\n",
    "            for side in 'right','top':\n",
    "                ax[J].spines[side].set_visible(False)\n",
    "            ax[J].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "            ax[J].set_ylim(ylim[j])\n",
    "            ax[J].set_xticks(np.r_[0 : 181 : 30])\n",
    "            ax[J].set_yticks(yticks[j])\n",
    "            ax[J].set_ylabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "\n",
    "ax['D'].set_xlabel('Time [min]')\n",
    "if not vert:\n",
    "    ax['C'].set_xlabel('Time [min]')\n",
    "for i in 'AB':\n",
    "    ax[i].set_xticklabels([])\n",
    "if vert:    \n",
    "    ax['C'].set_xticklabels([])\n",
    "trans = mtransforms.ScaledTranslation(-0.5, -0.05, fig.dpi_scale_trans)\n",
    "for lbl in 'ABCD':\n",
    "    ax[lbl].text(0.0, 1.0, lbl, transform=ax[lbl].transAxes + trans, fontsize=10, va='bottom')\n",
    "\n",
    "fig.tight_layout(pad=0.2)\n",
    "if vert:\n",
    "    pdf_file = f'area_momentum_estimation_grid_{experiment_IDs[0][:6]}_{experiment_IDs[1][:6]}.pdf'\n",
    "else:\n",
    "    pdf_file = f'/Users/daniele/Downloads/area_momentum_estimation_grid_{experiment_IDs[0][:6]}_{experiment_IDs[1][:6]}_horiz.pdf'\n",
    "fig.savefig(pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buses = 3, # 14, 17, 39\n",
    "N_buses = len(buses)\n",
    "var_names = [f'Vd_bus{bus}' for bus in buses]\n",
    "area_measure = 'momentum'\n",
    "max_block_size = 100\n",
    "cutoff = 0.1\n",
    "filename = f'spectra_compensators_buses={\"-\".join(map(str,buses))}_cutoff={cutoff:.02f}_blocks={max_block_size}'\n",
    "data = np.load(filename + '.npz')\n",
    "for key in data.files:\n",
    "    globals()[key] = data[key]\n",
    "min_fft = Xfm.min(axis=(1,2))\n",
    "max_fft = Xfm.max(axis=(1,2))\n",
    "N_H = len(H_comp)\n",
    "# Xfm = Xfm.squeeze()\n",
    "step = Xfm.shape[1] // H_comp.size\n",
    "\n",
    "n = Xfm.shape[1]\n",
    "peaks = np.zeros((n,2))\n",
    "var_idx = 0\n",
    "for i in range(n):\n",
    "    x = 20*np.log10(Xfm[var_idx, i, F < 1.5])\n",
    "    locs,_ = find_peaks(x, height=10, prominence=1, distance=5)\n",
    "    peaks[i,:] = F[locs[1:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2.75, 5))\n",
    "x_offset = [0.2, 0.02]\n",
    "y_offset = [0.1, 0.04]\n",
    "x_space = 0.1\n",
    "y_space = 0.05\n",
    "\n",
    "# H_comp_sub = [0.1, 2.5, 5.0]\n",
    "H_comp_sub = [1.0, 3.0, 6.0]\n",
    "rows = len(H_comp_sub)\n",
    "height = [0.15, 0.15]\n",
    "n = 2.2\n",
    "w = 1 - np.sum(x_offset)\n",
    "h = (1 - np.sum(height) - y_space*len(height)*1.2 - np.sum(y_offset) - y_space * (rows - 1)) / rows\n",
    "print(h)\n",
    "ax = [plt.axes([x_offset[0], 1 - y_offset[1] - height[0], w, height[0]])]\n",
    "for i in range(rows-1, -1, -1):\n",
    "    ax.append(plt.axes([x_offset[0],\n",
    "                        y_offset[0] + height[1] + y_space*1.5 + (h + y_space) * i,\n",
    "                        w, h]))\n",
    "ax.append(plt.axes([x_offset[0], y_offset[0], w, height[1]]))\n",
    "# ax = [a[0] for a in ax]\n",
    "\n",
    "xticks = np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20])\n",
    "var_idx = 0\n",
    "\n",
    "reds = plt.get_cmap('Reds', N_H+4)\n",
    "blues = plt.get_cmap('Blues', N_H+4)\n",
    "for i in range(N_H-1):\n",
    "    ax[0].plot(F, 20*np.log10(Xfm[var_idx, i*step, :]), color=reds(i+2), lw=2)\n",
    "    ax[0].plot(F, 20*np.log10(Xfm[var_idx, step - 1 + i*step, :]), color=blues(i+2), lw=1)\n",
    "ax[0].plot(F, 20*np.log10(Xfm[var_idx, i*step, :]), color=reds(i+2), lw=2, label='Low momentum')\n",
    "ax[0].plot(F, 20*np.log10(Xfm[var_idx, step - 1 + i*step, :]), color=blues(i+2), lw=1, label='High momentum')\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_yticks(np.r_[-20:25:10])\n",
    "ax[0].set_ylabel('Power [dB]')\n",
    "ax[0].grid(which='major', axis='both', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "ax[0].set_xlim(xticks[[0,-1]] + np.array([0,1]))\n",
    "ax[0].xaxis.set_major_locator(FixedLocator(xticks))\n",
    "ax[0].xaxis.set_minor_locator(NullLocator())\n",
    "ax[0].xaxis.set_major_formatter(FixedFormatter([]))\n",
    "ax[0].legend(loc='lower left', frameon=False, fontsize=fontsize-1, bbox_to_anchor=[0,-0.05])\n",
    "ax[0].arrow(17, 7, -10, 7, shape='left', width=0.2, head_width=2, head_length=1, fc='k', ec='k')\n",
    "ax[0].text(10, 27, 'Increasing H comp', fontsize=fontsize-2, va='top', ha='center', rotation=-15)\n",
    "_forward = lambda x: 20 * np.log10(x)\n",
    "_inverse = lambda y: 10 ** (y/20)\n",
    "cmap = plt.cm.jet\n",
    "w,h = 2.75,1\n",
    "for i,H in enumerate(H_comp_sub):\n",
    "    j = np.where(H_comp == H)[0][0]\n",
    "    idx = IDX[j]\n",
    "    norm = FuncNorm((_forward, _inverse), vmin=min_fft[var_idx], vmax=max_fft[var_idx])\n",
    "    X,Y = np.meshgrid(F, ym[idx])\n",
    "    ylim = [Y.min(), Y.max()]\n",
    "    if True:\n",
    "        ax[i+1].pcolor(X, Y, Xfm[var_idx, idx, :], cmap=cmap, norm=norm)\n",
    "\n",
    "    col = [[1,1,1], [0,.75,1]]\n",
    "    for k in range(2):\n",
    "        jdx = np.argsort(ym[idx])\n",
    "        xdata = peaks[idx[jdx],k]\n",
    "        ydata = ym[idx[jdx]]\n",
    "        func = lambda x,a,b: a*x**b\n",
    "        popt,pcov = curve_fit(func, ydata, xdata)\n",
    "        ax[i+1].plot(func(ydata, *popt), ydata, '--', color=col[k], lw=1)\n",
    "\n",
    "    dx = np.log(F[-1] - cutoff) / 40\n",
    "    dy = np.diff(ylim)[0] / 10\n",
    "    xy = np.array([\n",
    "        [Fpeak[var_idx,j], ylim[0] + dy],\n",
    "        [np.exp(np.log(Fpeak[var_idx,j]) - dx), ylim[0]],\n",
    "        [np.exp(np.log(Fpeak[var_idx,j]) + dx), ylim[0]]\n",
    "    ])\n",
    "    triangle = Polygon(xy, fc='k', ec='k')\n",
    "    ax[i+1].add_patch(triangle)\n",
    "\n",
    "    ax[i+1].set_xlim([cutoff, F[-1]])\n",
    "    ax[i+1].set_xscale('log')\n",
    "    ax[i+1].set_xlim(xticks[[0,-1]] + np.array([0,1]))\n",
    "    ax[i+1].xaxis.set_major_locator(FixedLocator(xticks))\n",
    "    ax[i+1].xaxis.set_minor_locator(NullLocator())\n",
    "    if i == rows-1:\n",
    "        ax[i+1].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in xticks]))\n",
    "    else:\n",
    "        ax[i+1].xaxis.set_major_formatter(FixedFormatter([]))\n",
    "\n",
    "    yticks = np.linspace(ylim[0], ylim[1], 3)\n",
    "    ax[i+1].text(xticks[-1]-3, ylim[1] - 0.1*np.diff(ylim), 'H = {:.1f} s'.format(H),\n",
    "               fontsize=fontsize+1, color='w', verticalalignment='top', horizontalalignment='right')\n",
    "    ax[i+1].set_ylim(ylim)\n",
    "    ax[i+1].yaxis.set_major_locator(FixedLocator(yticks))\n",
    "    ax[i+1].yaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in yticks]))\n",
    "    ax[i+1].set_ylabel(r'M [GW$\\cdot$s$^2$]')\n",
    "\n",
    "ax[-2].set_xlabel('Frequency [Hz]')\n",
    "\n",
    "ax[-1].plot(H_comp[1:], Fpeak[var_idx,1:], 'ko-', lw=1, markersize=4, markerfacecolor='w')\n",
    "ax[-1].set_xlim([0.5, 6.5])\n",
    "ax[-1].set_ylim([3, 16])\n",
    "ax[-1].set_yticks(np.r_[5 : 20 : 5])\n",
    "ax[-1].set_xlabel('Compensator H [s]')\n",
    "ax[-1].set_ylabel('Frequency peak [Hz]')\n",
    "ax[-1].grid(which='major', axis='y', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "for side in 'right','top':\n",
    "    for a in ax:\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-0.5, 0, fig.dpi_scale_trans)\n",
    "ax[0].text(0.0, 1.0, 'A', transform=ax[0].transAxes + trans, fontsize=10, va='bottom')\n",
    "ax[-1].text(0.0, 1.0, 'C', transform=ax[-1].transAxes + trans, fontsize=10, va='bottom')\n",
    "trans = mtransforms.ScaledTranslation(-0.5, 0.03, fig.dpi_scale_trans)\n",
    "ax[1].text(0.0, 1.0, 'B', transform=ax[1].transAxes + trans, fontsize=10, va='bottom')\n",
    "\n",
    "fig.savefig(f'spectra_compensators_{var_names[var_idx]}.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
