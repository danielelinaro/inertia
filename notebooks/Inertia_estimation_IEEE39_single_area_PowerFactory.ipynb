{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import read_area_values, load_data_slide\n",
    "from dlml.nn import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ID = 1\n",
    "area_measure = 'momentum'\n",
    "stoch_load_bus_IDs = [3]\n",
    "rec_bus_IDs = [3, 14, 17]\n",
    "additional_tags = ['ReLU_none', 'PowerFactory']\n",
    "\n",
    "experiments = collect_experiments(area_ID, area_measure=area_measure, D=None, DZA=None, \\\n",
    "                                  stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=None, \\\n",
    "                                  rec_bus_IDs=rec_bus_IDs, additional_tags=additional_tags, \\\n",
    "                                  verbose=True)\n",
    "experiment_IDs = list(experiments.keys())\n",
    "experiment_ID = experiment_IDs[np.argmin([expt['val_loss'].min() for expt in experiments.values()])]\n",
    "MAPE = experiments[experiment_ID]['MAPE']\n",
    "loss = experiments[experiment_ID]['loss']\n",
    "val_loss = experiments[experiment_ID]['val_loss']\n",
    "batch_loss = experiments[experiment_ID]['batch_loss']\n",
    "tags = experiments[experiment_ID]['tags']\n",
    "print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE:.4f}%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "network_parameters = pickle.load(open(experiments_path + experiment_ID \\\n",
    "                                      + '/parameters.pkl', 'rb'))\n",
    "epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "best_idx = np.argmin(val_loss)\n",
    "best_checkpoint = checkpoint_files[epochs.index(best_idx + 1)]\n",
    "model = keras.models.load_model(best_checkpoint, compile=True)\n",
    "data_dirs = ['..' + os.path.sep +\n",
    "             os.path.sep.join([d for d in data_dir.split(os.path.sep) if '{}' not in d])\n",
    "             for data_dir in network_parameters['data_dirs']]\n",
    "# we need mean and standard deviation of the training set to normalize the data\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "data_dir = data_dirs[0]\n",
    "tmp = [re.findall('.*_bus', var_name)[0] for var_name in network_parameters['var_names']]\n",
    "var_names_fmt = list(OrderedDict({k + '{}': [] for k in tmp}).keys())\n",
    "if len(rec_bus_IDs) == 0:\n",
    "    rec_bus_IDs = list(np.unique([int(re.findall('\\d+', var_name)[0]) \\\n",
    "                                  for var_name in network_parameters['var_names']]))\n",
    "    rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "if not os.path.isdir(data_dir):\n",
    "    raise Exception(f'{data_dir}: no such directory')\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Data directory is {data_dir}.')\n",
    "print(f'Variable names: {var_names_fmt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_H = OrderedDict([\n",
    "    ('G 01', 5.00), ('G 02', 4.33), ('G 03', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "    ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "])\n",
    "\n",
    "\n",
    "if 'area1_wrong' in tags:\n",
    "    generators_areas_map = {\n",
    "        'default': [\n",
    "            ['G 02', 'G 03', 'G 10'],\n",
    "            ['G 04', 'G 05', 'G 06', 'G 07'],\n",
    "            ['G 08', 'G 09'],\n",
    "            ['G 01']\n",
    "        ]\n",
    "    }\n",
    "else:\n",
    "    generators_areas_map = {\n",
    "        'default': [\n",
    "            ['G 02', 'G 03'],\n",
    "            ['G 04', 'G 05', 'G 06', 'G 07'],\n",
    "            ['G 08', 'G 09', 'G 10'],\n",
    "            ['G 01']\n",
    "        ]\n",
    "    }\n",
    "\n",
    "P_nom = {'G 01': 10000e6, 'G 02': 700e6, 'G 03': 800e6, 'G 04':  800e6, 'G 05':  300e6,\n",
    "         'G 06':   800e6, 'G 07': 700e6, 'G 08': 700e6, 'G 09': 1000e6, 'G 10': 1000e6}\n",
    "\n",
    "window_dur = 60\n",
    "window_step = 1\n",
    "\n",
    "var_names_network = network_parameters['var_names']\n",
    "data_mean = {var_name: x_train_mean[k] for k,var_name in enumerate(var_names)}\n",
    "data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "\n",
    "if area_measure == 'inertia':\n",
    "    measure_units = 's'\n",
    "elif area_measure == 'energy':\n",
    "    measure_units = r'GW$\\cdot$s'\n",
    "elif area_measure == 'momentum':\n",
    "    measure_units = r'GW$\\cdot$s$^2$'\n",
    "    \n",
    "stoch_load_bus_list = 'stoch_load_bus_' + '-'.join(map(str, stoch_load_bus_IDs))\n",
    "rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "\n",
    "abbrv = {'inertia': 'H', 'energy': 'E', 'momentum': 'M'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = 700e6\n",
    "S3 = 800e6\n",
    "M = 0.2\n",
    "H2 = 4\n",
    "H3 = (30 * M * 1e9 - H2 * S2) / S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = 700e6\n",
    "S3a = 800e6\n",
    "S3b = 200e6\n",
    "M = 0.23\n",
    "H2 = 4.33\n",
    "H3a = 2.5\n",
    "H3b = (30 * M * 1e9 - H2 * S2 - H3a * S3a) / S3b\n",
    "print(H3b)\n",
    "# H3a, H3b = 4.47, 4.47\n",
    "print((H2 * S2 + H3a * S3a + H3b * S3b) / 30 * 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom = lambda H2,H3: (H2 * S2 + H3 * S3) / 30 * 1e-9\n",
    "mom(4, 4)\n",
    "mom(4, 3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators_areas_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_values = [\n",
    "    default_H,\n",
    "    OrderedDict([\n",
    "        ('G 01', 5.00), ('G 02', 5.00), ('G 03', 3.884), ('G 04', 3.57), ('G 05', 4.33),\n",
    "        ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "    ]),\n",
    "    OrderedDict([\n",
    "        ('G 01', 5.00), ('G 02', 5.00), ('G 03', 4.00), ('G 04', 3.57), ('G 05', 4.33),\n",
    "        ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.107)\n",
    "    ])\n",
    "]\n",
    "N_H = len(H_values)\n",
    "\n",
    "measure_exact = []\n",
    "\n",
    "data = []\n",
    "data_normalized = []\n",
    "measure = []\n",
    "area_inertia = []\n",
    "\n",
    "var_names_data = [\n",
    "    'Pe_line_3_4', 'Qe_line_3_4', 'Vd_bus3', 'Vq_bus3',\n",
    "    'Pe_line_14_15', 'Qe_line_14_15', 'Vd_bus14', 'Vq_bus14',\n",
    "    'Pe_line_16_17', 'Qe_line_16_17', 'Vd_bus17', 'Vq_bus17',\n",
    "]\n",
    "var_names = [var_name.format(bus_ID) for bus_ID in np.unique(rec_bus_IDs) for var_name in var_names_fmt]\n",
    "data_mean = {var_name: x_train_mean[k] for k,var_name in enumerate(var_names)}\n",
    "data_std = {var_name: x_train_std[k] for k,var_name in enumerate(var_names)}\n",
    "\n",
    "replace_keys = lambda D, keys_in, keys_out: {key_out: D[key_in] for key_in, key_out in zip(keys_in, keys_out)}\n",
    "\n",
    "for H in H_values:\n",
    "    data_file = data_dir + '/IEEE39_rnd_load_' + '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "    _,_,v,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "    _,_,h,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, 'inertia')\n",
    "    measure_exact.append(v[area_ID - 1])\n",
    "    area_inertia.append(h[area_ID - 1])\n",
    "\n",
    "    t, _, data_norm, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                        var_names_data,\n",
    "                                                        data_mean,\n",
    "                                                        data_std,\n",
    "                                                        window_dur,\n",
    "                                                        window_step,\n",
    "                                                        add_omega_ref = False,\n",
    "                                                        verbose = True)\n",
    "    data_norm = replace_keys(data_norm, var_names_data, var_names_network)\n",
    "    data_sliding = replace_keys(data_sliding, var_names_data, var_names_network)\n",
    "    data_normalized.append(data_norm)\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    time, HH, _ = predict(model, data_sliding, window_step)\n",
    "    measure.append(HH)\n",
    "measure_exact = np.array(measure_exact)\n",
    "area_inertia = np.array(area_inertia)\n",
    "measure_predicted = np.array(list(map(np.nanmean, measure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = len(var_names_fmt)\n",
    "fig = plt.figure(figsize=(8, n_vars * 2.5))\n",
    "gs = fig.add_gridspec(n_vars+1, 4)\n",
    "ax = []\n",
    "for i in range(n_vars):\n",
    "    ax.append([fig.add_subplot(gs[i, :3]), fig.add_subplot(gs[i, 3])]),\n",
    "# ax.append([fig.add_subplot(gs[-1, :2]), fig.add_subplot(gs[-1, 2:])])\n",
    "ax.append([fig.add_subplot(gs[-1,:])])\n",
    "\n",
    "col = [[.2,.2,.2], [.8,0,0], [0,.7,0]]\n",
    "\n",
    "bus_ID = rec_bus_IDs[0]\n",
    "\n",
    "idx = t < 60\n",
    "\n",
    "dm = np.max(measure_exact) - np.min(measure_exact)\n",
    "if dm == 0:\n",
    "    dm = np.max(measure_exact) / 10\n",
    "ylim = [np.min(measure_exact) - dm / 2, np.max(measure_exact) + dm / 2]\n",
    "\n",
    "for i in range(N_H):\n",
    "    for j,var_name in enumerate(var_names_fmt):\n",
    "        key = var_name.format(bus_ID)\n",
    "        value = np.squeeze(data_normalized[i][key])\n",
    "        n,edges = np.histogram(value, bins=25, range=(-4,4), density=True)\n",
    "        ax[j][0].plot(t[idx], value[idx], color=col[i], lw=1, \\\n",
    "                      label=f'{abbrv[area_measure]} = {measure_exact[i]:.2f} {measure_units}')\n",
    "        ax[j][1].plot(n, edges[:-1] + np.diff(edges[:2])[0] / 2, color=col[i], lw=1)\n",
    "        for a in ax[j]:\n",
    "            a.set_ylim([-4,4])\n",
    "        ax[j][0].set_ylabel(key)\n",
    "    ax[-1][0].plot(time / 60, measure[i], 'k', lw=1)\n",
    "    ax[-1][0].plot(time[[0,-1]] / 60, measure_exact[i] + np.zeros(2), 'k--', lw=1)\n",
    "    ax[-1][0].set_ylim(ylim)\n",
    "    ax[-1][0].set_xlabel('Time [min]')\n",
    "\n",
    "for row in ax:\n",
    "    for side in 'right','top':\n",
    "        for a in row:\n",
    "            a.spines[side].set_visible(False)\n",
    "\n",
    "ax[0][0].legend(loc='best')\n",
    "# ax[-1][0].get_shared_x_axes().join(ax[-1][0], ax[-1][1])\n",
    "\n",
    "ax[-1][0].set_xlim(time[[0,-1]] / 60)\n",
    "ax[-1][0].set_ylabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "ax[-2][0].set_xlabel('Time [s]')\n",
    "ax[-2][1].set_xlabel('Fraction')\n",
    "fig.tight_layout()\n",
    "# output_filename = f'IEEE39_area{area_ID}_H_G1={H_G1}_' + \\\n",
    "#     f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_const_H_{experiment_ID[:6]}.pdf'\n",
    "# fig.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With generator #3 (in area 1) split in two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'area1_wrong' in tags:\n",
    "    generators_areas_map['split_gen'] = [\n",
    "        ['G 02', 'G 03a', 'G 03b', 'G 10'],\n",
    "        ['G 04', 'G 05', 'G 06', 'G 07'],\n",
    "        ['G 08', 'G 09'],\n",
    "        ['G 01']\n",
    "    ]\n",
    "    H_values = [\n",
    "        default_H,\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 4.47), ('G 03b', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 7), ('G 03b', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 4.47), ('G 03b', 7), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 7), ('G 03b', 7), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ])\n",
    "    ]\n",
    "else:\n",
    "    generators_areas_map['split_gen'] = [\n",
    "        ['G 02', 'G 03a', 'G 03b'],\n",
    "        ['G 04', 'G 05', 'G 06', 'G 07'],\n",
    "        ['G 08', 'G 09', 'G 10'],\n",
    "        ['G 01']\n",
    "    ]\n",
    "    H_values = [\n",
    "        default_H,\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 4.47), ('G 03b', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 4.47), ('G 03b', 2.5), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 2.5), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "P_nom['G 03a'], P_nom['G 03b'] = 600e6, 200e6\n",
    "\n",
    "N_H = len(H_values)\n",
    "\n",
    "data = []\n",
    "data_normalized = []\n",
    "measure = []\n",
    "measure_exact = []\n",
    "area_inertia = []\n",
    "\n",
    "for H in H_values:\n",
    "    if len(H) == 10:\n",
    "        data_file = data_dir + '/IEEE39_rnd_load_' + \\\n",
    "            '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "        _,_,h,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, 'inertia')\n",
    "    else:\n",
    "        data_file = data_dir + '/IEEE39_rnd_load_split_gen_' + \\\n",
    "            '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '_{:.0f}_{:.0f}.h5' \\\n",
    "        .format(P_nom['G 03a']*1e-6, P_nom['G 03b']*1e-6)\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['split_gen'], P_nom, area_measure)\n",
    "        _,_,h,_ = read_area_values(data_file, generators_areas_map['split_gen'], P_nom, 'inertia')\n",
    "\n",
    "    measure_exact.append(v[area_ID - 1])\n",
    "    area_inertia.append(h[area_ID - 1])\n",
    "\n",
    "    t, d, data_norm, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                        var_names,\n",
    "                                                        None,\n",
    "                                                        data_std,\n",
    "                                                        window_dur,\n",
    "                                                        window_step,\n",
    "                                                        add_omega_ref = False,\n",
    "                                                        verbose = True)\n",
    "    data.append(d)\n",
    "    data_normalized.append(data_norm)\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    time, pred, _ = predict(model, data_sliding, window_step)\n",
    "    measure.append(pred)\n",
    "measure_exact = np.array(measure_exact)\n",
    "area_inertia = np.array(area_inertia)\n",
    "measure_predicted = np.array(list(map(np.nanmean, measure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, = np.where(np.array(list(map(len, H_values))) == 10)\n",
    "jdx, = np.where(np.array(list(map(len, H_values))) == 11)\n",
    "ms = 8\n",
    "fig,ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "ax.plot(measure_exact[idx], measure_predicted[idx], 'ko', ms=ms, markerfacecolor='w', markeredgewidth=2)\n",
    "ax.plot(measure_exact[jdx], measure_predicted[jdx], 'rs', ms=ms, markerfacecolor='w', markeredgewidth=2)\n",
    "ax.plot(measure_exact[[0,-1]], measure_exact[[0,-1]], '--', lw=1, color=[.6,.6,.6])\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.set_xlabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "ax.set_ylabel(f'Predicted {area_measure} [{measure_units}]')\n",
    "ax.grid(which='major', axis='both', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "# ax.set_xlim([0.358, 0.392])\n",
    "# ax.set_ylim([0.348, 0.392])\n",
    "# ax.set_xticks(np.r_[0.36 : 0.39 : 0.01])\n",
    "# ax.set_yticks(np.r_[0.35 : 0.39 : 0.01])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bus = 3\n",
    "var_name = 'Qe_bus{}'.format(bus)\n",
    "fig,ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "col = 'krgbcmy'\n",
    "ax[0].plot(t, data[0][var_name], 'k', lw=1, label='G 03')\n",
    "for i in range(1, len(data)):\n",
    "    ax[0].plot(t, data[i][var_name], col[i], lw=1, label='G 03a + G 03b')\n",
    "ax[0].legend(loc='best')\n",
    "\n",
    "ax[1].plot(t, data_normalized[0][var_name], 'k', lw=1, label='G 03')\n",
    "for i in range(1, len(data)):\n",
    "    ax[1].plot(t, data_normalized[i][var_name], col[i], lw=1, label='G 03a + G 03b')\n",
    "ax[1].set_xlim([0, 10])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bus = 3\n",
    "var_name = 'Qe_bus{}'.format(bus)\n",
    "fig,ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "col = 'krgbcmy'\n",
    "# ax[0].plot(t, data[0][var_name], 'k', lw=1, label='G 03')\n",
    "for i in (2,3):\n",
    "    ax[0].plot(t, data[i][var_name], col[i], lw=1, label='G 03a + G 03b')\n",
    "ax[0].set_xlim([0, 10])\n",
    "ax[0].legend(loc='best')\n",
    "# ax[1].plot(t, data_normalized[0][var_name], 'k', lw=1, label='G 03')\n",
    "for i in (2,3):\n",
    "    ax[1].plot(t, data_normalized[i][var_name], col[i], lw=1, label='G 03a + G 03b')\n",
    "ax[1].set_xlim([0, 10])\n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With generator #3 (in area 1) split in two and different values of nominal power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'area1_wrong' in tags:\n",
    "    generators_areas_map['split_gen'] = [\n",
    "        ['G 02', 'G 03a', 'G 03b', 'G 10'],\n",
    "        ['G 04', 'G 05', 'G 06', 'G 07'],\n",
    "        ['G 08', 'G 09'],\n",
    "        ['G 01']\n",
    "    ]\n",
    "    H_values = [\n",
    "        default_H,\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 4.47), ('G 03b', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 7), ('G 03b', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 4.47), ('G 03b', 7), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 7), ('G 03b', 7), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 7), ('G 03b', 7), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ])\n",
    "    ]\n",
    "else:\n",
    "    generators_areas_map['split_gen'] = [\n",
    "        ['G 02', 'G 03a', 'G 03b'],\n",
    "        ['G 04', 'G 05', 'G 06', 'G 07'],\n",
    "        ['G 08', 'G 09', 'G 10'],\n",
    "        ['G 01']\n",
    "    ]\n",
    "    H_values = [\n",
    "        default_H,\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 4.47), ('G 03b', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 0.345), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 1.845), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 3.345), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 4.845), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 6.345), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "        OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03a', 2.5), ('G 03b', 7.845), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ]),\n",
    "    ]\n",
    "\n",
    "\n",
    "P_nom['G 03a'], P_nom['G 03b'] = 800e6, 200e6\n",
    "\n",
    "N_H = len(H_values)\n",
    "\n",
    "data = []\n",
    "data_normalized = []\n",
    "measure = []\n",
    "measure_exact = []\n",
    "area_inertia = []\n",
    "\n",
    "for H in H_values:\n",
    "    if len(H) == 10:\n",
    "        data_file = data_dir + '/IEEE39_rnd_load_' + \\\n",
    "            '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "        _,_,h,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, 'inertia')\n",
    "    elif 'area_1_wrong' in tags and H != H_values[-1]:\n",
    "        data_file = data_dir + '/IEEE39_rnd_load_split_gen_' + \\\n",
    "            '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '_{:.0f}_{:.0f}.h5' \\\n",
    "        .format(P_nom['G 03a']*1e-6, P_nom['G 03b']*1e-6)\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['split_gen'], P_nom, area_measure)\n",
    "        _,_,h,_ = read_area_values(data_file, generators_areas_map['split_gen'], P_nom, 'inertia')\n",
    "    else:\n",
    "        data_file = data_dir + '/IEEE39_rnd_load_split_gen_' + \\\n",
    "            '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '_{:.0f}_{:.0f}_Q0.h5' \\\n",
    "        .format(P_nom['G 03a']*1e-6, P_nom['G 03b']*1e-6)\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['split_gen'], P_nom, area_measure)\n",
    "        _,_,h,_ = read_area_values(data_file, generators_areas_map['split_gen'], P_nom, 'inertia')\n",
    "\n",
    "    measure_exact.append(v[area_ID - 1])\n",
    "    area_inertia.append(h[area_ID - 1])\n",
    "\n",
    "    t, d, data_norm, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                        var_names,\n",
    "                                                        None,\n",
    "                                                        data_std,\n",
    "                                                        window_dur,\n",
    "                                                        window_step,\n",
    "                                                        add_omega_ref = False,\n",
    "                                                        verbose = True)\n",
    "    data.append(d)\n",
    "    data_normalized.append(data_norm)\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    time, pred, _ = predict(model, data_sliding, window_step)\n",
    "    measure.append(pred)\n",
    "measure_exact = np.array(measure_exact)\n",
    "area_inertia = np.array(area_inertia)\n",
    "measure_predicted = np.array(list(map(np.nanmean, measure)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, = np.where(np.array(list(map(len, H_values))) == 10)\n",
    "jdx, = np.where(np.array(list(map(len, H_values))) == 11)\n",
    "ms = 8\n",
    "fig,ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "ax.plot(measure_exact[idx], measure_predicted[idx], 'ko', ms=ms, markerfacecolor='w', markeredgewidth=2)\n",
    "ax.plot(measure_exact[jdx], measure_predicted[jdx], 'rs', ms=ms, markerfacecolor='w', markeredgewidth=2)\n",
    "ax.plot([measure_exact.min(), measure_exact.max()],\n",
    "        [measure_exact.min(), measure_exact.max()], '--', lw=1, color=[.6,.6,.6])\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.set_xlabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "ax.set_ylabel(f'Predicted {area_measure} [{measure_units}]')\n",
    "ax.grid(which='major', axis='both', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "# ax.set_xlim([0.358, 0.392])\n",
    "# ax.set_ylim([0.348, 0.392])\n",
    "# ax.set_xticks(np.r_[0.36 : 0.39 : 0.01])\n",
    "# ax.set_yticks(np.r_[0.35 : 0.39 : 0.01])\n",
    "fig.tight_layout()\n",
    "output_filename = f'IEEE39_PF_area{area_ID}_' + \\\n",
    "    f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_compensator_{experiment_ID[:6]}.pdf'\n",
    "fig.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a 4th generator (a compensator) added in area 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "compensator_name = 'Comp 01'\n",
    "\n",
    "generators_areas_map = {\n",
    "    'default': [\n",
    "        ['G 02', 'G 03', 'G 10'],\n",
    "        ['G 04', 'G 05', 'G 06', 'G 07'],\n",
    "        ['G 08', 'G 09'],\n",
    "        ['G 01']\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "generators_areas_map['compensator'] = deepcopy(generators_areas_map['default'])\n",
    "generators_areas_map['compensator'][area_ID - 1].append(compensator_name)\n",
    "generators_areas_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bus = 8\n",
    "\n",
    "if bus == 8:\n",
    "    compensator_name = 'G 11'\n",
    "    P_nom[compensator_name] = 500e6\n",
    "else:\n",
    "    compensator_name = 'Comp 01'\n",
    "    P_nom[compensator_name] = 100e6\n",
    "\n",
    "generators_areas_map['compensator'] = deepcopy(generators_areas_map['default'])\n",
    "generators_areas_map['compensator'][area_ID - 1].append(compensator_name)\n",
    "\n",
    "H_compensator = np.concatenate([[0.1, 0.2, 0.5], np.r_[1 : 10]])\n",
    "\n",
    "H_values = [\n",
    "    default_H\n",
    "]\n",
    "for h in H_compensator:\n",
    "    if bus == 8:\n",
    "        tmp = OrderedDict([\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20),\n",
    "            (compensator_name, h)\n",
    "        ])\n",
    "    else:\n",
    "        tmp = OrderedDict([(compensator_name, h),\n",
    "            ('G 01', 5.00), ('G 02', 4.33), ('G 03', 4.47), ('G 04', 3.57), ('G 05', 4.33),\n",
    "            ('G 06', 4.35), ('G 07', 3.77), ('G 08', 3.47), ('G 09', 3.45), ('G 10', 4.20)\n",
    "        ])\n",
    "    H_values.append(tmp)\n",
    "N_H = len(H_values)\n",
    "\n",
    "data_normalized = []\n",
    "measure = []\n",
    "measure_exact = []\n",
    "area_inertia = []\n",
    "\n",
    "zero_Q = True\n",
    "data_subdir = f'/with_compensator/bus_{bus}'\n",
    "if zero_Q:\n",
    "    data_subdir += '/zero_Q'\n",
    "else:\n",
    "    data_subdir += '/nonzero_Q'\n",
    "\n",
    "for H in H_values:\n",
    "    if compensator_name in H:\n",
    "        data_file = data_dir + data_subdir + '/IEEE39_w__Stoch._Load_&_Compensator_' + \\\n",
    "            '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['compensator'], P_nom, area_measure)\n",
    "        _,_,h,_ = read_area_values(data_file, generators_areas_map['compensator'], P_nom, 'inertia')\n",
    "    else:\n",
    "        data_file = data_dir + '/IEEE39_w__Stoch._Load_' + \\\n",
    "            '_'.join(map(lambda h: f'{h:.3f}', H.values())) + '.h5'\n",
    "        _,_,v,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, area_measure)\n",
    "        _,_,h,_ = read_area_values(data_file, generators_areas_map['default'], P_nom, 'inertia')\n",
    "\n",
    "    measure_exact.append(v[area_ID - 1])\n",
    "    area_inertia.append(h[area_ID - 1])\n",
    "\n",
    "    t, _, data_norm, data_sliding, _ = load_data_slide([data_file],\n",
    "                                                        var_names,\n",
    "                                                        data_mean,\n",
    "                                                        data_std,\n",
    "                                                        window_dur,\n",
    "                                                        window_step,\n",
    "                                                        add_omega_ref = False,\n",
    "                                                        verbose = True)\n",
    "    data_normalized.append(data_norm)\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    time, pred, _ = predict(model, data_sliding, window_step)\n",
    "    measure.append(pred)\n",
    "measure_exact = np.array(measure_exact)\n",
    "area_inertia = np.array(area_inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_predicted = np.array(list(map(np.nanmean, measure)))\n",
    "fig,ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "ax.plot(measure_exact[[1,-1]], measure_exact[[1,-1]], 'k--', lw=1)\n",
    "ax.plot(measure_exact[1:], measure_predicted[1:], 'ko', markerfacecolor='w', markersize=5, markeredgewidth=1)\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.set_xlabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "ax.set_ylabel(f'Predicted {area_measure} [{measure_units}]')\n",
    "ax.grid(which='major', axis='both', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "# ax.set_xlim([0.358, 0.392])\n",
    "# ax.set_ylim([0.348, 0.392])\n",
    "# ax.set_xticks(np.r_[0.36 : 0.39 : 0.01])\n",
    "# ax.set_yticks(np.r_[0.35 : 0.39 : 0.01])\n",
    "fig.tight_layout()\n",
    "fig.savefig(data_dir + data_subdir + '/compensator.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = len(var_names_fmt)\n",
    "fig = plt.figure(figsize=(9, n_vars * 3))\n",
    "gs = fig.add_gridspec(n_vars+1, 4)\n",
    "ax = []\n",
    "for i in range(n_vars):\n",
    "    ax.append([fig.add_subplot(gs[i, :3]), fig.add_subplot(gs[i, 3])])\n",
    "ax.append([fig.add_subplot(gs[-1, :])])\n",
    "\n",
    "col = [[.2,.2,.2], [.8,0,0], [0,.7,0], [0,0,.7]]\n",
    "cmap = plt.get_cmap('gray', N_H+1)\n",
    "bus_ID = rec_bus_IDs[0]\n",
    "\n",
    "idx = t < 60\n",
    "\n",
    "dm = np.max(measure_exact) - np.min(measure_exact)\n",
    "ylim = [np.min(measure_exact) - dm / 2, np.max(measure_exact) + dm / 2]\n",
    "\n",
    "for i in range(N_H):\n",
    "    for j,var_name in enumerate(var_names_fmt):\n",
    "        key = var_name.format(bus_ID)\n",
    "        value = data_normalized[i][key]\n",
    "        n,edges = np.histogram(value, bins=25, range=(-4,4), density=True)\n",
    "        ax[j][0].plot(t[idx], value[idx], color=cmap(i), lw=1, \\\n",
    "                      label=f'{abbrv[area_measure]} = {measure_exact[i]:.2f} {measure_units}')\n",
    "        ax[j][1].plot(n, edges[:-1] + np.diff(edges[:2])[0] / 2, color=cmap(i), lw=1)\n",
    "        for a in ax[j]:\n",
    "            a.set_ylim([-4,4])\n",
    "        ax[j][0].set_ylabel(key)\n",
    "    ax[-1][0].plot(time / 60, measure[i], color=cmap(i), lw=1)\n",
    "    ax[-1][0].plot(time[[0,-1]] / 60, measure_exact[i] + np.zeros(2), '--', color=cmap(i), lw=1)\n",
    "    ax[-1][0].set_ylim(ylim)\n",
    "    ax[-1][0].set_xlabel('Time [min]')\n",
    "\n",
    "for aa in ax:\n",
    "    for side in 'right','top':\n",
    "        for a in aa:\n",
    "            a.spines[side].set_visible(False)\n",
    "for i in range(n_vars):\n",
    "    for j in range(2):\n",
    "        ax[i][j].grid(axis='y', lw=0.5, linestyle=':')\n",
    "\n",
    "# ax[0][0].legend(loc='best')\n",
    "ax[-1][0].set_xlim([0,30])\n",
    "# ax[-1][0].set_ylim([0.3, 0.4])\n",
    "ax[-1][0].set_ylabel(f'{area_measure.capitalize()} [{measure_units}]')\n",
    "ax[-2][0].set_xlabel('Time [s]')\n",
    "ax[-2][1].set_xlabel('Fraction')\n",
    "fig.tight_layout()\n",
    "# output_filename = f'IEEE39_area{area_ID}_H_G1={H_G1}_' + \\\n",
    "#     f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_compensator_{experiment_ID[:6]}.pdf'\n",
    "# fig.savefig(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute percentage error\n",
    "mape = np.array([np.nanmean(np.abs((m - me) / me)) * 100 for m,me in zip(measure, measure_exact)])\n",
    "# mean absolute error\n",
    "mae = np.array([np.nanmean(np.abs(m - me)) for m,me in zip(measure, measure_exact)])\n",
    "# increase in area momentum when the compensator is present\n",
    "Dm = (measure_exact - measure_exact[0]) / measure_exact[0] * 100\n",
    "# mean prediction\n",
    "measure_predicted = np.array([np.nanmean(m) for m in measure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_axes(rows, cols, x_offset, y_offset, x_space, y_space, squeeze=True):\n",
    "    w = (1 - np.sum(x_offset) - x_space * (cols - 1)) / cols\n",
    "    h = (1 - np.sum(y_offset) - y_space * (rows - 1)) / rows\n",
    "    \n",
    "    ax = [[plt.axes([x_offset[0] + (w + x_space) * j,\n",
    "                     y_offset[0] + (h + y_space) * i,\n",
    "                     w, h]) for j in range(cols)] for i in range(rows-1, -1, -1)]\n",
    "    \n",
    "    for row in ax:\n",
    "        for a in row:\n",
    "            for side in 'right','top':\n",
    "                a.spines[side].set_visible(False)\n",
    "\n",
    "    if squeeze:\n",
    "        if rows == 1 and cols == 1:\n",
    "            return ax[0][0]\n",
    "        if rows == 1:\n",
    "            return ax[0]\n",
    "        if cols == 1:\n",
    "            return [a[0] for a in ax]\n",
    "        \n",
    "    return ax\n",
    "\n",
    "fontsize = 8\n",
    "lw = 0.75\n",
    "\n",
    "matplotlib.rc('font', **{'family': 'Times New Roman', 'size': fontsize})\n",
    "matplotlib.rc('axes', **{'linewidth': 0.75, 'labelsize': fontsize})\n",
    "matplotlib.rc('xtick', **{'labelsize': fontsize})\n",
    "matplotlib.rc('ytick', **{'labelsize': fontsize})\n",
    "\n",
    "rows = 2\n",
    "cols = 1\n",
    "x_offset = [0.17, 0.03]\n",
    "y_offset = [0.17, 0.075]\n",
    "x_space = 0.1\n",
    "y_space = 0.175\n",
    "\n",
    "fig = plt.figure(figsize=(8/2.54, 6/2.54))\n",
    "ax = make_axes(rows, cols, x_offset, y_offset, x_space, y_space)\n",
    "\n",
    "ax[0].plot(measure_exact[[0,-1]], measure_exact[[0,-1]], 'k--', lw=1)\n",
    "ax[0].plot(measure_exact[0], measure_predicted[0], 'ko', markerfacecolor='k', markersize=4, markeredgewidth=1)\n",
    "ax[0].plot(measure_exact[1:], measure_predicted[1:], 'ko', markerfacecolor='w', markersize=4, markeredgewidth=1)\n",
    "dx = measure_exact[-1] - measure_exact[0]\n",
    "ax[0].set_xlim([measure_exact[0] - dx/20, measure_exact[-1] + dx/20])\n",
    "ax[0].set_xlabel(f'{area_measure[0].capitalize()} [{measure_units}]')\n",
    "ax[0].set_xticks(np.r_[0.35 : 0.5 : 0.05])\n",
    "ax[0].set_ylim([measure_exact[0] - dx/5, measure_exact[-1] + dx/10])\n",
    "ax[0].set_ylabel(f'Predicted {area_measure[0].capitalize()} [{measure_units}]')\n",
    "ax[0].set_yticks(np.r_[0.35 : 0.55 : 0.05])\n",
    "\n",
    "start = 4\n",
    "x = Dm[start:] - Dm[start]\n",
    "y = mape[start:] - mape[start]\n",
    "power_law = lambda x,a,b: a * (x ** b)\n",
    "popt,pcov = curve_fit(power_law, x, y, p0=[1,0.5])\n",
    "x = np.linspace(x[0], x[-1], 50)\n",
    "y = power_law(x, *popt) + mape[start]\n",
    "x += Dm[start]\n",
    "ax[1].plot(x, y, color=[.7,.7,.7], lw=2)\n",
    "ax[1].plot(Dm[[1,start-1]], mape[1:start].mean() + np.zeros(2), color=[.4,.4,.4], lw=2)\n",
    "ax[1].plot(Dm[0], mape[0], 'ko', markerfacecolor='k', markeredgewidth=1, markersize=4)\n",
    "ax[1].plot(Dm[1:], mape[1:], 'ko', markerfacecolor='w', markeredgewidth=1, markersize=4)\n",
    "dx = Dm[-1] - Dm[0]\n",
    "ax[1].set_xlim([Dm[0] - dx/20, Dm[-1] + dx/20])\n",
    "ax[1].set_ylim([0,33])\n",
    "ax[1].set_yticks(np.r_[0:35:10])\n",
    "ax[1].set_xlabel(f'{area_measure[0].capitalize()} increase [%]')\n",
    "ax[1].set_ylabel('MAPE [%]')\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.grid(which='major', axis='y', lw=0.5, color=[.6,.6,.6], ls=':')\n",
    "    \n",
    "output_filename = f'IEEE39_PF_area{area_ID}_' + \\\n",
    "    f'rec_buses={rec_bus_list}_load_buses={stoch_load_bus_list}_compensator_error_{experiment_ID[:6]}.pdf'\n",
    "fig.savefig(output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
