{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "# import shelve\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "# from scipy.signal import find_peaks\n",
    "# from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.colors import LogNorm, FuncNorm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FixedLocator, NullLocator, FixedFormatter\n",
    "# from matplotlib.patches import Polygon\n",
    "import seaborn as sns\n",
    "\n",
    "fontsize = 7\n",
    "lw = 0.75\n",
    "\n",
    "matplotlib.rc('font', **{'family': 'Times New Roman', 'size': fontsize})\n",
    "matplotlib.rc('axes', **{'linewidth': 0.75, 'labelsize': fontsize})\n",
    "matplotlib.rc('xtick', **{'labelsize': fontsize})\n",
    "matplotlib.rc('ytick', **{'labelsize': fontsize})\n",
    "matplotlib.rc('xtick.major', **{'width': lw, 'size':3})\n",
    "matplotlib.rc('ytick.major', **{'width': lw, 'size':3})\n",
    "matplotlib.rc('ytick.minor', **{'width': lw, 'size':1.5})\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.data import load_data_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(R_mean, R_ctrl_mean, edges, ax, sort_freq=1.0,\n",
    "                      vmin=None, vmax=None, legend_bbox=[0.4, -0.05]):\n",
    "    edge = np.abs(edges - sort_freq).argmin()\n",
    "    kdx = np.argsort(R_mean[edge,:])\n",
    "    R_mean = R_mean[:,kdx]\n",
    "    R_ctrl_mean = R_ctrl_mean[:,kdx]\n",
    "\n",
    "    make_symmetric = False\n",
    "    if vmin is None:\n",
    "        vmin = min([r.min() for r in R_mean])\n",
    "        make_symmetric = True\n",
    "    if vmax is None:\n",
    "        vmax = max([r.max() for r in R_mean])\n",
    "        if make_symmetric:\n",
    "            if vmax > np.abs(vmin):\n",
    "                vmin = -vmax\n",
    "            else:\n",
    "                vmax = -vmin\n",
    "    print(f'Color bar bounds: ({vmin:.2f},{vmax:.2f}).')\n",
    "    ticks = np.linspace(vmin, vmax, 7)\n",
    "    ticklabels = [f'{tick:.2f}' for tick in ticks]\n",
    "\n",
    "    cmap = plt.get_cmap('bwr')\n",
    "    x = np.arange(R_mean.shape[-1])\n",
    "    y = edges[:-1] + np.diff(edges) / 2\n",
    "    im = ax[0].pcolormesh(x, y, R_mean, vmin=vmin, vmax=vmax, shading='auto', cmap=cmap)\n",
    "    ax[0].set_xticks(np.linspace(0, x[-1], 3, dtype=np.int32))\n",
    "    cbar = plt.colorbar(im, fraction=0.1, shrink=1, aspect=20, label='Correlation',\n",
    "                        orientation='vertical', ax=ax[0], ticks=ticks)\n",
    "    cbar.ax.set_yticklabels(ticklabels, fontsize=fontsize-1)\n",
    "    R_abs_mean = np.mean(np.abs(R_mean), axis=1)\n",
    "    R_ctrl_abs_mean = np.mean(np.abs(R_ctrl_mean), axis=1)\n",
    "    ax[1].plot(R_abs_mean, y, 'r', lw=1, label='Tr.')\n",
    "    ax[1].plot(R_ctrl_abs_mean, y, 'g--', lw=1, label='Untr.')\n",
    "    ax[1].plot(R_abs_mean - R_ctrl_abs_mean, y, 'k', lw=1, label='Diff.')\n",
    "    ax[1].legend(loc='lower left', bbox_to_anchor=legend_bbox, frameon=False, fontsize=fontsize-1)\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[i].set_ylim(edges[[0,-2]])\n",
    "        ax[i].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34246e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subplots(N, edges, norm_std, F, Xf, exact_momentum, pred_momentum, pred_momentum_ctrl,\n",
    "                  MAPE, R_mean, R_ctrl_mean, corr_edges, ax):\n",
    "    target_values = np.unique(exact_momentum)\n",
    "    \n",
    "    tab10 = plt.get_cmap('tab10')\n",
    "    green, magenta = tab10(2), tab10(6)\n",
    "    cmap = lambda i: (green, magenta)[i%2]\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[0].plot(edges[i][1:], N[i], lw=1, color=cmap(i))\n",
    "        ax[1].plot(F, 20*np.log10(Xf[i]), lw=1, color=cmap(i))\n",
    "\n",
    "    ax[0].grid(which='major', axis='x', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "    ax[0].set_xlim([-4.5, 4.5])\n",
    "    ax[0].set_xticks(np.r_[-4 : 4.5 : 2])\n",
    "    ax[0].set_ylabel('PDF')\n",
    "    ax[0].set_xlabel('Normalized V')\n",
    "    ticks = np.r_[0 : 0.61 : 0.2]\n",
    "    ax[0].set_ylim(ticks[[0,-1]])\n",
    "    ax[0].yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    ax[0].yaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in ticks]))\n",
    "    for i in range(2):\n",
    "        ax[0].text(-4, 0.6-i*0.1*np.diff(ax[0].get_ylim()), f'STD={norm_std[i]:.2f}', color=cmap(i),\n",
    "                   fontsize=fontsize-1, va='top')\n",
    "\n",
    "    ax[1].set_ylim([-55, -10])\n",
    "    ax[1].set_yticks(np.r_[-50 : -9 : 10])\n",
    "    ax[1].set_xscale('log')\n",
    "    ax[1].set_xlabel('Frequency [Hz]')\n",
    "    ax[1].set_ylabel('Power [dB]')\n",
    "    f_ticks = np.array([0.1, 0.2, 0.5, 1, 2, 5, 10, 20])\n",
    "    ax[1].set_xlim(f_ticks[[0,-1]] + np.array([0,1]))\n",
    "    ax[1].xaxis.set_major_locator(FixedLocator(f_ticks))\n",
    "    ax[1].xaxis.set_minor_locator(NullLocator())\n",
    "    ax[1].xaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in f_ticks]))\n",
    "    ax[1].grid(which='major', axis='y', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "    for i,v in enumerate(target_values):\n",
    "        ax[1].text(0.12, -48-i*0.1*np.diff(ax[1].get_ylim()),\n",
    "                   r'M={:.2f} GW$\\cdot$s$^2$'.format(v),\n",
    "                   color=cmap(i), fontsize=fontsize-1)\n",
    "\n",
    "    df = pd.DataFrame(data={'Exact': exact_momentum, 'Pred': np.concatenate(pred_momentum)})\n",
    "    df_ctrl = pd.DataFrame(data={'Exact': exact_momentum, 'Pred': np.concatenate(pred_momentum_ctrl)})\n",
    "    sns.violinplot(x='Exact', y='Pred', data=df, cut=0, inner='quartile',\n",
    "                   palette=[cmap(0), cmap(1)], ax=ax[2], linewidth=0.5)\n",
    "    ax[2].xaxis.set_major_locator(FixedLocator([0, 1]))\n",
    "    ax[2].xaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in target_values]))\n",
    "    ax[2].yaxis.set_major_locator(FixedLocator(target_values))\n",
    "    ax[2].yaxis.set_major_formatter(FixedFormatter([f'{tick:.2f}' for tick in target_values]))\n",
    "    ax[2].text(np.mean(ax[2].get_xlim()), target_values.mean(), f'MAPE={MAPE:.1f}%',\n",
    "               ha='center', va='center', fontsize=fontsize-1)\n",
    "\n",
    "    plot_correlations(R_mean, R_ctrl_mean, corr_edges, sort_freq=[1.1], ax=ax[3:])\n",
    "    for i in (3,4):\n",
    "        ax[i].set_ylim(f_ticks[[0,-1]] + np.array([0,1]))\n",
    "        ax[i].yaxis.set_major_locator(FixedLocator(f_ticks))\n",
    "        ax[i].yaxis.set_minor_locator(NullLocator())\n",
    "        if i == 3:\n",
    "            ax[i].yaxis.set_major_formatter(FixedFormatter([f'{tick:g}' for tick in f_ticks]))\n",
    "        else:\n",
    "            ax[i].set_yticklabels([])\n",
    "    ax[3].set_ylabel('Frequency [Hz]')\n",
    "    ax[3].set_xlabel('Filter #')\n",
    "    ax[4].set_xlabel('Correlation')\n",
    "\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_experiment_IDs = False\n",
    "\n",
    "if find_best_experiment_IDs:\n",
    "    from dlml.utils import collect_experiments\n",
    "    area_measure = 'momentum'\n",
    "    stoch_load_bus_IDs = []\n",
    "    rec_bus_IDs = [3]\n",
    "    H_G1, D, DZA = None, None, None # 500, 2, 0\n",
    "    best_experiment_IDs = {1: {'Vd_bus3': '474d2016e33b441889ce8b17531487cb',\n",
    "                               'Vq_bus3': '617188cbcaef4816a8853081fd303ac1'}}\n",
    "    for area_ID in (1,2):\n",
    "        if area_ID not in best_experiment_IDs:\n",
    "            best_experiment_IDs[area_ID] = {}\n",
    "        for var_name in (f'Vd_bus{rec_bus_IDs[0]}', f'Vq_bus{rec_bus_IDs[0]}'):\n",
    "            if var_name not in best_experiment_IDs[area_ID]:\n",
    "                additional_tags = ['ReLU_none', 'converted_from_PowerFactory', 'all_stoch_loads',\n",
    "                                   var_name.split('_')[0]]\n",
    "                expts = collect_experiments(area_ID, area_measure=area_measure, D=D, DZA=DZA, \\\n",
    "                                            stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=H_G1, \\\n",
    "                                            rec_bus_IDs=rec_bus_IDs, additional_tags=additional_tags, \\\n",
    "                                            verbose=False)\n",
    "                if expts is None or len(expts) == 0:\n",
    "                    continue\n",
    "                expt_IDs = list(expts.keys())\n",
    "                expt_ID = expt_IDs[np.argmin([expt['val_loss'].min() for expt in expts.values()])]\n",
    "                MAPE = expts[expt_ID]['MAPE']\n",
    "                loss = expts[expt_ID]['loss']\n",
    "                val_loss = expts[expt_ID]['val_loss']\n",
    "                batch_loss = expts[expt_ID]['batch_loss']\n",
    "                tags = expts[expt_ID]['tags']\n",
    "                best_experiment_IDs[area_ID][var_name] = expt_ID\n",
    "                print(f'The best experiment is {expt_ID[:6]} ' + \\\n",
    "                      f'(val_loss = {val_loss.min():.4f}, ' + \\\n",
    "                      f'MAPE = {MAPE:.4f}%).')\n",
    "else:\n",
    "    best_experiment_IDs = {1: {'Vd_bus3': '474d2016e33b441889ce8b17531487cb',\n",
    "                               'Vq_bus3': '617188cbcaef4816a8853081fd303ac1'}, #'4c8bfb605ed74ea2935f3c3ce416b52d'\n",
    "                           2: {'Vd_bus3': 'fb6e5dd5df00455fb12c97d0daf77d84',\n",
    "                               'Vq_bus3': 'f19eac813b484b8c8708ebde2cd5b2c0'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e25044",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 4\n",
    "fig,ax = plt.subplots(rows, 5, width_ratios=[1, 1.8, 1, 2.2, 1], figsize=(16.5/2.54, 3.75/2.54*rows))\n",
    "\n",
    "force = False\n",
    "k = 0\n",
    "for area_ID in (1,2):\n",
    "    for var_name in ('Vd_bus3','Vq_bus3'):\n",
    "        experiment_ID = best_experiment_IDs[area_ID][var_name]\n",
    "        data_file = f'hist_spectra_acc_corr_area_{area_ID}_{var_name}_{experiment_ID[:6]}.npz'\n",
    "        if force or not os.path.isfile(data_file):\n",
    "            set_name = 'training'\n",
    "            data_dir = '/home/daniele/Research/deep-power/data/IEEE39/converted_from_PowerFactory/' + \\\n",
    "                f'all_stoch_loads/var_H_area_{area_ID}_comp_grid/subset_2'\n",
    "            data_files = sorted(glob.glob(os.path.join(data_dir, '*' + set_name + '*.h5')))\n",
    "            generators_areas_map = [['G02','G03','Comp11'],\n",
    "                             ['G04','G05','G06','G07','Comp21'],\n",
    "                             ['G08','G09', 'G10','Comp31'],\n",
    "                             ['G01']]\n",
    "            generators_Pnom = {'G01': 10000e6, 'G02': 700e6, 'G03': 800e6, 'G04': 800e6, 'G05': 300e6,\n",
    "                        'G06': 800e6, 'G07': 700e6, 'G08': 700e6, 'G09': 1000e6, 'G10': 1000e6,\n",
    "                        'Comp11': 100e6, 'Comp21': 100e6, 'Comp31': 100e6}\n",
    "\n",
    "            ret = load_data_areas({set_name: data_files}, [var_name],\n",
    "                                  [generators_areas_map[ID-1] for ID in [area_ID]],\n",
    "                                  generators_Pnom,\n",
    "                                  area_measure='momentum',\n",
    "                                  trial_dur=60,\n",
    "                                  max_block_size=10000,\n",
    "                                  use_tf=False,\n",
    "                                  add_omega_ref=True,\n",
    "                                  use_fft=False)\n",
    "\n",
    "            t = ret[0]\n",
    "            X_raw = ret[1][set_name]\n",
    "            y = ret[2][set_name]\n",
    "            group_index = [np.where(y == mom)[0] for mom in np.unique(y)]\n",
    "            n_mom_groups = len(group_index)\n",
    "            X_mean, X_std = X_raw.mean(axis=(1,2)), X_raw.std(axis=(1,2))\n",
    "            X = (X_raw - X_mean) / X_std\n",
    "            X = X.squeeze()\n",
    "            y = y.squeeze()\n",
    "            norm_std = [X[idx].std() for idx in group_index]\n",
    "\n",
    "            dt = np.diff(t[:2])[0]\n",
    "            N_samples = t.size\n",
    "            Xf = fft(X)\n",
    "            Xf = 2.0 / N_samples * np.abs(Xf[:, :N_samples//2])\n",
    "            F = fftfreq(N_samples, dt)[:N_samples//2]\n",
    "\n",
    "            Xf = [Xf[idx,:].mean(axis=0) for idx in group_index]\n",
    "            N,edges = zip(*(np.histogram(X[idx,:], bins=50, density=True) for idx in group_index))\n",
    "\n",
    "            experiments_path = '../experiments/neural_network/'\n",
    "            test_results = pickle.load(open(os.path.join(experiments_path, experiment_ID,\n",
    "                                                         'test_results.pkl'), 'rb'))\n",
    "            MAPE = test_results['mape_prediction'][0]\n",
    "            N_bands = 60\n",
    "            filter_order = 6\n",
    "            if experiment_ID == '474d2016e33b441889ce8b17531487cb':\n",
    "                N_trials = 4000\n",
    "            else:\n",
    "                N_trials = 1000\n",
    "            correlations_file = f'correlations_{experiment_ID[:6]}_{N_bands}-bands_64-filters_' + \\\n",
    "                f'36-neurons_{N_trials}-trials_{filter_order}-butter_{var_name}_pool_1_3.npz'\n",
    "            correlations = np.load(os.path.join(experiments_path, experiment_ID, correlations_file))\n",
    "            R, R_ctrl = correlations['R'], correlations['R_ctrl']\n",
    "            R[correlations['p'] > 0.05] = np.nan\n",
    "            R_ctrl[correlations['p_ctrl'] > 0.05] = np.nan\n",
    "            R_mean = np.nanmean(R, axis=0)\n",
    "            R_ctrl_mean = np.nanmean(R_ctrl, axis=0)\n",
    "\n",
    "            np.savez_compressed(data_file, N=N, edges=edges, F=F, Xf=Xf, norm_std=norm_std,\n",
    "                                exact_momentum=correlations['exact_momentum'],\n",
    "                                pred_momentum=correlations['pred_momentum'],\n",
    "                                pred_momentum_ctrl=correlations['pred_momentum_ctrl'], MAPE=MAPE,\n",
    "                                R_mean=R_mean, R_ctrl_mean=R_ctrl_mean, corr_edges=correlations['edges'])\n",
    "\n",
    "        data = np.load(data_file)\n",
    "        for key in data.files:\n",
    "            exec(f'{key} = data[\"{key}\"]')\n",
    "\n",
    "        plot_subplots(N, edges, norm_std, F, Xf, exact_momentum, pred_momentum, pred_momentum_ctrl,\n",
    "              MAPE, R_mean, R_ctrl_mean, corr_edges, ax[k,:])\n",
    "        ax[k,2].set_title('Area {}, {}'.format(area_ID, var_name.replace('_',' @ ')), fontsize=fontsize+1)\n",
    "        xl,yl = ax[k,3].get_xlim(), ax[k,3].get_ylim()\n",
    "        x,y = xl[0] + np.diff(xl)/20, np.logspace(np.log10(yl[0]), np.log10(yl[1]), 20)[1]\n",
    "        ax[k,3].text(x, y, experiment_ID[:6], fontsize=fontsize+1, color='k')\n",
    "        k += 1\n",
    "\n",
    "only_first = True\n",
    "if only_first:\n",
    "    trans = mtransforms.ScaledTranslation(-0.4, -0.05, fig.dpi_scale_trans)\n",
    "else:\n",
    "    trans = mtransforms.ScaledTranslation(-0.3, -0.05, fig.dpi_scale_trans)\n",
    "for i,label in enumerate('ABCD'):\n",
    "    if only_first:\n",
    "        ax[i,0].text(0.0, 1.0, label, transform=ax[i,0].transAxes + trans, fontsize=fontsize+2, va='bottom')\n",
    "    else:\n",
    "        for j in range(5):\n",
    "            ax[i,j].text(0.0, 1.0, label+str(j+1), transform=ax[i,j].transAxes + trans,\n",
    "                         fontsize=fontsize, va='bottom')\n",
    "fig.tight_layout(pad=0.3)\n",
    "plt.savefig('hist_spectra_acc_corr_supp.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
