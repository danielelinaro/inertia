{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from comet_ml.api import API, APIExperiment\n",
    "from comet_ml.query import Tag\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from deep_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure for the PSCC-2022 abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "workspace = 'danielelinaro'\n",
    "project_name = 'inertia'\n",
    "D = 2\n",
    "DZA = 60\n",
    "network_name = 'IEEE39'\n",
    "inertia_units = 'GW s'\n",
    "area_ID = 1\n",
    "# inertia of generator 1\n",
    "H_G1 = 500 # [s]\n",
    "# the bus(es) where the stochastic load is connected\n",
    "stoch_load_bus_IDs = [3]\n",
    "stoch_load_bus_list = 'stoch_load_bus_' + '-'.join(map(str, stoch_load_bus_IDs))\n",
    "# the bus(es) used for recording: an empy list means that the corresponding experiment tag won't be used\n",
    "rec_bus_IDs = []\n",
    "\n",
    "query = Tag(network_name) & \\\n",
    "        Tag(f'D={D}') & \\\n",
    "        Tag(f'DZA={DZA}') & \\\n",
    "        Tag('1D_pipeline') & \\\n",
    "        Tag(stoch_load_bus_list) & \\\n",
    "        Tag(f'H_G1_{H_G1}') & \\\n",
    "        Tag(f'area{area_ID}')\n",
    "\n",
    "if len(rec_bus_IDs) > 1:\n",
    "    rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "    query &= Tag(rec_bus_list)\n",
    "\n",
    "experiments = api.query(workspace, project_name, query, archived=False)\n",
    "experiment_IDs = []\n",
    "MAPE = []\n",
    "val_loss = []\n",
    "loss = []\n",
    "batch_loss = []\n",
    "tags =  []\n",
    "for experiment in experiments:\n",
    "    ID = experiment.id\n",
    "    experiment_IDs.append(ID)\n",
    "    sys.stdout.write(f'Downloading data for experiment ID {ID}... ')\n",
    "    metrics = experiment.get_metrics()\n",
    "    sys.stdout.write('done.\\n')\n",
    "    val_loss.append(np.array([float(m['metricValue']) for m in metrics if m['metricName'] == 'val_loss']))\n",
    "    loss.append(np.array([float(m['metricValue']) for m in metrics if m['metricName'] == 'loss']))\n",
    "    batch_loss.append(np.array([float(m['metricValue']) for m in metrics if m['metricName'] == 'batch_loss']))\n",
    "    has_MAPE = False\n",
    "    for m in metrics:\n",
    "        if m['metricName'] == 'mape_prediction':\n",
    "            val = m['metricValue']\n",
    "            try:\n",
    "                MAPE.append(float(val))\n",
    "            except:\n",
    "                MAPE.append(list(map(float, [v for v in val[1:-1].split(' ') if len(v)])))\n",
    "            has_MAPE = True\n",
    "            break\n",
    "    tags.append(experiment.get_tags())\n",
    "    print(f'  val_loss: {val_loss[-1].min():.4f}')\n",
    "    if has_MAPE:\n",
    "        print(f'      MAPE: {MAPE[-1]}%')\n",
    "    else:\n",
    "        print('      MAPE: [experiment not terminated]')\n",
    "    print('      Tags: \"{}\"'.format('\" \"'.join(tags[-1])))\n",
    "idx = np.argmin([loss.min() for loss in val_loss])\n",
    "experiment_ID = experiment_IDs[idx]\n",
    "MAPE = MAPE[idx]\n",
    "val_loss = val_loss[idx]\n",
    "loss = loss[idx]\n",
    "batch_loss = batch_loss[idx]\n",
    "tags = tags[idx]\n",
    "print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE}%).')\n",
    "\n",
    "experiments_path = '../experiments/neural_network/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "network_parameters = pickle.load(open(experiments_path + experiment_ID + '/parameters.pkl', 'rb'))\n",
    "test_results = pickle.load(open(experiments_path + experiment_ID + '/test_results.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = len(loss)\n",
    "epochs = np.arange(n_epochs) + 1\n",
    "\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'size'   : 8}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig,ax = plt.subplots(1, 2, figsize=(3.3, 1.8))\n",
    "ax[0].semilogy(epochs, val_loss, color=[.8,.8,.8], lw=1, label='Validation set')\n",
    "ax[0].semilogy(epochs, loss, 'k', lw=1, label='Training set')\n",
    "ax[0].legend(loc='upper right', fontsize=7)\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_xticks(np.r_[0 : 650 : 150])\n",
    "y_test, y_prediction = test_results['y_test'], test_results['y_prediction']\n",
    "ax[1].plot([8,14.5], [8,14.5], lw=2, color=[.8,.8,.8])\n",
    "ax[1].plot(y_test, y_prediction, 'o', color=[.6,.6,.6], markerfacecolor='w', markersize=3, markeredgewidth=0.5)\n",
    "for x in np.unique(y_test):\n",
    "    idx,_ = np.where(y_test == x)\n",
    "    ymean, ystd = y_prediction[idx].mean(), y_prediction[idx].std()\n",
    "    ysem = ystd / np.sqrt(len(idx))\n",
    "    ax[1].plot(x + np.zeros(2), ymean + 3 * ystd * np.array([-1,1]), 'k', linewidth=1)\n",
    "    ax[1].plot(x, ymean, 'ko', markerfacecolor='w', markersize=3.75, markeredgewidth=1)\n",
    "ax[1].set_xlabel(r'Inertia [GW$\\cdot$s]')\n",
    "ax[1].set_ylabel(r'Predicted inertia [GW$\\cdot$s]')\n",
    "ax[1].set_xticks(np.r_[8:16])\n",
    "ax[1].set_yticks(np.r_[8:16])\n",
    "ax[1].text(8.5, 14.5, f'MAPE = {MAPE:.2f}%', fontsize=7)\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'top','right':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)\n",
    "fig.savefig(f'training_results_{experiment_ID[:6]}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure with training results comparison\n",
    "\n",
    "IEEE39 network, inertia changed in area 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "workspace = 'danielelinaro'\n",
    "project_name = 'inertia'\n",
    "\n",
    "area = 1\n",
    "if area == 1:\n",
    "    experiment_IDs = [\n",
    "        '505c290d41d64bb39fc40d9c6f8ff0f4', # bus 14\n",
    "        'ff59cc49801f49328074538fcae5407d', # buses 3 and 14\n",
    "        '97131ee9bae6498086050fb2201bfbae'  # buses 3, 14 and 17\n",
    "    ]\n",
    "elif area == 2:\n",
    "    experiment_IDs = [\n",
    "        'df4192b3ec904551b81df8f4743b63f9', # bus 14\n",
    "        '8026c27b6a944734a2507b7a44136b6f', # buses 3 and 14\n",
    "        'a07428e678f345c78dbcf1c795a85500'  # buses 3, 14 and 17\n",
    "    ]\n",
    "    \n",
    "experiments = [api.get_experiment_by_id(ID) for ID in experiment_IDs]\n",
    "metrics = [experiment.get_metrics() for experiment in experiments]\n",
    "parameters = [pickle.load(open(f'../experiments/neural_network/{ID}/parameters.pkl', 'rb')) \\\n",
    "              for ID in experiment_IDs]\n",
    "test_results = [pickle.load(open(f'../experiments/neural_network/{ID}/test_results.pkl', 'rb')) \\\n",
    "                for ID in experiment_IDs]\n",
    "losses = [[float(m['metricValue']) for m in metric if m['metricName'] == 'loss'] for metric in metrics]\n",
    "val_losses = [[float(m['metricValue']) for m in metric if m['metricName'] == 'val_loss'] for metric in metrics]\n",
    "bus_IDs = [sorted(list(set([int(re.findall('\\d+', var_name)[0]) for var_name in pars['var_names']]))) \\\n",
    "           for pars in parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('rainbow', 3)\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "gs = fig.add_gridspec(2, 6)\n",
    "ax = [\n",
    "    [fig.add_subplot(gs[0,:3]), fig.add_subplot(gs[0,3:])],\n",
    "    [fig.add_subplot(gs[1,:2]), fig.add_subplot(gs[1,2:4]), fig.add_subplot(gs[1,4:])]\n",
    "]\n",
    "\n",
    "for i,(loss,val_loss) in enumerate(zip(losses,val_losses)):\n",
    "    n = len(loss)\n",
    "    epochs = np.arange(n) + 1\n",
    "    if len(bus_IDs[i]) == 1:\n",
    "        lbl = f'Bus {bus_IDs[i][0]}'\n",
    "    else:\n",
    "        lbl = 'Buses ' + '-'.join(list(map(str, bus_IDs[i])))\n",
    "    ax[0][0].semilogy(epochs, loss, color=cmap(i), lw=1, label=lbl)\n",
    "    ax[0][1].semilogy(epochs, val_loss, color=cmap(i), lw=1)\n",
    "\n",
    "ax[0][0].legend(loc='upper right')\n",
    "ax[0][0].set_ylabel('Training loss')\n",
    "ax[0][1].set_ylabel('Validation loss')\n",
    "\n",
    "for i,results in enumerate(test_results):\n",
    "    y_test, y_prediction = results['y_test'], results['y_prediction']\n",
    "    ax[1][i].plot([8,14.5], [8,14.5], lw=2, color=[.6,.6,.6])\n",
    "    ax[1][i].plot(y_test, y_prediction, 'o', color=[.8,.8,.8], markerfacecolor='w', markersize=3, markeredgewidth=0.5)\n",
    "    for x in np.unique(y_test):\n",
    "        idx, = np.where(y_test == x)\n",
    "        ymean, ystd = y_prediction[idx].mean(), y_prediction[idx].std()\n",
    "        ysem = ystd / np.sqrt(len(idx))\n",
    "        ax[1][i].plot(x + np.zeros(2), ymean + 3 * ystd * np.array([-1,1]), color=cmap(i), linewidth=1.5)\n",
    "        ax[1][i].plot(x, ymean, 's', color=cmap(i), markerfacecolor='w', markersize=5, markeredgewidth=1.5)\n",
    "    ax[1][i].text(8.5, 14.5, 'MAPE = {:.2f}%'.format(results['mape_prediction'][0]), fontsize=7)\n",
    "\n",
    "for a in ax[0]:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.set_xlabel('Epoch')\n",
    "    a.set_ylim([1e-2, 2])\n",
    "for a in ax[1]:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "    a.set_xlabel('Real inertia [GWs]')\n",
    "    if a == ax[1][0]:\n",
    "        a.set_ylabel('Predicted inertia [GWs]')\n",
    "    a.set_xlim([7.5, 15])\n",
    "    a.set_ylim([7.5, 15])\n",
    "    a.set_xticks(np.r_[8:16])\n",
    "    a.set_yticks(np.r_[8:16])\n",
    "    a.grid(which='major', axis='y', lw=0.5, ls=':', color=[.75,.75,.75])\n",
    "ax[1][1].set_title('Test results')\n",
    "fig.tight_layout()\n",
    "for ext in 'pdf','png':\n",
    "    fig.savefig(f'IEEE39_training_results_area_{area}.{ext}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
