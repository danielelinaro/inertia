{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from comet_ml.api import API, APIExperiment\n",
    "from comet_ml.query import Tag\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from deep_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "workspace = 'danielelinaro'\n",
    "project_name = 'inertia'\n",
    "D = 2\n",
    "DZA = 60\n",
    "network_name = 'IEEE39'\n",
    "inertia_units = 'GW s'\n",
    "area_ID = 1\n",
    "# inertia of generator 1\n",
    "H_G1 = 500 # [s]\n",
    "# the bus(es) where the stochastic load is connected\n",
    "stoch_load_bus_IDs = [3]\n",
    "stoch_load_bus_list = 'stoch_load_bus_' + '-'.join(map(str, stoch_load_bus_IDs))\n",
    "# the bus(es) used for recording: an empy list means that the corresponding experiment tag won't be used\n",
    "rec_bus_IDs = []\n",
    "\n",
    "query = Tag(network_name) & \\\n",
    "        Tag(f'D={D}') & \\\n",
    "        Tag(f'DZA={DZA}') & \\\n",
    "        Tag('1D_pipeline') & \\\n",
    "        Tag(stoch_load_bus_list) & \\\n",
    "        Tag(f'H_G1_{H_G1}') & \\\n",
    "        Tag(f'area{area_ID}')\n",
    "\n",
    "if len(rec_bus_IDs) > 1:\n",
    "    rec_bus_list = 'buses_' + '-'.join(map(str, rec_bus_IDs))\n",
    "    query &= Tag(rec_bus_list)\n",
    "\n",
    "experiments = api.query(workspace, project_name, query, archived=False)\n",
    "experiment_IDs = []\n",
    "MAPE = []\n",
    "val_loss = []\n",
    "loss = []\n",
    "batch_loss = []\n",
    "tags =  []\n",
    "for experiment in experiments:\n",
    "    ID = experiment.id\n",
    "    experiment_IDs.append(ID)\n",
    "    sys.stdout.write(f'Downloading data for experiment ID {ID}... ')\n",
    "    metrics = experiment.get_metrics()\n",
    "    sys.stdout.write('done.\\n')\n",
    "    val_loss.append(np.array([float(m['metricValue']) for m in metrics if m['metricName'] == 'val_loss']))\n",
    "    loss.append(np.array([float(m['metricValue']) for m in metrics if m['metricName'] == 'loss']))\n",
    "    batch_loss.append(np.array([float(m['metricValue']) for m in metrics if m['metricName'] == 'batch_loss']))\n",
    "    has_MAPE = False\n",
    "    for m in metrics:\n",
    "        if m['metricName'] == 'mape_prediction':\n",
    "            val = m['metricValue']\n",
    "            try:\n",
    "                MAPE.append(float(val))\n",
    "            except:\n",
    "                MAPE.append(list(map(float, [v for v in val[1:-1].split(' ') if len(v)])))\n",
    "            has_MAPE = True\n",
    "            break\n",
    "    tags.append(experiment.get_tags())\n",
    "    print(f'  val_loss: {val_loss[-1].min():.4f}')\n",
    "    if has_MAPE:\n",
    "        print(f'      MAPE: {MAPE[-1]}%')\n",
    "    else:\n",
    "        print('      MAPE: [experiment not terminated]')\n",
    "    print('      Tags: \"{}\"'.format('\" \"'.join(tags[-1])))\n",
    "idx = np.argmin([loss.min() for loss in val_loss])\n",
    "experiment_ID = experiment_IDs[idx]\n",
    "MAPE = MAPE[idx]\n",
    "val_loss = val_loss[idx]\n",
    "loss = loss[idx]\n",
    "batch_loss = batch_loss[idx]\n",
    "tags = tags[idx]\n",
    "print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE}%).')\n",
    "\n",
    "experiments_path = '../experiments/neural_network/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "network_parameters = pickle.load(open(experiments_path + experiment_ID + '/parameters.pkl', 'rb'))\n",
    "test_results = pickle.load(open(experiments_path + experiment_ID + '/test_results.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = len(loss)\n",
    "epochs = np.arange(n_epochs) + 1\n",
    "\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'size'   : 8}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig,ax = plt.subplots(1, 2, figsize=(3.3, 1.8))\n",
    "ax[0].semilogy(epochs, val_loss, color=[.8,.8,.8], lw=1, label='Validation set')\n",
    "ax[0].semilogy(epochs, loss, 'k', lw=1, label='Training set')\n",
    "ax[0].legend(loc='upper right', fontsize=7)\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_xticks(np.r_[0 : 650 : 150])\n",
    "y_test, y_prediction = test_results['y_test'], test_results['y_prediction']\n",
    "ax[1].plot([8,14.5], [8,14.5], lw=2, color=[.8,.8,.8])\n",
    "ax[1].plot(y_test, y_prediction, 'o', color=[.6,.6,.6], markerfacecolor='w', markersize=3, markeredgewidth=0.5)\n",
    "for x in np.unique(y_test):\n",
    "    idx, = np.where(y_test == x)\n",
    "    ymean, ystd = y_prediction[idx].mean(), y_prediction[idx].std()\n",
    "    ysem = ystd / np.sqrt(len(idx))\n",
    "    ax[1].plot(x + np.zeros(2), ymean + 3 * ystd * np.array([-1,1]), 'k', linewidth=1)\n",
    "    ax[1].plot(x, ymean, 'ko', markerfacecolor='w', markersize=3.75, markeredgewidth=1)\n",
    "ax[1].set_xlabel(r'Inertia [GW$\\cdot$s]')\n",
    "ax[1].set_ylabel(r'Predicted inertia [GW$\\cdot$s]')\n",
    "ax[1].set_xticks(np.r_[8:16])\n",
    "ax[1].set_yticks(np.r_[8:16])\n",
    "ax[1].text(8.5, 14.5, f'MAPE = {MAPE:.2f}%', fontsize=7)\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'top','right':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)\n",
    "fig.savefig(f'training_results_{experiment_ID[:6]}.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
