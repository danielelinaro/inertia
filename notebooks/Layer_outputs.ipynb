{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import butter, filtfilt, lombscargle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import read_area_values, load_data_areas, load_data_slide\n",
    "from dlml.nn import predict, DownSampling1D, SpectralPooling, MaxPooling1DWithArgmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36871b",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b90255",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ID = 1\n",
    "area_measure = 'momentum'\n",
    "stoch_load_bus_IDs = []\n",
    "rec_bus_IDs = [3]\n",
    "H_G1, D, DZA = None, None, None # 500, 2, 0\n",
    "additional_tags = ['ReLU_none', 'converted_from_PowerFactory', 'all_stoch_loads', 'data_subset']\n",
    "missing_tags = []\n",
    "use_FFT = False\n",
    "if use_FFT:\n",
    "    additional_tags.append('fft')\n",
    "else:\n",
    "    missing_tags.append('fft')\n",
    "pooling_type = 'argmax'\n",
    "if pooling_type is not None and pooling_type != '':\n",
    "    additional_tags.append(pooling_type + '_pooling')\n",
    "\n",
    "# training on frequency data, 2 output values\n",
    "# experiment_ID = '9ea493c789b542bf979c51a6031f4044'\n",
    "# training on frequency data, 4 output values\n",
    "# experiment_ID = 'f6d9a03f1cfe450288e9cb86da94235f'\n",
    "# training on time series data, 2 output values\n",
    "# experiment_ID = '034a1edb0797475b985f0e1335dab383'\n",
    "# training on time series data, 4 output values\n",
    "# experiment_ID = 'b346a89d384c4db2ba4058a2c83c4f12'\n",
    "experiment_ID = None\n",
    "\n",
    "if experiment_ID is not None:\n",
    "    from comet_ml.api import API, APIExperiment\n",
    "    api = API(api_key = os.environ['COMET_API_KEY'])\n",
    "    experiment = api.get_experiment('danielelinaro', 'inertia', experiment_ID)\n",
    "    sys.stdout.write(f'Getting metrics for experiment {experiment_ID[:6]}... ')\n",
    "    sys.stdout.flush()\n",
    "    metrics = experiment.get_metrics()\n",
    "    sys.stdout.write('done.\\n')\n",
    "    val_loss = []\n",
    "    for m in metrics:\n",
    "        if m['metricName'] == 'val_loss':\n",
    "            val_loss.append(float(m['metricValue']))\n",
    "        elif m['metricName'] == 'mape_prediction':\n",
    "            MAPE = float(m['metricValue'])\n",
    "    val_loss = np.array(val_loss)\n",
    "else:\n",
    "    # find the best experiment that matches the set of tags above\n",
    "    experiments = collect_experiments(area_ID, area_measure=area_measure, D=D, DZA=DZA, \\\n",
    "                                      stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=H_G1, \\\n",
    "                                      rec_bus_IDs=rec_bus_IDs, additional_tags=additional_tags, \\\n",
    "                                      missing_tags=missing_tags, verbose=True)\n",
    "    experiment_IDs = list(experiments.keys())\n",
    "    experiment_ID = experiment_IDs[np.argmin([expt['val_loss'].min() for expt in experiments.values()])]\n",
    "    experiment_ID = experiment_IDs[np.argmin([expt['MAPE'] for expt in experiments.values()])]\n",
    "\n",
    "    MAPE = experiments[experiment_ID]['MAPE']\n",
    "    loss = experiments[experiment_ID]['loss']\n",
    "    val_loss = experiments[experiment_ID]['val_loss']\n",
    "    batch_loss = experiments[experiment_ID]['batch_loss']\n",
    "    tags = experiments[experiment_ID]['tags']\n",
    "print(f'Selected experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE:.4f}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0a7fe",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81320651",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "network_parameters = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'parameters.pkl'), 'rb'))\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "try:\n",
    "    epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "except:\n",
    "    best_checkpoint = checkpoint_files[-1]\n",
    "try:\n",
    "    model = keras.models.load_model(best_checkpoint)\n",
    "except:\n",
    "    if pooling_type == 'downsample':\n",
    "        custom_objects = {'DownSampling1D': DownSampling1D}\n",
    "    elif pooling_type == 'spectral':\n",
    "        custom_objects = {'SpectralPooling': SpectralPooling}\n",
    "    elif pooling_type == 'argmax':\n",
    "        custom_objects = {'MaxPooling1DWithArgmax': MaxPooling1DWithArgmax}\n",
    "    with keras.utils.custom_object_scope(custom_objects):\n",
    "        model = keras.models.load_model(best_checkpoint)\n",
    "if pooling_type == 'argmax':\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, MaxPooling1DWithArgmax):\n",
    "            print(f'Setting store_argmax = True for layer \"{layer.name}\".')\n",
    "            layer.store_argmax = True\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "try:\n",
    "    x_train_min = network_parameters['x_train_min']\n",
    "    x_train_max = network_parameters['x_train_max']\n",
    "except:\n",
    "    pass\n",
    "var_names = network_parameters['var_names']\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Variable names: {var_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e540f",
   "metadata": {},
   "source": [
    "#### Plot the model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f8316",
   "metadata": {},
   "source": [
    "#### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08887b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = 'test'\n",
    "use_fft = network_parameters['use_fft'] if 'use_fft' in network_parameters else False\n",
    "data_dirs = []\n",
    "for area_ID,data_dir in zip(network_parameters['area_IDs'], network_parameters['data_dirs']):\n",
    "    data_dirs.append(data_dir.format(area_ID))\n",
    "data_dir = os.path.join('..', data_dirs[0])\n",
    "data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=100,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=use_fft)\n",
    "y = ret[2][set_name]\n",
    "if use_fft:\n",
    "    X = [(ret[1][set_name][i] - m) / (M - m) for i,(m,M) in enumerate(zip(x_train_min, x_train_max))]\n",
    "    F = ret[0]\n",
    "else:\n",
    "    X = [(ret[1][set_name][i] - m) / s for i,(m,s) in enumerate(zip(x_train_mean, x_train_std))]\n",
    "    t = ret[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f46974",
   "metadata": {},
   "source": [
    "#### Predict the momentum using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6537dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [np.where(y == mom)[0] for mom in np.unique(y)]\n",
    "n_mom_values = len(idx)\n",
    "momentum = [np.squeeze(model.predict(X[0][jdx])) for jdx in idx]\n",
    "mean_momentum = [m.mean() for m in momentum]\n",
    "stddev_momentum = [m.std() for m in momentum]\n",
    "print('Mean momentum:', mean_momentum)\n",
    "print(' Std momentum:', stddev_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8366a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10', n_mom_values)\n",
    "if use_fft:\n",
    "    Xf = X\n",
    "else:\n",
    "    data_files_training = sorted(glob.glob(data_dir + os.path.sep + f'*_training_set.h5'))\n",
    "    ret_fft = load_data_areas({'training': data_files_training}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=200,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=True)\n",
    "    x_train_min_fft = np.array([val.min() for val in ret_fft[1]['training']], dtype=np.float32)\n",
    "    x_train_max_fft = np.array([val.max() for val in ret_fft[1]['training']], dtype=np.float32)\n",
    "    ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=100,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=True)\n",
    "    F = ret[0]\n",
    "    Xf = [(ret[1][set_name][i] - m) / (M - m) for i,(m,M) in enumerate(zip(x_train_min_fft,\n",
    "                                                                           x_train_max_fft))]\n",
    "\n",
    "fig,ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "for i in range(len(idx)):\n",
    "    mean = Xf[0][idx[i]].mean(axis=0)\n",
    "    stddev = Xf[0][idx[i]].std(axis=0)\n",
    "    ci = 1.96 * stddev / np.sqrt(idx[i].size)\n",
    "    ax.fill_between(F, mean + ci, mean - ci, color=cmap(i))\n",
    "ax.set_xscale('log')\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.grid(which='major', axis='both', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "ax.set_xlabel('Frequency [Hz]')\n",
    "ax.set_ylabel('Normalized FFT')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'spectra_{n_mom_values}_momentum_levels.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "096eb16f",
   "metadata": {},
   "source": [
    "dt = np.diff(t[:2])[0]\n",
    "sampling_rate = 1 / dt\n",
    "cutoff_frequency = sampling_rate / 4\n",
    "print(f'Sampling rate = {sampling_rate:.4f} Hz')\n",
    "print(f'Cut-off frequency = {cutoff_frequency:.4f} Hz')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62490008",
   "metadata": {},
   "source": [
    "n_samples = X[0].shape[-1]\n",
    "input_layer = keras.Input(shape=(n_samples, 1), name='input_layer')\n",
    "conv = keras.layers.Conv1D(8, 16, activation=None, name='conv_1d')(input_layer)\n",
    "sp = SpectralPooling(sampling_rate, cutoff_frequency, name='sp')(conv)\n",
    "submodel = keras.Model(inputs=[input_layer], outputs=[conv])\n",
    "model = keras.Model(inputs=[input_layer], outputs=[sp])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2b928a4",
   "metadata": {},
   "source": [
    "x = tf.constant(X[0][idx[0]])\n",
    "y = submodel(x)\n",
    "z = model(x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96ff1b87",
   "metadata": {},
   "source": [
    "%matplotlib notebook\n",
    "ii = 5\n",
    "plt.plot(t, x[0, :], 'k', label='x')\n",
    "plt.plot(t[:-15], y[0, :, ii], 'r', label=r'$y_{}$'.format(ii))\n",
    "plt.plot(t[3:-17:2], z[0, :, ii], 'b', label=r'$z_{}$'.format(ii))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74371b1c",
   "metadata": {},
   "source": [
    "#### Make as many submodels as there are layers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51d663cb",
   "metadata": {},
   "source": [
    "multi_output_model = keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers[1:]])\n",
    "Y = [multi_output_model.predict(X[0][jdx]) for jdx in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_layers = len(model.layers)\n",
    "N_vars = len(var_names)\n",
    "submodels = [\n",
    "    keras.Model(inputs=model.inputs, outputs=[model.layers[j].output for j in range(i,i+N_vars)])\n",
    "     for i in range(N_vars, N_layers - N_vars - 3, N_vars)\n",
    "]\n",
    "for layer in model.layers[-4:]:\n",
    "    submodels.append(keras.Model(inputs=model.inputs, outputs=layer.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = 1\n",
    "submodel = submodels[layer_id]\n",
    "submodel.summary()\n",
    "Y = [submodel.predict(X[0][jdx]) for jdx in idx]\n",
    "print(Y[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4a70d",
   "metadata": {},
   "source": [
    "### Plot the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "for j,jdx in enumerate(idx):\n",
    "    mean = X[0][jdx].mean(axis=0)\n",
    "    stddev = X[0][jdx].std(axis=0)\n",
    "    ci = 1.96 * stddev / np.sqrt(jdx.size)\n",
    "    ax.fill_between(t, mean + ci, mean - ci, color=cmap(j))\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.set_xlabel('Time [min]')\n",
    "ax.grid(which='major', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de089153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which trial to use\n",
    "trial = 0\n",
    "# the input to the model\n",
    "x = X[0][trial:trial+1, :]\n",
    "# the output of the model\n",
    "y = submodel(x)\n",
    "y = np.squeeze(y.numpy().T)\n",
    "# let's build the time vector\n",
    "t_out = t[np.newaxis,:]\n",
    "for layer in submodel.layers:\n",
    "    if isinstance(layer, keras.layers.Conv1D):\n",
    "        kernel_size = layer.kernel_size[0]\n",
    "        n_filters = layer.filters\n",
    "#         if t_out.shape[0] != n_filters:\n",
    "        t_out = np.tile(t_out[:,kernel_size-1:], [n_filters,1])\n",
    "    elif isinstance(layer, MaxPooling1DWithArgmax):\n",
    "        jdx = tf.squeeze(layer.argmax).numpy().T // kernel_size\n",
    "        t_out = np.array([t_out[k,kdx] for k,kdx in enumerate(jdx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = np.array([lombscargle(t_out[i], y[i], F[1:]) for i in range(t_out.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6744a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "cmap2 = plt.get_cmap('viridis', y.shape[0])\n",
    "fig,ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "ax.plot(t, np.squeeze(x), 'k', lw=1)\n",
    "for i,(a,b) in enumerate(zip(t_out, y)):\n",
    "    ax.plot(a, b, markersize=2, lw=1, color=cmap2(i))\n",
    "ax.set_xlabel('Time [min]')\n",
    "ax.grid(which='major', axis='x', ls=':', lw=0.5, color=[.6,.6,.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaab1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1)\n",
    "for i in range(yf.shape[0]):\n",
    "    ax.loglog(F[1:], yf[i,:], color=cmap2(i), lw=1)\n",
    "for side in 'right','top':\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.grid(which='major', axis='both', ls=':', lw=0.5, color=[.6,.6,.6])\n",
    "ax.set_xlabel('Frequency [Hz]')\n",
    "ax.set_ylabel('Periodogram')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becde011",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_traces, n_samples, n_kernels = y[0].shape\n",
    "rows, cols = n_kernels // 8, 8\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(cols*1.5, rows),\n",
    "                      sharex=True, sharey=False)\n",
    "show_fft = False\n",
    "hp_filter = False\n",
    "if use_fft:\n",
    "    n = -1\n",
    "    m = int(n_samples / 3)\n",
    "    show_fft = False\n",
    "else:\n",
    "    n = -1\n",
    "    m = n_samples\n",
    "if show_fft:\n",
    "#     m = int(n_samples / 3)\n",
    "    m = n_samples // 2\n",
    "    Yf = []\n",
    "    dt = np.diff(t[:2])[0]\n",
    "    filter_order = 10\n",
    "    cutoff = 0.1\n",
    "    b,a = butter(filter_order//2, cutoff, 'hp', fs=1/dt)\n",
    "    for y in Y:\n",
    "        n_samples = y.shape[1]\n",
    "        if hp_filter:\n",
    "            tmp = filtfilt(b, a, y, axis=1)\n",
    "        else:\n",
    "            tmp = y\n",
    "        tmp = fft(tmp, axis=1)\n",
    "        Yf.append(2.0 / n_samples * np.abs(tmp[:, :n_samples//2, :]))    \n",
    "    freq = fftfreq(n_samples, dt)[:n_samples//2]\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = i * cols + j\n",
    "        if n > 0:\n",
    "            for q in range(len(Y)):\n",
    "                ax[i][j].plot(Y[q][:n, :m, k].T, color=cmap(q), lw=0.5)\n",
    "        else:\n",
    "            for q in range(len(Y)):\n",
    "                if show_fft:\n",
    "                    mean = Yf[q][:, :, k].mean(axis=0)\n",
    "                    stddev = Yf[q][:, :, k].std(axis=0)\n",
    "                    ci = 1.96 * stddev / np.sqrt(yf[q].shape[0])\n",
    "                    ax[i][j].fill_between(freq, mean[:m] + ci[:m], mean[:m] - ci[:m], color=cmap(q))\n",
    "                else:\n",
    "                    mean = Y[q][:, :, k].mean(axis=0)\n",
    "                    stddev = Y[q][:, :, k].std(axis=0)\n",
    "                    ci = 1.96 * stddev / np.sqrt(y[q].shape[0])\n",
    "#                     ax[i][j].fill_between(np.arange(m), mean[:m] + ci[:m], mean[:m] - ci[:m], color=cmap(q))\n",
    "                    ax[i][j].fill_between(t_out, mean + ci, mean - ci, color=cmap(q))\n",
    "                    ax[i][j].set_xticks(np.linspace(0, 60, 5))\n",
    "#         if show_fft:\n",
    "#             ax[i][j].set_xscale('log')\n",
    "#         else:\n",
    "#             ax[i][j].set_xticks([0, m])\n",
    "        for side in 'right','top':\n",
    "            ax[i][j].spines[side].set_visible(False)\n",
    "        ax[i][j].set_yticklabels([])\n",
    "fig.tight_layout(pad=0)\n",
    "output_file = experiment_ID[:6] + f'_layer_{layer_id}_outputs'\n",
    "if show_fft:\n",
    "    output_file += '_spectra'\n",
    "fig.savefig(output_file + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.squeeze(model.layers[layer_id].weights[0].numpy())\n",
    "print('weights shape:', weights.shape)\n",
    "if len(weights.shape) > 2:\n",
    "    input_id = 0\n",
    "    weights = np.squeeze(weights[:, input_id, :])\n",
    "else:\n",
    "    input_id = 0\n",
    "kernel_size, n_kernels = weights.shape\n",
    "if show_fft:\n",
    "    weightsf = fft(weights, axis=0)\n",
    "    weightsf = 2.0 / kernel_size * np.abs(weightsf[:kernel_size//2, :])\n",
    "rows, cols = n_kernels // 8, 8\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(cols*2, rows*1.5), sharex=True, sharey=True)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = i * 8 + j\n",
    "        if show_fft:\n",
    "            ax[i][j].plot(weightsf[:,k], 'k', lw=1)\n",
    "            ax[i][j].set_xticks([0, kernel_size//2])\n",
    "        else:\n",
    "            ax[i][j].plot(weights[:,k], 'k', lw=1)\n",
    "            ax[i][j].set_xticks([0, kernel_size])\n",
    "        for side in 'right','top':\n",
    "            ax[i][j].spines[side].set_visible(False)\n",
    "fig.tight_layout(pad=0)\n",
    "output_file = experiment_ID[:6] + f'_layer_{layer_id}_input_{input_id}_weights'\n",
    "if show_fft:\n",
    "    output_file += '_spectra'\n",
    "fig.savefig(output_file + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Stop here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdaf8c",
   "metadata": {},
   "source": [
    "## Continue from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_blocks = len(data_sliding[0][var_names[0]])\n",
    "inputs_to_network = []\n",
    "inputs_to_classifier = []\n",
    "outputs = []\n",
    "for data_slid in data_sliding:\n",
    "    for i in range(N_blocks):\n",
    "        x = {var_name: tf.constant(data_slid[var_name][i:i+1,:], dtype=tf.float32) for var_name in var_names}\n",
    "        inputs_to_network.append(np.concatenate([np.squeeze(data_slid[var_name][i:i+1,:]) for var_name in var_names]))\n",
    "        inputs_to_classifier.append(np.squeeze(submodels[-3].predict(x)))\n",
    "#         inputs_to_classifier.append(np.squeeze(submodels[-2].predict(x)))\n",
    "        outputs.append(np.squeeze(submodels[-1].predict(x)))\n",
    "inputs_to_network = np.array(inputs_to_network)\n",
    "inputs_to_classifier = np.array(inputs_to_classifier)\n",
    "outputs = np.array(outputs)\n",
    "scaled_inputs_to_network = StandardScaler().fit_transform(inputs_to_network)\n",
    "scaled_inputs_to_classifier = StandardScaler().fit_transform(inputs_to_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'kr'\n",
    "fig,ax = plt.subplots(2, 1, figsize=(10,5), sharex=False)\n",
    "j = 10\n",
    "for i in range(2):\n",
    "    ax[0].plot(inputs_to_network[i*N_blocks + j], col[i], lw=1)\n",
    "    ax[1].plot(inputs_to_classifier[i*N_blocks + j], col[i], lw=1, label=f'{outputs[i*N_blocks+j,0]:.2f}')\n",
    "ax[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98de7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_to_classifier[i + j].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_to_classifier[i*N_blocks + j].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_inputs_to_network = np.zeros(N_blocks)\n",
    "dst_inputs_to_classifier = np.zeros(N_blocks)\n",
    "for i in range(N_blocks):\n",
    "    alignment = dtw.dtw(inputs_to_network[i], inputs_to_network[i+N_blocks], keep_internals=False)\n",
    "    dst_inputs_to_network[i] = alignment.distance\n",
    "    alignment = dtw.dtw(inputs_to_classifier[i], inputs_to_classifier[i+N_blocks], keep_internals=False)\n",
    "    dst_inputs_to_classifier[i] = alignment.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1766d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(dst_inputs_to_network, [0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(dst_inputs_to_classifier, [0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "m = np.min([inputs_to_network[i].min(), inputs_to_network[i+N_blocks].min()])\n",
    "M = np.max([inputs_to_network[i].max(), inputs_to_network[i+N_blocks].max()])\n",
    "dst_inputs_to_network = np.sqrt((inputs_to_network[i] - inputs_to_network[i+N_blocks]) ** 2) / (M - m)\n",
    "m = np.min([inputs_to_classifier[i].min(), inputs_to_classifier[i+N_blocks].min()])\n",
    "M = np.max([inputs_to_classifier[i].max(), inputs_to_classifier[i+N_blocks].max()])\n",
    "dst_inputs_to_classifier = np.sqrt((inputs_to_classifier[i] - inputs_to_classifier[i+N_blocks]) ** 2) / (M - m)\n",
    "\n",
    "plt.plot(dst_inputs_to_network, 'k', lw=0.5)\n",
    "plt.plot(dst_inputs_to_classifier, 'r', lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3122e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((scaled_inputs_to_network[0] - scaled_inputs_to_network[N]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((scaled_inputs_to_classifier[0] - scaled_inputs_to_classifier[N]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d023c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pc_inputs_to_network = pca.fit_transform(scaled_inputs_to_network)\n",
    "pc_inputs_to_classifier = pca.fit_transform(scaled_inputs_to_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(7,4))\n",
    "ax[0].plot(pc_inputs_to_network[:N,0], pc_inputs_to_network[:N,1], 'k.')\n",
    "ax[0].plot(pc_inputs_to_network[N:,0], pc_inputs_to_network[N:,1], 'r.')\n",
    "ax[1].plot(pc_inputs_to_classifier[:N,0], pc_inputs_to_classifier[:N,1], 'k.')\n",
    "ax[1].plot(pc_inputs_to_classifier[N:,0], pc_inputs_to_classifier[N:,1], 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_inputs_to_network = umap.UMAP().fit_transform(scaled_inputs_to_network)\n",
    "embedding_inputs_to_classifier = umap.UMAP().fit_transform(scaled_inputs_to_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4de92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(embedding_inputs_to_network[:N,0], embedding_inputs_to_network[:N,1],\n",
    "         'ko', ms=4, markerfacecolor='w')\n",
    "plt.plot(embedding_inputs_to_network[N:,0], embedding_inputs_to_network[N:,1],\n",
    "         'ks', ms=4)\n",
    "plt.plot(embedding_inputs_to_classifier[:N,0], embedding_inputs_to_classifier[:N,1],\n",
    "         'ro', ms=4, markerfacecolor='w')\n",
    "plt.plot(embedding_inputs_to_classifier[N:,0], embedding_inputs_to_classifier[N:,1],\n",
    "         'rs', ms=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[0]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=True)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[1]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94de17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[2]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[3]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[4]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2abb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[5]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc75f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(10,3))\n",
    "for i,a in enumerate(ax):\n",
    "    a.plot(outputs[6+i][0], 'k', lw=1)\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(10,3))\n",
    "for i,a in enumerate(ax):\n",
    "    a.plot(outputs[6+i][0], 'k', lw=1)\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
