{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import tables\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import dtw\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import read_area_values, load_data_areas, load_data_slide\n",
    "from dlml.nn import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36871b",
   "metadata": {},
   "source": [
    "#### Find the best experiment given a set of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b90255",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ID = 1\n",
    "area_measure = 'momentum'\n",
    "stoch_load_bus_IDs = []\n",
    "rec_bus_IDs = [3]\n",
    "H_G1, D, DZA = None, None, None # 500, 2, 0\n",
    "additional_tags = ['ReLU_none', 'converted_from_PowerFactory', 'all_stoch_loads', 'data_subset']\n",
    "experiments = collect_experiments(area_ID, area_measure=area_measure, D=D, DZA=DZA, \\\n",
    "                                  stoch_load_bus_IDs=stoch_load_bus_IDs, H_G1=H_G1, \\\n",
    "                                  rec_bus_IDs=rec_bus_IDs, additional_tags=additional_tags, \\\n",
    "                                  verbose=True)\n",
    "experiment_IDs = list(experiments.keys())\n",
    "experiment_ID = experiment_IDs[np.argmin([expt['val_loss'].min() for expt in experiments.values()])]\n",
    "MAPE = experiments[experiment_ID]['MAPE']\n",
    "loss = experiments[experiment_ID]['loss']\n",
    "val_loss = experiments[experiment_ID]['val_loss']\n",
    "batch_loss = experiments[experiment_ID]['batch_loss']\n",
    "tags = experiments[experiment_ID]['tags']\n",
    "print(f'The best experiment is {experiment_ID[:6]} (val_loss = {val_loss.min():.4f}, MAPE = {MAPE:.4f}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0a7fe",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81320651",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "network_parameters = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'parameters.pkl'), 'rb'))\n",
    "epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "model = keras.models.load_model(best_checkpoint)\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "var_names = network_parameters['var_names']\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Variable names: {var_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e540f",
   "metadata": {},
   "source": [
    "#### Plot the model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=False, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f8316",
   "metadata": {},
   "source": [
    "#### Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = []\n",
    "for area_ID,data_dir in zip(network_parameters['area_IDs'], network_parameters['data_dirs']):\n",
    "    data_dirs.append(data_dir.format(area_ID))\n",
    "data_dir = os.path.join('..', data_dirs[0])\n",
    "data_files = sorted(glob.glob(data_dir + os.path.sep + '*_test_set.h5'))\n",
    "X = []\n",
    "for data_file in data_files:\n",
    "    fid = tables.open_file(data_file)\n",
    "    time = fid.root.time.read()\n",
    "    x = [(fid.root[var_name].read()[:,:-1] - m) / s for var_name,m,s in zip(network_parameters['var_names'],\n",
    "                                                                            x_train_mean,\n",
    "                                                                            x_train_std)]\n",
    "    X.append([np.reshape(y, [-1, 2400]) for y in x])\n",
    "    fid.close()\n",
    "dt = np.diff(time[:2])[0]\n",
    "sampling_rate = 1 / dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f46974",
   "metadata": {},
   "source": [
    "#### Predict the momentum using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6537dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = [np.squeeze(model.predict(x)) for x in X]\n",
    "mean_momentum = [m.mean() for m in momentum]\n",
    "print('Mean momentum:', mean_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74371b1c",
   "metadata": {},
   "source": [
    "#### Make as many submodels as there are layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_layers = len(model.layers)\n",
    "N_vars = len(var_names)\n",
    "submodels = [\n",
    "    keras.Model(inputs=model.inputs, outputs=[model.layers[j].output for j in range(i,i+N_vars)])\n",
    "     for i in range(N_vars, N_layers - N_vars - 3, N_vars)\n",
    "]\n",
    "for layer in model.layers[-4:]:\n",
    "    submodels.append(keras.Model(inputs=model.inputs, outputs=layer.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "submodel = submodels[i]\n",
    "submodel.summary()\n",
    "y = [submodel.predict(x) for x in X]\n",
    "print(y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7737e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.squeeze(model.layers[1].weights[0].numpy())\n",
    "fig,ax = plt.subplots(2, 8, figsize=(12, 3), sharex=True, sharey=True)\n",
    "for i in range(2):\n",
    "    for j in range(8):\n",
    "        k = i * 8 + j\n",
    "        ax[i][j].plot(weights[:,k], 'k', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57586223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time[:2400], X[0][0][0,:], 'k', lw=1)\n",
    "plt.plot(time[:2400], X[1][0][0,:], 'r', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc09ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y[0][:n, :, 11].T, 'k', lw=1)\n",
    "plt.plot(y[1][:n, :, 11].T, 'r', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761deb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y[0][:n, :, 15].T, 'k', lw=1)\n",
    "plt.plot(y[1][:n, :, 15].T, 'r', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becde011",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = y[0].shape[2] // 8, 8\n",
    "fig,ax = plt.subplots(rows, cols, figsize=(cols*1.5, rows*1.5),\n",
    "                      sharex=True, sharey=True)\n",
    "n = 1\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        k = i * cols + j\n",
    "        ax[i][j].plot(y[0][:n, :, k].T, 'k', lw=1)\n",
    "        ax[i][j].plot(y[1][:n, :, k].T, 'r', lw=1)\n",
    "#         ax[i][j].plot(y[0][:, :, k].mean(axis=0), 'k', lw=2)\n",
    "#         ax[i][j].plot(y[1][:, :, k].mean(axis=0), 'r', lw=2)\n",
    "        ax[i][j].set_xticks([0, y[0].shape[1]])\n",
    "        for side in 'right','top':\n",
    "            ax[i][j].spines[side].set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Stop here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdaf8c",
   "metadata": {},
   "source": [
    "## Continue from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_blocks = len(data_sliding[0][var_names[0]])\n",
    "inputs_to_network = []\n",
    "inputs_to_classifier = []\n",
    "outputs = []\n",
    "for data_slid in data_sliding:\n",
    "    for i in range(N_blocks):\n",
    "        x = {var_name: tf.constant(data_slid[var_name][i:i+1,:], dtype=tf.float32) for var_name in var_names}\n",
    "        inputs_to_network.append(np.concatenate([np.squeeze(data_slid[var_name][i:i+1,:]) for var_name in var_names]))\n",
    "        inputs_to_classifier.append(np.squeeze(submodels[-3].predict(x)))\n",
    "#         inputs_to_classifier.append(np.squeeze(submodels[-2].predict(x)))\n",
    "        outputs.append(np.squeeze(submodels[-1].predict(x)))\n",
    "inputs_to_network = np.array(inputs_to_network)\n",
    "inputs_to_classifier = np.array(inputs_to_classifier)\n",
    "outputs = np.array(outputs)\n",
    "scaled_inputs_to_network = StandardScaler().fit_transform(inputs_to_network)\n",
    "scaled_inputs_to_classifier = StandardScaler().fit_transform(inputs_to_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'kr'\n",
    "fig,ax = plt.subplots(2, 1, figsize=(10,5), sharex=False)\n",
    "j = 10\n",
    "for i in range(2):\n",
    "    ax[0].plot(inputs_to_network[i*N_blocks + j], col[i], lw=1)\n",
    "    ax[1].plot(inputs_to_classifier[i*N_blocks + j], col[i], lw=1, label=f'{outputs[i*N_blocks+j,0]:.2f}')\n",
    "ax[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98de7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_to_classifier[i + j].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_to_classifier[i*N_blocks + j].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_inputs_to_network = np.zeros(N_blocks)\n",
    "dst_inputs_to_classifier = np.zeros(N_blocks)\n",
    "for i in range(N_blocks):\n",
    "    alignment = dtw.dtw(inputs_to_network[i], inputs_to_network[i+N_blocks], keep_internals=False)\n",
    "    dst_inputs_to_network[i] = alignment.distance\n",
    "    alignment = dtw.dtw(inputs_to_classifier[i], inputs_to_classifier[i+N_blocks], keep_internals=False)\n",
    "    dst_inputs_to_classifier[i] = alignment.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1766d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(dst_inputs_to_network, [0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(dst_inputs_to_classifier, [0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "m = np.min([inputs_to_network[i].min(), inputs_to_network[i+N_blocks].min()])\n",
    "M = np.max([inputs_to_network[i].max(), inputs_to_network[i+N_blocks].max()])\n",
    "dst_inputs_to_network = np.sqrt((inputs_to_network[i] - inputs_to_network[i+N_blocks]) ** 2) / (M - m)\n",
    "m = np.min([inputs_to_classifier[i].min(), inputs_to_classifier[i+N_blocks].min()])\n",
    "M = np.max([inputs_to_classifier[i].max(), inputs_to_classifier[i+N_blocks].max()])\n",
    "dst_inputs_to_classifier = np.sqrt((inputs_to_classifier[i] - inputs_to_classifier[i+N_blocks]) ** 2) / (M - m)\n",
    "\n",
    "plt.plot(dst_inputs_to_network, 'k', lw=0.5)\n",
    "plt.plot(dst_inputs_to_classifier, 'r', lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3122e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((scaled_inputs_to_network[0] - scaled_inputs_to_network[N]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((scaled_inputs_to_classifier[0] - scaled_inputs_to_classifier[N]) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d023c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pc_inputs_to_network = pca.fit_transform(scaled_inputs_to_network)\n",
    "pc_inputs_to_classifier = pca.fit_transform(scaled_inputs_to_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(7,4))\n",
    "ax[0].plot(pc_inputs_to_network[:N,0], pc_inputs_to_network[:N,1], 'k.')\n",
    "ax[0].plot(pc_inputs_to_network[N:,0], pc_inputs_to_network[N:,1], 'r.')\n",
    "ax[1].plot(pc_inputs_to_classifier[:N,0], pc_inputs_to_classifier[:N,1], 'k.')\n",
    "ax[1].plot(pc_inputs_to_classifier[N:,0], pc_inputs_to_classifier[N:,1], 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_inputs_to_network = umap.UMAP().fit_transform(scaled_inputs_to_network)\n",
    "embedding_inputs_to_classifier = umap.UMAP().fit_transform(scaled_inputs_to_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4de92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(embedding_inputs_to_network[:N,0], embedding_inputs_to_network[:N,1],\n",
    "         'ko', ms=4, markerfacecolor='w')\n",
    "plt.plot(embedding_inputs_to_network[N:,0], embedding_inputs_to_network[N:,1],\n",
    "         'ks', ms=4)\n",
    "plt.plot(embedding_inputs_to_classifier[:N,0], embedding_inputs_to_classifier[:N,1],\n",
    "         'ro', ms=4, markerfacecolor='w')\n",
    "plt.plot(embedding_inputs_to_classifier[N:,0], embedding_inputs_to_classifier[N:,1],\n",
    "         'rs', ms=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[0]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=True)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[1]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94de17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[2]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[3]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[4]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2abb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs[5]\n",
    "rows = output[0].shape[2] + 1\n",
    "rows = 8\n",
    "fig,ax = plt.subplots(rows, 6, figsize=(16,rows), sharex=False)\n",
    "for j,key in enumerate(x.keys()):\n",
    "    for i,a in enumerate(ax[:,j]):\n",
    "        if i == 0:\n",
    "            a.plot(np.squeeze(x[key].numpy()), 'r', lw=1)\n",
    "        else:\n",
    "            a.plot(np.squeeze(output[j][0,:,i-1]), 'k', lw=1)\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "        for side in 'right','top':\n",
    "            a.spines[side].set_visible(False)\n",
    "        if i == rows:\n",
    "            break\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc75f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(10,3))\n",
    "for i,a in enumerate(ax):\n",
    "    a.plot(outputs[6+i][0], 'k', lw=1)\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(10,3))\n",
    "for i,a in enumerate(ax):\n",
    "    a.plot(outputs[6+i][0], 'k', lw=1)\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
