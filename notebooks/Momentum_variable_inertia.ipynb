{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "from scipy.fft import fft, fftfreq\n",
    "# from scipy.signal import butter, filtfilt\n",
    "# from sklearn.metrics import r2_score\n",
    "# from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "# from dlml.utils import collect_experiments\n",
    "from dlml.data import load_data_files, load_data_areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ab434",
   "metadata": {},
   "source": [
    "#### Which model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ecaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on frequency data, 2 output values\n",
    "# experiment_ID = '9ea493c789b542bf979c51a6031f4044'\n",
    "# training on frequency data, 4 output values\n",
    "# experiment_ID = 'f6d9a03f1cfe450288e9cb86da94235f'\n",
    "# training on time data, 2 output values\n",
    "# experiment_ID = '034a1edb0797475b985f0e1335dab383'\n",
    "# training on time data, 4 output values\n",
    "# experiment_ID = 'b346a89d384c4db2ba4058a2c83c4f12'\n",
    "# training on time data, 2 output values, 8 input values\n",
    "experiment_ID = '474d2016e33b441889ce8b17531487cb' # replaces 98475b819ecb4d569646d7e1467d7c9c'\n",
    "# training on time data, 4 output values, 16 input values (with compensators)\n",
    "experiment_ID = 'c6f72abb5e364c4cb7770250e135bd73' # replaces '302a21340f354ac2949184be98d8e907'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc0d23",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefe21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "network_parameters = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'parameters.pkl'), 'rb'))\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "try:\n",
    "    epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "except:\n",
    "    best_checkpoint = checkpoint_files[-1]\n",
    "model = keras.models.load_model(best_checkpoint)\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "x_train_min = network_parameters['x_train_min']\n",
    "x_train_max = network_parameters['x_train_max']\n",
    "var_names = network_parameters['var_names']\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Variable names: {var_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714c54d",
   "metadata": {},
   "source": [
    "#### Model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca49fb",
   "metadata": {},
   "source": [
    "Some variables used in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ed18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, Xf = {}, {}, {}\n",
    "group_index, n_mom_groups = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9028f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(os.path.join('..', network_parameters['data_dirs'][0].format(network_parameters['area_IDs'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc320c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('..', network_parameters['data_dirs'][0].format(network_parameters['area_IDs'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81010714",
   "metadata": {},
   "source": [
    "#### Load the original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22eb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fft = network_parameters['use_fft'] if 'use_fft' in network_parameters else False\n",
    "if use_fft:\n",
    "    raise Exception('This notebook must be used on a network that uses time-domain inputs')\n",
    "\n",
    "set_name = 'test'\n",
    "low_high = True\n",
    "\n",
    "data_dir = os.path.join('..', network_parameters['data_dirs'][0].format(network_parameters['area_IDs'][0]))\n",
    "# if 'comp' in os.path.split(data_dir)[-1]:\n",
    "#     data_dir = os.path.join(*os.path.split(data_dir)[:-1], os.path.split(data_dir)[-1].replace('_comp',''))\n",
    "data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=5000,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=False)\n",
    "t = ret[0]\n",
    "X_raw = ret[1][set_name]\n",
    "y[set_name] = ret[2][set_name]\n",
    "\n",
    "X[set_name] = np.zeros(X_raw.shape)\n",
    "for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "    X[set_name][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "X[set_name] = X[set_name].squeeze()\n",
    "y[set_name] = y[set_name].squeeze()\n",
    "if low_high:\n",
    "    m = y[set_name].mean()\n",
    "    idx = y[set_name] > m\n",
    "    jdx = y[set_name] < m\n",
    "    y[set_name][idx] = y[set_name][idx].mean()\n",
    "    y[set_name][jdx] = y[set_name][jdx].mean()\n",
    "dt = np.diff(t[:2])[0]\n",
    "N_samples = t.size\n",
    "Xf[set_name] = fft(X[set_name])\n",
    "Xf[set_name] = 2.0 / N_samples * np.abs(Xf[set_name][:, :N_samples//2])\n",
    "F = fftfreq(N_samples, dt)[:N_samples//2]\n",
    "\n",
    "group_index[set_name] = [np.where(y[set_name] == mom)[0] for mom in np.unique(y[set_name])]\n",
    "n_mom_groups[set_name] = len(group_index[set_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b6007",
   "metadata": {},
   "source": [
    "#### Load the first data set\n",
    "Here, the values of inertia of G2 and G3 are changed while keeping the area momentum constant."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1a543cf",
   "metadata": {},
   "source": [
    "base_folder = network_parameters['data_dirs'][0]\n",
    "while '{}' in base_folder:\n",
    "    base_folder,_ = os.path.split(base_folder)\n",
    "data_files = []\n",
    "group_index['var_G2_G3'] = []\n",
    "for i,prefix in enumerate(('low','high')):\n",
    "    folder = os.path.join('..', base_folder, prefix + '_momentum_' + set_name + '_var_G1_G2')\n",
    "    files = sorted(glob.glob(folder + os.path.sep + '*.h5'))\n",
    "    group_index['var_G2_G3'].append(np.arange(len(files)) + len(data_files))\n",
    "    data_files += files\n",
    "n_mom_groups['var_G2_G3'] = len(group_index['var_G2_G3'])\n",
    "\n",
    "ret = load_data_files(data_files,\n",
    "                      network_parameters['var_names'],\n",
    "                      network_parameters['generators_areas_map'][:1],\n",
    "                      network_parameters['generators_Pnom'],\n",
    "                      'momentum')\n",
    "\n",
    "X_raw = ret[1][:, :, :-1]\n",
    "X['var_G2_G3'] = np.zeros(X_raw.shape)\n",
    "for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "    X['var_G2_G3'][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "y['var_G2_G3'] = ret[2]\n",
    "X['var_G2_G3'] = X['var_G2_G3'].squeeze()\n",
    "y['var_G2_G3'] = y['var_G2_G3'].squeeze()\n",
    "Xf['var_G2_G3'] = fft(X['var_G2_G3'])\n",
    "Xf['var_G2_G3'] = 2.0 / N_samples * np.abs(Xf['var_G2_G3'][:, :N_samples//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6690296",
   "metadata": {},
   "source": [
    "#### Load the second data set\n",
    "Here, the values of inertia of G4 or G8 are changed. The momentum of area 1 is unchanged."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb8d1dae",
   "metadata": {},
   "source": [
    "base_folder = network_parameters['data_dirs'][0]\n",
    "while '{}' in base_folder:\n",
    "    base_folder,_ = os.path.split(base_folder)\n",
    "generators = 'G4', 'G8'\n",
    "for gen in generators:\n",
    "    key = 'var_' + gen\n",
    "    data_files = []\n",
    "    group_index[key] = []\n",
    "    for i,prefix in enumerate(('low','high')):\n",
    "        folder = os.path.join('..', base_folder, prefix + '_momentum_' + set_name + '_var_' + gen)\n",
    "        files = sorted(glob.glob(folder + os.path.sep + '*.h5'))\n",
    "        group_index[key].append(np.arange(len(files)) + len(data_files))\n",
    "        data_files += files\n",
    "    n_mom_groups[key] = len(group_index[key])\n",
    "\n",
    "    ret = load_data_files(data_files,\n",
    "                          network_parameters['var_names'],\n",
    "                          network_parameters['generators_areas_map'][:1],\n",
    "                          network_parameters['generators_Pnom'],\n",
    "                          'momentum')\n",
    "\n",
    "    X_raw = ret[1][:, :, :-1]\n",
    "    X[key] = np.zeros(X_raw.shape)\n",
    "    for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "        X[key][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "    y[key] = ret[2]\n",
    "    X[key] = X[key].squeeze()\n",
    "    y[key] = y[key].squeeze()\n",
    "    Xf[key] = fft(X[key])\n",
    "    Xf[key] = 2.0 / N_samples * np.abs(Xf[key][:, :N_samples//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300651c",
   "metadata": {},
   "source": [
    "#### Load the third data set\n",
    "Here, the values of inertia of G2 and G3 are increased beyond the values used to generate the low-momentum configuration of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..',\n",
    "                        network_parameters['data_dirs'][0].format(network_parameters['area_IDs'][0]),\n",
    "                        '..',\n",
    "                        'coarse')\n",
    "data_file = 'inertia_5.000_3.863_4.003_3.570_4.330_4.350_3.770_3.470_3.450_4.200_0.100_0.100_0.100_test_set.h5'\n",
    "base_folder = network_parameters['data_dirs'][0]\n",
    "while '{}' in base_folder:\n",
    "    base_folder,_ = os.path.split(base_folder)\n",
    "data_files = [os.path.join(data_dir, data_file)]\n",
    "\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=5000,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=False)\n",
    "\n",
    "key = 'var_G2_G3'\n",
    "X_raw = ret[1][set_name]\n",
    "X[key] = np.zeros(X_raw.shape)\n",
    "for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "    X[key][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "y[key] = ret[2][set_name]\n",
    "X[key] = X[key].squeeze()\n",
    "y[key] = y[key].squeeze()\n",
    "Xf[key] = fft(X[key])\n",
    "Xf[key] = 2.0 / N_samples * np.abs(Xf[key][:, :N_samples//2])\n",
    "\n",
    "group_index[key] = [np.arange(y[key].size)]\n",
    "n_mom_groups[key] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3141d76",
   "metadata": {},
   "source": [
    "#### Load the fourth data set\n",
    "Here, the values of inertia of G2 and G3 are fixed to the low-momentum configuration of the test set, while the inertia of the compensator in area 1 is increased to 6.1 s: this leads to an area momentum that is equivalent to that of the previous file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ef5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..',\n",
    "                        network_parameters['data_dirs'][0].format(network_parameters['area_IDs'][0]),\n",
    "                        '..')\n",
    "data_file = 'inertia_5.000_3.463_3.603_3.570_4.330_4.350_3.770_3.470_3.450_4.200_6.100_0.100_0.100_test_set.h5'\n",
    "base_folder = network_parameters['data_dirs'][0]\n",
    "while '{}' in base_folder:\n",
    "    base_folder,_ = os.path.split(base_folder)\n",
    "data_files = [os.path.join(data_dir, data_file)]\n",
    "\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=5000,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=False)\n",
    "\n",
    "key = 'var_Comp11'\n",
    "X_raw = ret[1][set_name]\n",
    "X[key] = np.zeros(X_raw.shape)\n",
    "for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "    X[key][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "y[key] = ret[2][set_name]\n",
    "X[key] = X[key].squeeze()\n",
    "y[key] = y[key].squeeze()\n",
    "Xf[key] = fft(X[key])\n",
    "Xf[key] = 2.0 / N_samples * np.abs(Xf[key][:, :N_samples//2])\n",
    "\n",
    "group_index[key] = [np.arange(y[key].size)]\n",
    "n_mom_groups[key] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2dfb6",
   "metadata": {},
   "source": [
    "#### Predict the values of area momentum for all the input data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffecbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = {k: model.predict(v) for k,v in X.items()}\n",
    "ym = {k: [v[group_index[k][i]].mean() for i in range(n_mom_groups[k])] for k,v in y.items()}\n",
    "ys = {k: [v[group_index[k][i]].std() for i in range(n_mom_groups[k])] for k,v in y.items()}\n",
    "ym_pred = {k: [v[group_index[k][i]].mean() for i in range(n_mom_groups[k])] for k,v in y_pred.items()}\n",
    "ys_pred = {k: [v[group_index[k][i]].std() for i in range(n_mom_groups[k])] for k,v in y_pred.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_exact = deepcopy(y)\n",
    "y_exact['var_G2_G3'] -= 1e-6\n",
    "y_exact['var_Comp11'] += 1e-6\n",
    "exact_momentum = np.concatenate(list(y_exact.values()))\n",
    "pred_momentum = np.concatenate(list(y_pred.values()))\n",
    "df = pd.DataFrame(data={'exact': exact_momentum, 'pred': np.concatenate(pred_momentum)})\n",
    "data = {'ym': ym, 'ym_pred': ym_pred, 'ys_pred': ys_pred, 'F': F, 'Xf': Xf,\n",
    "        'group_index': group_index, 'n_mom_groups': n_mom_groups, 'df': df}\n",
    "data_file = os.path.join(experiments_path, experiment_ID, f'variable_inertia_{experiment_ID[:6]}.npz')\n",
    "np.savez_compressed(data_file, **data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902aa39",
   "metadata": {},
   "source": [
    "#### Plot the spectra of all the input data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_violin = False\n",
    "\n",
    "fig,ax = plt.subplots(3, 1, figsize=(6.5, 10))\n",
    "\n",
    "cmap_name = 'tab10'\n",
    "cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "if use_violin:\n",
    "    palette = [cmap(i) for i in [0, 2, 3, 1]]\n",
    "    sns.violinplot(x='exact', y='pred', data=df, cut=0, inner='quartile',\n",
    "                   palette=palette, linewidth=1, ax=ax[0])\n",
    "else:\n",
    "    ax[0].plot(ym['test'], ym['test'], 'k--', lw=2, markerfacecolor='w')\n",
    "    n = 0\n",
    "    for k in ym:\n",
    "        for j in range(len(ym[k])):\n",
    "            ax[0].plot(ym[k][j] + np.zeros(2),\n",
    "                       ym_pred[k][j] + ys_pred[k][j] * np.array([-1,1]),\n",
    "                       color=cmap(n), linewidth=3)\n",
    "            ax[0].plot(ym[k][j], ym_pred[k][j], 'o', color=cmap(n), markersize=10,\n",
    "                       markerfacecolor='w', markeredgewidth=3)\n",
    "            n += 1\n",
    "ax[0].set_xlabel(r'Exact momentum [GW$\\cdot$s$^2$]')\n",
    "ax[0].set_ylabel(r'Estimated momentum [GW$\\cdot$s$^2$]')\n",
    "ax[0].grid(which='major', axis='both', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "\n",
    "for a in (1,2):\n",
    "    n = 0\n",
    "    for i,(k,v) in enumerate(Xf.items()):\n",
    "        for j in range(n_mom_groups[k]):\n",
    "            m = v[group_index[k][j], :].mean(axis=0)\n",
    "            s = v[group_index[k][j], :].std(axis=0)\n",
    "            ci = 1.96 * s / np.sqrt(group_index[k][j].size)\n",
    "            ax[a].fill_between(F, 20*np.log10(m + ci), 20*np.log10(m - ci),\n",
    "                            color=cmap(n), label=k, alpha=0.5)\n",
    "            n += 1\n",
    "    ax[a].set_xscale('log')\n",
    "    ax[a].set_ylabel('Power [dB]')\n",
    "ax[1].legend(loc='lower left', frameon=False, fontsize=8)\n",
    "ax[2].set_xlabel('Frequency [Hz]')\n",
    "ax[2].set_xlim([0.4, 1.5])\n",
    "ax[2].set_ylim([-33, -10])\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "pdf_file = os.path.join(experiments_path, experiment_ID, f'variable_inertia_{experiment_ID[:6]}.pdf')\n",
    "fig.savefig(pdf_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
