{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from dlml.utils import collect_experiments\n",
    "from dlml.data import load_data_files, load_data_areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ab434",
   "metadata": {},
   "source": [
    "#### Which model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ecaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on frequency data, 2 output values\n",
    "# experiment_ID = '9ea493c789b542bf979c51a6031f4044'\n",
    "# training on frequency data, 4 output values\n",
    "# experiment_ID = 'f6d9a03f1cfe450288e9cb86da94235f'\n",
    "# training on time data, 2 output values\n",
    "experiment_ID = '034a1edb0797475b985f0e1335dab383'\n",
    "# training on time data, 4 output values\n",
    "# experiment_ID = 'b346a89d384c4db2ba4058a2c83c4f12'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc0d23",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefe21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '../experiments/neural_network/'\n",
    "network_parameters = pickle.load(open(os.path.join(experiments_path, experiment_ID, 'parameters.pkl'), 'rb'))\n",
    "checkpoint_path = experiments_path + experiment_ID + '/checkpoints/'\n",
    "checkpoint_files = glob.glob(checkpoint_path + '*.h5')\n",
    "try:\n",
    "    epochs = [int(os.path.split(file)[-1].split('.')[1].split('-')[0]) for file in checkpoint_files]\n",
    "    best_checkpoint = checkpoint_files[epochs.index(np.argmin(val_loss) + 1)]\n",
    "except:\n",
    "    best_checkpoint = checkpoint_files[-1]\n",
    "model = keras.models.load_model(best_checkpoint)\n",
    "x_train_mean = network_parameters['x_train_mean']\n",
    "x_train_std  = network_parameters['x_train_std']\n",
    "x_train_min = network_parameters['x_train_min']\n",
    "x_train_max = network_parameters['x_train_max']\n",
    "var_names = network_parameters['var_names']\n",
    "print(f'Loaded network from {best_checkpoint}.')\n",
    "print(f'Variable names: {var_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714c54d",
   "metadata": {},
   "source": [
    "#### Model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca49fb",
   "metadata": {},
   "source": [
    "Some variables used in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ed18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, Xf = {}, {}, {}\n",
    "group_index, n_mom_groups = {}, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81010714",
   "metadata": {},
   "source": [
    "#### Load the original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22eb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fft = network_parameters['use_fft'] if 'use_fft' in network_parameters else False\n",
    "if use_fft:\n",
    "    raise Exception('This notebook must be used on a network that uses time-domain inputs')\n",
    "\n",
    "set_name = 'test'\n",
    "\n",
    "data_dir = os.path.join('..', network_parameters['data_dirs'][0].format(network_parameters['area_IDs'][0]))\n",
    "data_files = sorted(glob.glob(data_dir + os.path.sep + f'*_{set_name}_set.h5'))\n",
    "ret = load_data_areas({set_name: data_files}, network_parameters['var_names'],\n",
    "                        network_parameters['generators_areas_map'][:1],\n",
    "                        network_parameters['generators_Pnom'],\n",
    "                        network_parameters['area_measure'],\n",
    "                        trial_dur=network_parameters['trial_duration'],\n",
    "                        max_block_size=500,\n",
    "                        use_tf=False, add_omega_ref=True,\n",
    "                        use_fft=False)\n",
    "t = ret[0]\n",
    "X_raw = ret[1][set_name]\n",
    "y[set_name] = ret[2][set_name]\n",
    "group_index[set_name] = [np.where(y[set_name] == mom)[0] for mom in np.unique(y[set_name])]\n",
    "\n",
    "X[set_name] = np.zeros(X_raw.shape)\n",
    "for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "    X[set_name][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "X[set_name] = X[set_name].squeeze()\n",
    "y[set_name] = y[set_name].squeeze()\n",
    "dt = np.diff(t[:2])[0]\n",
    "N_samples = t.size\n",
    "Xf[set_name] = fft(X[set_name])\n",
    "Xf[set_name] = 2.0 / N_samples * np.abs(Xf[set_name][:, :N_samples//2])\n",
    "F = fftfreq(N_samples, dt)[:N_samples//2]\n",
    "n_mom_groups[set_name] = len(group_index[set_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b6007",
   "metadata": {},
   "source": [
    "#### Load the first data set\n",
    "Here, the values of inertia of G2 and G3 are changed while keeping the area momentum constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d66fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = network_parameters['data_dirs'][0]\n",
    "while '{}' in base_folder:\n",
    "    base_folder,_ = os.path.split(base_folder)\n",
    "data_files = []\n",
    "group_index['var_G2_G3'] = []\n",
    "for i,prefix in enumerate(('low','high')):\n",
    "    folder = os.path.join('..', base_folder, prefix + '_momentum_' + set_name + '_var_G1_G2')\n",
    "    files = sorted(glob.glob(folder + os.path.sep + '*.h5'))\n",
    "    group_index['var_G2_G3'].append(np.arange(len(files)) + len(data_files))\n",
    "    data_files += files\n",
    "n_mom_groups['var_G2_G3'] = len(group_index['var_G2_G3'])\n",
    "\n",
    "ret = load_data_files(data_files,\n",
    "                      network_parameters['var_names'],\n",
    "                      network_parameters['generators_areas_map'][:1],\n",
    "                      network_parameters['generators_Pnom'],\n",
    "                      'momentum')\n",
    "\n",
    "X_raw = ret[1][:, :, :-1]\n",
    "X['var_G2_G3'] = np.zeros(X_raw.shape)\n",
    "for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "    X['var_G2_G3'][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "y['var_G2_G3'] = ret[2]\n",
    "X['var_G2_G3'] = X['var_G2_G3'].squeeze()\n",
    "y['var_G2_G3'] = y['var_G2_G3'].squeeze()\n",
    "Xf['var_G2_G3'] = fft(X['var_G2_G3'])\n",
    "Xf['var_G2_G3'] = 2.0 / N_samples * np.abs(Xf['var_G2_G3'][:, :N_samples//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6690296",
   "metadata": {},
   "source": [
    "#### Load the second data set\n",
    "Here, the values of inertia of G4 or G8 are changed. The momentum of area 1 is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d364731",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = network_parameters['data_dirs'][0]\n",
    "while '{}' in base_folder:\n",
    "    base_folder,_ = os.path.split(base_folder)\n",
    "generators = 'G4', 'G8'\n",
    "for gen in generators:\n",
    "    key = 'var_' + gen\n",
    "    data_files = []\n",
    "    group_index[key] = []\n",
    "    for i,prefix in enumerate(('low','high')):\n",
    "        folder = os.path.join('..', base_folder, prefix + '_momentum_' + set_name + '_var_' + gen)\n",
    "        files = sorted(glob.glob(folder + os.path.sep + '*.h5'))\n",
    "        group_index[key].append(np.arange(len(files)) + len(data_files))\n",
    "        data_files += files\n",
    "    n_mom_groups[key] = len(group_index[key])\n",
    "\n",
    "    ret = load_data_files(data_files,\n",
    "                          network_parameters['var_names'],\n",
    "                          network_parameters['generators_areas_map'][:1],\n",
    "                          network_parameters['generators_Pnom'],\n",
    "                          'momentum')\n",
    "\n",
    "    X_raw = ret[1][:, :, :-1]\n",
    "    X[key] = np.zeros(X_raw.shape)\n",
    "    for i,(m,s) in enumerate(zip(x_train_mean, x_train_std)):\n",
    "        X[key][i,:,:] = (X_raw[i,:,:] - m) / s\n",
    "    y[key] = ret[2]\n",
    "    X[key] = X[key].squeeze()\n",
    "    y[key] = y[key].squeeze()\n",
    "    Xf[key] = fft(X[key])\n",
    "    Xf[key] = 2.0 / N_samples * np.abs(Xf[key][:, :N_samples//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2dfb6",
   "metadata": {},
   "source": [
    "#### Predict the values of area momentum for all the input data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffecbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = {k: model.predict(v) for k,v in X.items()}\n",
    "ym = {k: [v[group_index[k][i]].mean() for i in range(n_mom_groups[k])] for k,v in y.items()}\n",
    "ys = {k: [v[group_index[k][i]].std() for i in range(n_mom_groups[k])] for k,v in y.items()}\n",
    "ym_pred = {k: [v[group_index[k][i]].mean() for i in range(n_mom_groups[k])] for k,v in y_pred.items()}\n",
    "ys_pred = {k: [v[group_index[k][i]].std() for i in range(n_mom_groups[k])] for k,v in y_pred.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902aa39",
   "metadata": {},
   "source": [
    "#### Plot the spectra of all the input data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2, 1, figsize=(6.5, 7))\n",
    "\n",
    "cmap = plt.get_cmap('Paired')\n",
    "ax[0].plot(ym['test'], ym['test'], 'ko--', lw=2, markerfacecolor='w')\n",
    "for i,k in enumerate(ym_pred):\n",
    "    for j in range(2):\n",
    "        ax[0].plot(ym[set_name][j] + np.zeros(2),\n",
    "                ym_pred[k][j] + ys_pred[k][j] * np.array([-1,1]),\n",
    "                color=cmap(i*2+1), lw=2)\n",
    "    ax[0].plot(ym[set_name], ym_pred[k], 'o-', color=cmap(i*2+1),\n",
    "            markerfacecolor='w', markeredgewidth=2, label=k)\n",
    "ax[0].set_xlabel(r'Exact momentum [GW$\\cdot$s$^2$]')\n",
    "ax[0].set_ylabel(r'Estimated momentum [GW$\\cdot$s$^2$]')\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[0].grid(which='major', axis='both', lw=0.5, ls=':', color=[.6,.6,.6])\n",
    "xlim = [0.149, 0.31]\n",
    "ylim = [0.145, 0.32]\n",
    "ticks = np.r_[0.15 : 0.31 : 0.03]\n",
    "ax[0].set_xlim(xlim)\n",
    "ax[0].set_ylim(ylim)\n",
    "ax[0].set_xticks(ticks)\n",
    "ax[0].set_yticks(ticks)\n",
    "\n",
    "for i,(k,v) in enumerate(Xf.items()):\n",
    "    for j in range(n_mom_groups[k]):\n",
    "        m = v[group_index[k][j], :].mean(axis=0)\n",
    "        s = v[group_index[k][j], :].std(axis=0)\n",
    "        ci = 1.96 * s / np.sqrt(group_index[k][j].size)\n",
    "        ax[1].fill_between(F, 20*np.log10(m + ci), 20*np.log10(m - ci),\n",
    "                        color=cmap(i*2+j), label=k, alpha=0.5)\n",
    "ax[1].legend(loc='lower left', frameon=False, fontsize=8)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Frequency [Hz]')\n",
    "ax[1].set_ylabel('Power [dB]')\n",
    "\n",
    "for a in ax:\n",
    "    for side in 'right','top':\n",
    "        a.spines[side].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'variable_inertia_{experiment_ID[:6]}.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
